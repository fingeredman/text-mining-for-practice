{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT MINING for PRACTICE\n",
    "- 본 자료는 텍스트 마이닝을 활용한 연구 및 강의를 위한 목적으로 제작되었습니다.\n",
    "- 본 자료를 강의 목적으로 활용하고자 하시는 경우 꼭 아래 메일주소로 연락주세요.\n",
    "- 본 자료에 대한 허가되지 않은 배포를 금지합니다.\n",
    "- 강의, 저작권, 출판, 특허, 공동저자에 관련해서는 문의 바랍니다.\n",
    "- **Contact : 전병진(fingeredman@gmail.com)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEEK 05-1. 한국어 텍스트 데이터 전처리: KoNLPy\n",
    "- Python의 KoNLPy 패키지를 활용해 텍스트 데이터를 전처리하는 방법에 대해 다룹니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 텍스트 데이터를 다루는 다양한 방법 알아보기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. 텍스트 데이터를 다루는 기본함수 알아보기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앞에 공백과 뒤에 줄바꿈이 달린 문자열 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 1-1) 텍스트 앞뒤의 불필요한 문자열 지우기\n",
    "# strip() 함수는 문자열의 맨 앞과 뒤에 붙어있는 개행문자(\\n), 공백문자(\\s), 탭(\\t)을 제거합니다.\n",
    "new_text = \"  앞에 공백과 뒤에 줄바꿈이 달린 문자열 입니다. \\n\"\n",
    "new_text = new_text.strip()\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앞에 공백과 뒤에 줄바꿈이 달린 문자열 입니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1-2) 텍스트 앞에 붙은 불필요한 문자열 지우기\n",
    "# strip() 함수는 문자열의 맨 앞과 뒤에 붙어있는 개행문자(\\n), 공백문자(\\s), 탭(\\t)을 제거합니다.\n",
    "new_text = \"  앞에 공백과 뒤에 줄바꿈이 달린 문자열 입니다. \\n\"\n",
    "new_text = new_text.lstrip()\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  앞에 공백과 뒤에 줄바꿈이 달린 문자열 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 1-3) 텍스트 뒤에 붙은 불필요한 문자열 지우기\n",
    "# strip() 함수는 문자열의 맨 앞과 뒤에 붙어있는 개행문자(\\n), 공백문자(\\s), 탭(\\t)을 제거합니다.\n",
    "new_text = \"  앞에 공백과 뒤에 줄바꿈이 달린 문자열 입니다. \\n\"\n",
    "new_text = new_text.rstrip()\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['영', '일', '이', '삼', '사', '오', '육', '칠', '팔', '구', '십']\n"
     ]
    }
   ],
   "source": [
    "# 2) 텍스트를 문자열 단위로 나눠 리스트로 만들기\n",
    "# split(STRING) 함수는 문자열을 STRING 단위로 나눠 리스트 형태로 만듭니다.\n",
    "# STRING에는 공백문자를 입력할 수 없습니다.\n",
    "new_text = \"영,일,이,삼,사,오,육,칠,팔,구,십\"\n",
    "string_list = new_text.split(\",\")\n",
    "print(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저의 직업은 데이터 엔지니어 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 3) 텍스트 일부를 치환하기\n",
    "# replace(STRING, NEW_STRING) 함수는 문자열(STRING)의 일부를 다른 문자열(NEW_STRING)로 치환합니다.\n",
    "new_text = \"저의 직업은 프로그램 개발자 입니다.\"\n",
    "new_text = new_text.replace(\"프로그램 개발자\", \"데이터 엔지니어\")\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저의\n",
      "직업은\n",
      "데이터\n",
      "엔지니어\n",
      "입니다.\n"
     ]
    }
   ],
   "source": [
    "# 문자열이 아닌 특수기호도 치환이 가능합니다.\n",
    "new_text = new_text.replace(\" \", \"\\n\")\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT MINING은 DATA MINING의 한 분야입니다.\n"
     ]
    }
   ],
   "source": [
    "# 4-1) 텍스트에 포함된 소문자 알파벳을 대문자로 변경하기\n",
    "# upper() 함수는 문자열에 포함된 소문자 알파벳을 모두 대문자로 변경합니다.\n",
    "new_text = \"text mining은 DATA MINING의 한 분야입니다.\"\n",
    "new_text = new_text.upper()\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text mining은 data mining의 한 분야입니다.\n"
     ]
    }
   ],
   "source": [
    "# 4-2) 텍스트에 포함된 대문자 알파벳을 소문자로 변경하기\n",
    "# lower() 함수는 문자열에 포함된 대문자 알파벳을 모두 소문자로 변경합니다.\n",
    "new_text = \"text mining은 DATA MINING의 한 분야입니다.\"\n",
    "new_text = new_text.lower()\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# 5) 텍스트에 포함된 문자열의 인덱스 찾아내기\n",
    "new_text = \"영일이삼사오육칠팔구십\"\n",
    "string_index = new_text.index(\"육\")\n",
    "print(string_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. 텍스트 데이터를 리스트 처럼 다루기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python에서 문자열은 리스트와 유사한 자료구조로 취급해 인덱싱 할 수 있습니다.\n",
    "new_text = \"영일이삼사오육칠팔구\"\n",
    "new_list = [0, 1, 2, 3, 4, 5, 6, 7, 8,  9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_text : 영일이삼사오육칠팔구십\n",
      "new_list : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# 1) 더하기 연산자를 활용해 두 문자열을 결합합니다.\n",
    "new_text = new_text + \"십\"\n",
    "new_list = new_list + [10]\n",
    "print(\"new_text :\", new_text)\n",
    "print(\"new_list :\", new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_text_length : 11\n",
      "new_list_length : 11\n"
     ]
    }
   ],
   "source": [
    "# 2) 문자열에 존재하는 모든 문자의 개수를 불러옵니다.\n",
    "new_text_length = len(new_text)\n",
    "new_list_length = len(new_list)\n",
    "print(\"new_text_length :\", new_text_length)\n",
    "print(\"new_list_length :\", new_list_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 3-1) 문자열에 특정 문자가 존재하는지 여부를 in 연산자를 통해 확인합니다.\n",
    "print(\"칠\" in new_text)\n",
    "print(7 in new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 3-2) 문자열에 특정 문자가 존재하지 않는지 여부를 not in 연산자를 통해 확인합니다.\n",
    "print(\"칠\" not in new_text)\n",
    "print(7 not in new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 문자 : 영\n",
      "1번째 문자 : 일\n",
      "4번째 문자 : 사\n"
     ]
    }
   ],
   "source": [
    "# 4) 문자열에 존재하는 N 번째 문자를 불러옵니다.\n",
    "print(\"0번째 문자 :\", new_text[0])\n",
    "print(\"1번째 문자 :\", new_text[1])\n",
    "print(\"4번째 문자 :\", new_text[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~3번째 문자 : 영일이\n",
      "4~9번째 문자 : 사오육칠팔\n",
      "2~3번째 문자 : 이\n"
     ]
    }
   ],
   "source": [
    "# 5) 문자열에 존재하는 N번째 부터 M-1번째 문자를 리스트 형식으로 불러옵니다.\n",
    "print(\"0~3번째 문자 :\", new_text[0:3])\n",
    "print(\"4~9번째 문자 :\", new_text[4:9])\n",
    "print(\"2~3번째 문자 :\", new_text[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번째 부터 모든 문자 : 삼사오육칠팔구십\n",
      "5번째 부터 모든 문자 : 오육칠팔구십\n",
      "9번째 부터 모든 문자 : 구십\n"
     ]
    }
   ],
   "source": [
    "# 6) 문자열에 존재하는 N번째 부터 모든 문자를 리스트 형식으로 불러옵니다.\n",
    "print(\"3번째 부터 모든 문자 :\", new_text[3:])\n",
    "print(\"5번째 부터 모든 문자 :\", new_text[5:])\n",
    "print(\"9번째 부터 모든 문자 :\", new_text[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 이전의 모든 문자 : 영\n",
      "7번째 이전의 모든 문자 : 영일이삼사오육\n",
      "9번째 이전의 모든 문자 : 영일이삼사오육칠팔\n"
     ]
    }
   ],
   "source": [
    "# 7) 문자열에 존재하는 N번째 이전의 모든 문자를 리스트 형식으로 불러옵니다.\n",
    "print(\"1번째 이전의 모든 문자 :\", new_text[:1])\n",
    "print(\"7번째 이전의 모든 문자 :\", new_text[:7])\n",
    "print(\"9번째 이전의 모든 문자 :\", new_text[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "끝에서 |-1|-1번째 이전의 모든 문자 : 영일이삼사오육칠팔구\n",
      "끝에서 |-1|-1번째 부터 모든 문자 : 십\n",
      "끝에서 |-2|-1번째 이전의 모든 문자 : 영일이삼사오육칠팔\n",
      "끝에서 |-2|-1번째 부터 모든 문자 : 구십\n"
     ]
    }
   ],
   "source": [
    "# 8) 문자열 인덱싱에 사용되는 정수 N의 부호가 음수인 경우, 마지막 문자부터 |N|-1번째 원소를 의미합니다.\n",
    "print(\"끝에서 |-1|-1번째 이전의 모든 문자 :\", new_text[:-1])\n",
    "print(\"끝에서 |-1|-1번째 부터 모든 문자 :\", new_text[-1:])\n",
    "print(\"끝에서 |-2|-1번째 이전의 모든 문자 :\", new_text[:-2])\n",
    "print(\"끝에서 |-2|-1번째 부터 모든 문자 :\", new_text[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영 일 이 삼 사 오 육 칠 팔 구 십 "
     ]
    }
   ],
   "source": [
    "# 9) FOR 문의 for + (반복할 변수) + in + (반복할 값이 저장된 리스트): 구조에서 리스트 대신 문자열을 활용합니다.\n",
    "for i in new_text:\n",
    "    print(i, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 한국어 텍스트 데이터를 전처리하는 방법 알아보기: KoNLPy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. KoNLPy 패키지 설치하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 한국어 텍스트 전처리를 도와주는 konlpy 패키지를 설치합니다.\n",
    "# konlpy를 활용하기 위해서는 jpype1 패키지도 설치합니다.\n",
    "# jpype1 패키지가 동작하기 위해서는 Java JDK 설치가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install jpype1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. KoNLPy 패키지 내 형태소분석기 호출하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KoNLPy 패키지에서는 총 5가지 형태소분석기를 제공합니다.\n",
    "# 그 중 꼬꼬마와 한나눔, OKT 형태소분석기를 불러와 비교합니다.\n",
    "\n",
    "text = \"아버지가 가방에 들어가신다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아버지', 'NNG'), ('가', 'JKS'), ('가방', 'NNG'), ('에', 'JKM'), ('들어가', 'VV'), ('시', 'EPH'), ('ㄴ다', 'EFN'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "# 꼬꼬마 형태소 분석기를 불러옵니다.\n",
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "print(kkma.pos(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아버지', 'N'), ('가', 'J'), ('가방', 'N'), ('에', 'J'), ('들', 'P'), ('어', 'E'), ('가', 'P'), ('시ㄴ다', 'E'), ('.', 'S')]\n"
     ]
    }
   ],
   "source": [
    "# 한나눔 형태소 분석기를 불러옵니다.\n",
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()\n",
    "\n",
    "print(hannanum.pos(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아버지', 'Noun'), ('가', 'Josa'), ('가방', 'Noun'), ('에', 'Josa'), ('들어가신다', 'Verb'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "# OKT(Twitter) 형태소 분석기를 불러옵니다.\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "print(okt.pos(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 형태소분석기는 종류별로 형태소를 분리하는 기준과 태그명이 다릅니다.\n",
    "# 본 자료에서는 꼬꼬마 형태소 분석기를 활용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. 형태소분석기 활용하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['텍스트 데이터는 비정형 데이터에 해당합니다.', '비정형 데이터는 전체 데이터의 80% 정도를 차지합니다.']\n"
     ]
    }
   ],
   "source": [
    "# 1) sentences(TEXT) 함수를 활용해 문단을 문장단위로 분리하여 리스트 형태로 만듭니다.\n",
    "text= \"텍스트 데이터는 비정형 데이터에 해당합니다. 비정형 데이터는 전체 데이터의 80% 정도를 차지합니다.\"\n",
    "sentence_list = kkma.sentences(text)\n",
    "print(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('텍스트', 'NNG'), ('데이터', 'NNG'), ('는', 'JX'), ('비정형', 'NNG'), ('데이터', 'NNG'), ('에', 'JKM'), ('해당', 'NNG'), ('하', 'XSV'), ('ㅂ니다', 'EFN'), ('.', 'SF')]\n",
      "[('비정형', 'NNG'), ('데이터', 'NNG'), ('는', 'JX'), ('전체', 'NNG'), ('데이터', 'NNG'), ('의', 'JKG'), ('80', 'NR'), ('%', 'SW'), ('정도', 'NNG'), ('를', 'JKO'), ('차지', 'NNG'), ('하', 'XSV'), ('ㅂ니다', 'EFN'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "# 2) pos(TEXT) 함수를 활용해 문장을 형태소 단위로 분리하여 리스트 형태로 만듭니다.\n",
    "for sentence in sentence_list:\n",
    "    pos_list = kkma.pos(sentence)\n",
    "    print(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['텍스트', '데이터', '비정형', '해당']\n",
      "['비정형', '데이터', '전체', '80', '정도', '차지']\n"
     ]
    }
   ],
   "source": [
    "# 2) nouns(TEXT) 함수를 활용해 문장을 형태소 단위로 분리하고 명사(NNG, NNP)만 리스트 형태로 만듭니다.\n",
    "for sentence in sentence_list:\n",
    "    pos_list = kkma.nouns(sentence)\n",
    "    print(pos_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 한국어 텍스트 데이터를 전처리하는 방법 알아보기: TEANAPS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. TEANAPS 패키지 설치하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 텍스트 분석을 위한 TEANAPS 패키지를 설치합니다.\n",
    "# TEANAPS는 Google Colaboratory/Linux 환경에 최적화되어 있습니다.\n",
    "# Windows 환경에서 일부 기능에 제한이 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEANAPS (https://github.com/fingeredman/teanaps)\n",
    "#!git clone https://github.com/fingeredman/teanaps.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!python \"teanaps/teanaps_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. TEANAPS 패키지 내 형태소분석기 호출하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아버지', 'NNG', (0, 3)), ('가', 'JC', (3, 4)), ('가방', 'NNG', (5, 7)), ('에', 'JC', (7, 8)), ('들어가신다', 'VV', (9, 14)), ('.', 'SW', (14, 15))]\n"
     ]
    }
   ],
   "source": [
    "# TEANAPS 형태소 분석기를 불러옵니다.\n",
    "from teanaps.nlp import SyntaxAnalyzer\n",
    "sa = SyntaxAnalyzer()\n",
    "\n",
    "# TEANAPS에서는 한국어 텍스트 분석을 위해 3가지 형태소분석기를 지원합니다.\n",
    "# 사용할 형태소분석기 유형을 지정합니다.\n",
    "# 지정하지 않은 경우에는 기본으로 Okt 형태소분석기가 사용됩니다.\n",
    "sa.set_tagger(\"okt\")\n",
    "#sa.set_tagger(\"mecab\")\n",
    "#sa.set_tagger(\"kkma\")\n",
    "\n",
    "text = \"아버지가 가방에 들어가신다.\"\n",
    "pos_list = sa.parse(text)\n",
    "print(pos_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. 형태소분석기 활용하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['금융 비트코인 쇠락 재적 결함 보고서 넷 코리아 손 예술 기자 대표 암호 화폐 비트코인 가격 급 변동 불구 일부 암호 화폐 옹호 론자 비트코인 몇 가지 결함 해소 국면 것 예측 그 결함 전제 국내외 정부 감독 당국 선제 시각 및 규제 환경 정비 주장 한국 금융 연구원 비트코인 쇠락 재적 결함 보고서 암호 화폐 옹호 론 입장 그 제시 세 가지 결함 발표 여기 암호 화폐 옹호 론자 암호 화폐 부가가치 낼 수 사업 모델 등장 가능성 집중 인물 통칭 그 위해 비트코인 세 가지 결함 우선 해소 보고 하나 비트코인 재화 용역 구입 사용 시장 은 것 미국 비트코인 시장조사 기관 사토시 캐피탈 리서치 지난 기준 비트코인 사용 거래 결제 액 약 중국 알리페 위챗 페이 거래 결제 액 약 감안 시장 것 두 번 비트코인 거래 건수 급증 블록 용량 제한 등 채굴 통핸 결제 처리 지연 이용자 거래 완료 위해 부담 수수료 문제 것 비트코인 기반 기술 블록 체인 구성 각 블록 용량 메가바이트 초당 평균 거래 처리 건수 건 약 개 블록 형성 반면 비자 경우 초당 거래 처리 건수 수 건 달 세 번 거래소 해킹 등 사기 거래 노출 점 지난 캐나다 암호 화폐 거래소 대표이사 이자 설립 사망 거액 고객 암호 화폐 분 시로 파산 보호 신청 파산관재인 은 비밀 키 관리 설립 사망 이전 개월 간 핫월렛 고객 암호 폐가 발표 핫월렛 인터넷 연결 암호 화폐 전자지갑 세 가지 결함 불구 비트코인 이용 오프라인 결제 나라 디지털 화폐 대한 실험 시도 상태 이 때문 암호 화폐 비트코인 정말 법정 통화 보완 거나 지급 결제 가치 저장 수단 역할 수 가늠 위해 선 재적 결함 대처 국내외 정부 감독 당국 암호 화폐 대한 시각 및 규제 환경 정비 게 이 보고서 의견 옹호 론 지적 세 가지 결함 중 일부 금융 소비자 투자자 보호 문제 직결 상황 한국 금융 연구원 암호 화폐 수용 검토 정부 감독 당국 소비자 보호 강화 및 금융시장 안정 확보 관점 시장 참가자 정보 공시 의무 강화 결제 계좌 및 전자지갑 제공 거래소 금융 사의 자본금 유동성 규제 부과 며 이 자금 세탁 차단 등 대한 집중 검토 고 서술 한편 비트코인 중순 육박 올해 등 이 기간 동안 비트코인 시가총액 감소 손 예술 기자',\n",
       " '비트코인 상반 평가 김산 기자 얼 퍼거슨 하버드대 교수 왼쪽 워렌 버핏 버크셔 해서웨이 회장 오른쪽 사진 트위터 워렌 버핏 버크셔 해서웨이 회장 세계 경제 사학자 얼 퍼거슨 하버드대 교수 비트코인 상반 평가 과거 비트코인 비판 퍼거슨 교수 자신 발언 후회 고 언급 반면 버핏 회장 한층 더 부정 시각 견 지해 눈길 버핏 회장 지난달 이하 현지 시간 미국 인터뷰 비트코인 고유 가치 것 생산 기본 망상 주장 비트코인 사기꾼 면서 인생 것 가상 화폐 암호 화폐 투자 투자자 말 그 지난해 버크셔 해서웨이 주주총회 비트코인 쥐약 며 비판 발언 바 그 이전 비트코인 튤립 버블 이나 신기루 비유 퍼거슨 교수 생각 현지 시간 외신 퍼거슨 교수 호주 일간 이 개최 비즈니스 서밋 비공개 행사 암호 화폐 망상 말 버핏 주장 정반대 입장 셈 퍼거슨 교수 블록 체인 기반 암호 폐가 만 곳 존재 생각 그 비트코인 가격 절정 달 지난 말 미국 폭스 비즈니스 네트워크 방송 출연 비트코인 금융 역사상 가장 버블 거품 평가 바 지난달 비트코인 디지털 금 이 수 후보 중 하나 라며 비트코인 대해 긍정 시각 내비 또 지난 금융 변화 앞 금융 변화 더 혁신 일 것 전망 그 최근 블록 체인 회사 자문 위원 참여 것 김산 한경닷컴 기자 기사 제보 및 보도자료 한경닷컴 바로가기 모바일 한경 구독 신청 네이버 한국 경제 채널 구독 보기 한국 경제 무단 재 및 재 배포 금지',\n",
       " '코 인터뷰 스테판 러스트 비트코인 비즈니스 총괄 김산 기자 한경닷컴 인터뷰 스테판 러스트 비트코인 비즈니스 총괄 현재 가상 화폐 암호 화폐 생태계 약 정도 사용자 것 추정 인터넷 사용자 수 우리 얼마나 암호 화폐 산업 초기 단계 알 수 지난 서울 장충 체육관 개최 분산 경제 포럼 디코 노미 한경닷컴 인터뷰 스테판 러스트 비트코인 비즈니스 총괄 사진 은 현재 암호 화폐 상황 스테판 총괄 당시 구글 존재 전세계 인터넷 표준 프로토콜 역시 그 당시 표준 프로토콜 면서 비트코인 캐시 초기 단계 암호 화폐 생태계 표준 자리 잡 수 노력 고 강조 비트코인 전세계 위 암호 화폐 비트코인 캐시 암호 화폐 기업 글로벌 암호 화폐 전문 미디어 비트코인 뉴스 를 비롯 암호 화폐 관련 지갑 서비스 채굴 사업 플랫폼 사업 게임 사업 등 그 설명 비트코인 암호 화폐 지갑 약 활성화 주소 존재 매일 건 상당 활동 발생 지갑 앱 응용프로그램 도 평균 건 다운로드 비트코인 금융 서비스 질 데 집중 암호 화폐 지갑 앱 통해 이용자 암호 화폐 수탁 서비스 등 금융 관리 서비스 수 계획 한경닷컴 인터뷰 스테판 러스트 비트코인 비즈니스 총괄 개발자 육성 공 귀띔 비트코인 캐시 블록 체인 위 작동 앱 육성 위 비트코인 위해 개발자 수 도구모음 스테판 총괄 우리 개발자 프로토콜 위 앱 때 무엇 알 며 이제 개발자 비트코인 캐시 플랫폼 활용 스마트 계약 토큰 수 고 의미 부여 비트코인 연내 블록 체인 개발자 위 해커 톤 국내 개최 계획 스테판 총괄 개발자 비트코인 캐시 플랫폼 더 취지 라며 한국 세계 톱 안 암호 화폐 시장 개발자 우리 한국 고 말 비트코인 캐시 시세 한경닷컴 인터뷰 당일 무려 급등 그 기간 비트코인 약 오른 것 비 상승 폭 우리 비트코인 캐시 평가절하 생각 사람 비트코인 캐시 결제 수단 사용 고 역설 비트코인 캐시 다음 목표 개인 가치 전송 체계 표준 이 것 카카오 톡 보이 스톡 스카이프 등 사용 음성 인터넷 프로토콜 사례 과거 국제 통화 돈 통신사 제공 유선 망 통해 젠 대부분 인터넷 전화 를 활용 아주 비용 통화 수 것 스테판 총괄 전화 로 발전 것 암호 화폐 금융 일종 통화 인터넷 프로토콜 로 발전 형태 라며 금전 가치 자체 인터넷 실어 수 미래 암호 폐가 미래 금융 그 자체 것 김산 한경닷컴 기자 기사 제보 및 보도자료 한경닷컴 바로가기 모바일 한경 구독 신청 네이버 한국 경제 채널 구독 보기 한국 경제 무단 재 및 재 배포 금지']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from teanaps.nlp import SyntaxAnalyzer\n",
    "\n",
    "sa = SyntaxAnalyzer()\n",
    "\n",
    "tokenized_sentence_list = []\n",
    "\n",
    "PATH = \"teanaps/data/article_sample.txt\"\n",
    "POS_LIST = [\"NNG\", \"NNP\"]\n",
    "\n",
    "f = open(PATH, encoding=\"utf-8\")\n",
    "\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    col = line.split(\"\\t\")\n",
    "    label = col[0]\n",
    "    source = col[1]\n",
    "    datetime = col[2]\n",
    "    title = col[3]\n",
    "    content = col[4]\n",
    "    tagged_word_list = sa.parse(content)\n",
    "    tokenized_sentence = \"\"\n",
    "    for word, pos, loc in tagged_word_list:\n",
    "        if pos in POS_LIST:\n",
    "            tokenized_sentence += \" \" + word\n",
    "    tokenized_sentence_list.append(tokenized_sentence.strip())\n",
    "f.close()\n",
    "\n",
    "tokenized_sentence_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
