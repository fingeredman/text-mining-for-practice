하이퍼링크 기반 추론은 웹의 하이퍼텍스트 기능을 이용함으로써 접근성, 멀티미디어 기능,빠른 응답 시간, 서버의 안정성, 사용 및 업그레이드의 용이성, 플랫폼 독립성 등을 갖는 의료 전문가시스템을 구현할 수 있도록 해 준다. 전문가의 규칙에 따라 서로 하이퍼링크된 HTML문서들은 웹 서버에 적재된 후 추론 기능을 제공하게 되는데, 이러한 HTML문서들은 자체 개발한 WeBIS (Web-based Inference System)라는 GUI 기반 의사결정 그래프 편집 도구에 의해 자동으로 관리된다. 그럼에도 불구하고, 의료분야 전문가시스템이 다루는 규칙베이스의 크기가 큰 경우에 지식공학자가 이들 규칙들을 수작업으로 입력, 관리하는 것이 매우 어렵게 된다. 따라서, 본 연구에서는 고혈압 관리를 위 한 의사결정 그래프 자동 생성 시스템을 개발하였다. 이러한 일련의 과정을 통하여 본 연구에서는 하이퍼링크 기반 추론 기법을 이용하여 웹 기반 의료 전문가 시스템을 개발하는 방법론을 제시하였고, 그 응용으로써 빠른 응답속도와 안정성을 보이는 웹기반 고혈압 관리 시스템을 구현하였다.
급속한 인터넷의 확산으로 이제 웹은 단지 커뮤니케이션이나 홍보, 쇼핑의 수단뿐이 아닌 정보의 보급 및 창고로서의 역할이 더욱 커지고 있다. 또한, 과거의 웹 기반 기술인 하이퍼텍스트에 멀티미디어 기술이 접목되면서 하이퍼미디어 개념이 도입되어 텍스트 외의 이미지, 동영상, 사운드 등 다양한 형식의 미디어를 통해 정보를 접할 수 있게 되었다. 그러나, 이러한 정보공간에서 정보의 양이 기하급수적으로 증가함에 따라 웹 이용자들은 인지과부하(Cognitive overload)로 인하여 웹 상에서 방향감 상실, 정보공간에서 길 잃음 둥의 다양한 어려움을 겪고 있다. 이러한 문제를 해결하기 위해 많은 연구자들이 지속적으로 연구하고 있으며 그 중의 하나가 공간 개념(Spatial concept)을 적용한 공간 메타포(Spatial metaphor) 연구이다. 본 연구에서는 이러한 공간 메타포 개념을 이용하여 새로운 개념의 네비게이션 방식의 웹사이트를 개발하고 이를 Atomic-Map이라고 하였다. Davis 교수가 제안한 기술수용모형 (TAM) 모형을 이용하여 Atomic-Map의 사용성을 분석한 결과 Atomic-Map을 이용하여 정보공간에서 복잡한 네비게이션 하에서 발생할 수 있는 여러 가지 문제를 해결할 수 있음을 실증적으로 검증하였다.
적응 서비스는 사용자들이 접근하는 상황의 끊임없는 변화를 반영하기 위하여 필요하다. 상황-인식은사용자 상황에 기반하여 사용자와 기기간의 상호운용성을 지원함으로서 정보 획득과 수행을 증대시키는 기술이다. 본 연구는 유비쿼터스 컴퓨팅에서 상황-인식을 다루는데 필요한 미들웨어를 개발하는 것을 그 목적으로 하고 있다. 이를 수행하기 위해서 본 연구에서 개발한 미들fil어는 블루투스 무선통신기술을 사용하여 이동시의 이동노드를 인식하고, 컨텍스트 서버에서 획득한 상황에 따라서 적절한 수행모듈을 수행하는데 중요한 역할을 담당한다. 또한, 개발한 미들웨어를 사용한 상황 정보에 따라서 음악 연주 서비스를 제공하는 응용 프로그램을 개발하여 미들웨어의 유용성을 확인하였다.
오늘날 자원의 보고라 할 수 있는 웹에는 자연어로 표현된 텍스트와 테이블들로 구성된 무수히 많은 문서들이 존재하고 있다. 이러한 웹 문서들로부터 규칙을 습득하고 습득된 규칙과 웹 문서간의 일관성을 유지하기 위해, 본 논문에서는 확장형 규칙 표식 언어 (extensible Rule Markup Language, XRML) 체계를 개발하였다. XRML은 웹 페이지에 내재되어 있는 규칙을 식별하여 자동으로 정형화된 규칙을 생성할 수 있도록 지원하는 규칙 식별 표식 언어 (Rule Identification Markup Language, XRML)와 구조화된 규칙 표현을 위한 규칙 구조 표식 언어 (Rule Structure Markup Language)로 구성된다. 특히, RIML은 HTML안에 내재되어 있는 규칙을 HTML 문서에 직접 명시할 수 있도록 설계되었기 때문에, RIML을 통해 웹페이지에 있는 규칙들을 식별하고 이 식별된 규칙은 RSML으로 표현된 정형화된 규칙으로 자동 변환될 수 있다. 본 논문에서는 RIML의 설계 시 웹페이지로부터 규칙을 식별하는 과정에서 발생하는 공유되는 변수 (variables) 및 값 (values),생략된 어구 ,동의어와 같은 몇 가지 중요한 현상들을 발견하고 이를 해결하고자 하였다. 제안된 XRML 접근 방법의 성능을 측정하고자, 3개의 대표적인 온라인 서점인 Amazon.com, BarnesandNoble.com, Powells.com의 실제 웹페이지들로부터 배송 및 환불과 관련된 규칙을 습득하여 XRML의 효과를 측정하는 실험을 수행하였다. 실험 결과에 따르면, 웹페이지로부터 규칙은 $97.7\%$ 수식 이미지의 매우 높은 정확성을 가지고 습득되었으며, 생성된 규칙의 완전성은 $88.5\%$ 수식 이미지로 측정되어, XRML이 특정 주제에 관한 전문가 시스템을 구축하기 위해 웹페이지로부터 규칙을 추출할 때 효율적인 도구가 될 수 있음이 예시되었다.에서 1일 저장한 시금치보다 클로로필의 잔존율이 높아 $5^{\circ}C$ 수식 이미지에서 저장하는 것이 클로로필의 함량이 보존됨을 알 수 있었다. 시금치를 무포장, 폴리에틸렌백과 신문지로 포장하여 5, $20^{\circ}C$ 수식 이미지에서 1, 5일 저장하여 비교한 클로로필 함량은 $5^{\circ}C$ 수식 이미지에서 1, 5일간 저장한 경우는 폴리에틸렌백으로 포장한 시금치가 가장 많은 클로로필을 보유하였고, $20^{\circ}C$ 수식 이미지에서 1일 저장하였을 때는 폴리에틸렌백으로 포장한 시금치가 가장 높은 클로로필 함유량을 나타냈지만 저장 5일째에서는 무포장하여 저장한 시금치가 가장 높은 클로로필 함유량을 나타내었다. 결과적으로 시금치를 1일 저장할 때 폴리에틸렌백으로 포장하여 저장하는 것이 클로로필의 파괴를 최소화하는 방법이 될 수 있다. 위생관리 될 수 있는 급식 시스템의 구축도 필요하겠다. 식중독예방을 위한 방안으로 본 연구에 사용된 것과 같은 체계적인 모니터링 도구를 활용한 지속적인 자가 진단과 개선 및 시정이 철저하게 이루어져야 할 것이다. 본 연구의 제한점은 훈련된 연구원이 직접 현장 점검하는 방법을 채택하여 경제적, 시간적 한계로 인해 샘플수가 적었다. 그러므로 우리나라 집단급식소의 수에 비해 적은 수의 급식소를 대상으로 하여 대표성이 다소 결여되었다. 따라서 우리나라 집단급식소의 위생관리 실태를 완전하게 파악하기 위해서는 더 많은 연구자들이 급식소의 위생관리 실태조사에 참여하고, 이를 데이터베이스화하여 객관적으로 평가하는 작업이 필요할 것으로 사료된
본 논문은 시맨틱 검색 시스템에 관한 포괄적인 개념적 모델 제안과 실질적인 구현 사례를 제시한다. 제안된 시맨틱 검색 시스템은 개념적으로 3계층의 아키텍처 지식획득 계층, 지식표현 계층, 지식이용 계층으로 구성하여 설계 및 구현되었다. 지식획득(Knowledge acquisition) 계층은 다양한 소스(Source)의 콘텐츠(텍스트, 이미지, 멀티미디어등)로부터 시맨틱 메타데이터를 생성 및 저장하는 영역이다. 지식표현(Knowledge Representation) 계층은 온톨로지의 스키마와 인스턴스를 구축하고, 이러한 온톨로지 기반 질의 확장 등을 통해 시맨틱 검색을 처리하는 영역이다. 마지막으로 지식이용(Knowledge Utilization) 계층은 검색 이용자가 시맨틱 웹 언어 또는 온톨로지에 대한 지식이 없더라도 직관적으로 검색 질의(Query)를 입력하고 검색 결과를 확인할 수 있도록 구성하였다. 향후 제시된 시맨틱 검색 시스템은 기존 연구 수준의 시맨틱 검색 시스템을 상용화 수준으로 향상시킬 수 있는 계기가 될 것으로 기대된다.
인터넷을 통한 지식의 유통이 텍스트 형태의 지식뿐만 아니라 동영상 형태의 지식 유통으로 진화하고 있는 상황에서, UCC 지식 동영상을 공유하는 서비스가 나타나왔다. 본 논문은 동영상 UCC를 중심으로 지식 공유를 하는 'H' 사이트의 비즈니스 모델 평가 과정에서 수행된 고객 모델 분석사례를 보고한다. UCC 지식 동영상 공유 서비스는, 텍스트 형태의 지식공유 형태를 벗어나 새로운 형태인 동영상으로 지식을 공유한다는 점에서 불연속적 혁신의 형태를 띠며, 컨텐트 제공자와 컨텐트 소비자가 상호 매개되므로 직간접적 네트워크 효과가 일어나는 Value Network라는 특성을 가진다. 이렇게 불연속적 혁신이 일어나는 Value Network의 고객 모델 분석을 위해 첨단기술수용주기 이론인 캐즘 이론과 이를 심화 발전시킨 테크노그래픽스, 그리고 블루오션 전략에서 소개된 비고객 분석을 적용하여, UCC 지식 동영상 공유 사이트인 'H'사이트의 To-Be 고객 모델을 제안한다.
내용기반 이미지 검색은 색상, 질감 등의 이미지 자체의 자질들을 이용하여 검색하므로 텍스트 기반 이미지 검색의 객관성 부족과 모든 이미지에 사람이 주석을 달아야 하는 단점을 보완할 수 있는 이미지 검색 방법이다. 이러한 내용 기반 이미지 검색에서 사용되는 방식 중 SIM(Self-organizing Image browsing Map) 방식은 SOM 알고리즘을 이용하여 이미지들을 브라우징 가능한 그룹으로 맵핑하고 그 결과를 바탕으로 이미지를 검색하게 된다. 하지만 비슷한 이미지라 할지라도 이미지의 밝기, 피사체의 움직임 등에 의하여 색상 정보가 다르게 나타나게 되면 SOM 알고리즘의 학습 과정에서 유사한 이미지들을 그룹화한 노드를 BMU로 선택하지 못하고 떨어져 있는 다른 노드를 선택하게 된다. 이 경우 학습이 진행되면서 유사한 이미지들이 군집하는 과정을 거치지만 학습이 완료될 때까지 다른 유사 이미지들을 그룹화한 노드에 맵핑이 되지 못하는 경우가 발생한다. 그 결과, 검색 결과에 나타나지 못하여 적합 이미지 검색률이 낮아 질 수 있다. 따라서 본 논문에서는 HSV 색상모델을 이용하여 양자화하고 이미지의 색상 특징 벡터를 추출한 뒤 SOM 알고리즘을 이용하여 이미지들을 브라우징 가능한 그룹으로 맵핑한다. 이때 SIM 방식의 문제점인 유사 이미지가 따로 맵핑되어 적합 이미지 검색률이 낮아지는 것을 줄이기 위하여 SOM을 두 개의 층으로 구성한다. 첫 번째 층에서 이미지의 색상 자질을 이용하여 학습을 완료한 후, 학습이 완료된 첫 번째 층 맵의 각 노드들의 연결 가중치를 이용하여 두 번째 층에서 다시 한번 학습을 수행한다. 두 개의 층으로 학습이 완료된 두 번째 층의 SOM에 질의 이미지의 특징 벡터를 입력하여 BMU를 선택하고 BMU와 연결된 첫 번째 층의 노드를 최종 선택하여 이미지를 검색한다. 실험결과, 제안된 이미지 검색 방법이 기존의 이미지 검색 방법 보다 적합 이미지의 검색 성공률이 높은 것을 확인 할 수 있었다.
상황인식 컴퓨팅 사용자의 상황적이고 주관적 웰빙(SWB) 측정은 그에 맞는 정신건강 추천, 특히 대사증후군이나 우울증을 위한 추천에 매우 도움이 될 것이다. 현존하는 자가 진단식 측정법이나 자가 센싱 방법이 주관적 웰빙정보를 모니터링 하는데 제안되고 있음에도 불구하고 시의 적절한 서비스를 제공하지 못하여 상황인식 서비스로 쓰이기에는 부적합하다. 따라서 본 논문의 목적은 상황적이고 주관적 웰빙을 추정하는 방법을 제안하는 것이다. 이 방법은 사용자가 남기는 응답 글로부터 상황 자료를 획득하기 때문에 매우 적시적이며 따라서 그때마다의 감정 상태를 파악할 수 있다. 특히 본 연구에서는 온라인 대화나 기타 텍스트 기반의 의사소통에서 노출되는 분노심 등 부정적 감정에 관련된 감정동사와 정도 부사에 초점을 두어 측정한다. 제안된 상황적이고 주관적 웰빙 추정 방법을 기반으로 하여 웰빙 생활을 위한 추천 시스템을 개발하고자 한다. 이러한 아이디어의 실현가능성을 보이기 위하여 실제 운전자들을 대상으로 제안 방법이 얼마나 실제 감정을 잘 추론하는지에 대해 실험을 수행하였다.
특허의 중요성이 커짐에 따라 특허분석의 중요성 또한 점점 커지고 있다. 특허분석은 네트워크 기반 방법과 키워드 기반 방법으로 나눠지는데 네트워크 기반은 특허 내부에 존재하는 세부 기술정보에 대한 분석이 불가능하다는 단점이 있고 키워드 기반은 기술정보간의 상호관계를 규명하지 못한다는 단점이 있다. 기존에 제시된 네트워크 기반 특허 분석과 키워드 기반 분석의 한계를 극복하기 위해서 두 방법을 혼합한 방법으로서 본 연구에서는 특허 키워드 네트워크 기반 분석 방법론을 제시하였다. 본 연구에서는 LED 분야의 특허들을 대상으로 텍스트 마이닝을 통해 중요한 기술정보를 추출한 다음, 키워드 네트워크를 구축하고, 이를 대상으로 커뮤니티 네트워크 분석을 수행하였다. 분석 결과는 다음과 같다. 첫째, 특허 키워드 네트워크는 매우 낮은 밀도와 매우 높은 클러스터링 지수를 나타내었다. 밀도가 높다는 것은 LED 분야내 특허 키워드 네트워크 내 노드(키워드)들이 산발적으로 연결되어 있다는 것을 의미하며, 클러스터링 지수가 높다는 것은 해당 키워드 네트워크 내 노드, 즉 키워드들이 각각의 커뮤니티로 매우 긴밀하게 연결되어 있음을 나타낸다. 둘째, 특허 키워드 네트워크도 다른 지식네트워크와 마찬가지로 명확한 멱함수 분포를 따른다는 사실을 알 수 있었다. 이는 기존에 활발히 연구, 활용되어 많은 연결고리를 갖고 있는 특허개념(키워드)수록 지속적으로 다른 연구자들에 의해 선택되고 이 키워드를 바탕으로 새로운 키워드들이 연결되어서 이들 키워드간의 조합으로 새로운 기술이 발명된다는 것이다. 셋째, 특허가 개발될 때 특정 분야에 유입된 키워드 중 새로운 링크가 생긴 키워드의 대부분이 기존에 연결되어 있던 커뮤니티 내의 키워드들과 결합되어 새로운 특허 개념을 구성한다는 사실을 발견하였다. 이러한 사실은 단기(4년) 장기(10년) 두 기간 모두 동일하게 나타났다. 나아가 본 연구에서 제시한 방법론을 통해 도출된 특허 키워드 조합 정보를 활용하면 미래에 어떤 개념들이 합쳐져서 새로운 특허 단위로 만들어 질지 가늠해볼 수 있고, 새로운 특허를 개발할 때 참고할 수 있는 유용한 정보로 활용할 수 있다.
최근 스마트폰의 등장으로 인해 사용자들은 시간과 공간의 제약 없이 스마트폰을 이용한 새로운 의사소통의 방법을 경험하고 있다. 이러한 스마트폰은 고화질의 컬러화면, 고해상도 카메라, 실시간 3D 가속그래픽과 다양한 센서(GPS와 Digital Compass) 등을 제공하고 있으며, 다양한 센서들은 사용자들(개발자, 일반 사용자)로 하여금 이전에 경험하지 못했던 서비스를 경험할 수 있도록 지원하고 있다. 그 중에서 모바일 증강현실은 스마트폰의 다양한 센서들을 이용하여 개발할 수 있는 대표적인 서비스 중 하나이며, 이러한 센서들을 이용한 다양한 방법의 모바일 증강현실 연구들이 활발하게 진행되고 있다. 모바일 증강현실은 크게 위치 정보 기반의 서비스와 내용 기반 서비스로 구분할 수 있다. 위치 정보 기반의 서비스는 구현이 쉬운 장점이 있으나, 증강되는 정보의 위치가 실제의 객체의 정확한 위치에 증강되는 정보가 제공되지 않는 경우가 발생하는 단점이 존재한다. 이와 반대로, 내용 기반 서비스는 정확한 위치에 증강되는 정보를 제공할 수 있으나, 구현 및 데이터베이스에 존재하는 이미지의 양에 따른 검색 속도가 증가하는 단점이 존재한다. 본 논문에서는 위치 정보 기반의 서비스와 내용기반의 서비스의 장점들을 이용한 방법으로, 스마트폰의 다양한 센서(GPS, Digital Compass)로 부터 수집된 정보를 이용하여 데이터베이스의 탐색 범위를 줄이고, 탐색 범위에 존재하는 이미지들의 특징 정보를 기반으로 실제의 랜드마크를 인식하고, 인식한 랜드마크의 정보를 링크드 오픈 데이터(LOD)에서 검색하여 해당 정보를 제공하는 랜드마크 가이드 시스템을 제안한다. 제안하는 시스템은 크게 2개의 모듈(랜드마크 탐색 모듈과 어노테이션 모듈)로 구성되어있다. 첫 번째로, 랜드마크 탐색 모듈은 스마트폰으로 인식한 랜드마크(건물, 조형물 등)에 해당하는 정보들을 (텍스트, 사진, 비디오 등) 링크드 오픈 데이터에서 검색하여 검색된 결과를 인식한 랜드마크의 정확한 위치에 정보를 제공하는 역할을 한다. 스마트폰으로부터 입력 받은 이미지에서 특징점 추출을 위한 방법으로는 SURF 알고리즘을 사용했다. 또한 실시간성을 보장하고 처리 속도를 향상 시키기 위한 방법으로는 입력 받은 이미지와 데이터베이스에 있는 이미지의 비교 연산을 수행할 때 GPS와 Digital Compass의 정보를 사용하여 그리드 기반의 클러스터링을 생성하여 탐색 범위를 줄임으로써, 이미지 검색 속도를 향상 시킬 수 있는 방법을 제시하였다. 두 번째로 어노테이션 모듈은 사용자들의 참여에 의해서 새로운 랜드마크의 정보를 링크드 오픈 데이터에 추가할 수 있는 기능을 제공한다. 사용자들은 키워드를 이용해서 링크드 오픈 데이터로에서 관련된 주제를 검색할 수 있으며, 검색된 정보를 수정하거나, 사용자가 지정한 랜드마크에 해당 정보를 표시할 수 있도록 지정할 수 있다. 또한, 사용자가 지정하려고 하는 랜드마크에 대한 정보가 존재하지 않는다면, 사용자는 랜드마크의 사진을 업로드하고, 새로운 랜드마크에 대한 정보를 생성하는 기능을 제공한다. 이러한 과정은 시스템이 카메라로부터 입력 받은 대상(랜드마크)에 대한 정확한 증강현실 컨텐츠를 제공하기 위해 필요한 URI를 찾는데 사용되며, 다양한 각도의 랜드마크 사진들을 사용자들에 의해 협업적으로 생성할 수 있는 환경을 제공한다. 본 연구에서 데이터베이스의 탐색 범위를 줄이기 위해서 랜드마크의 GPS 좌표와 Digital Compass의 정보를 이용하여 그리드 기반의 클러스터링 방법을 제안하여, 그 결과 탐색시간이 기존에는 70~80ms 걸리는 반면 제안하는 방법을 통해서는 18~20ms로 약 75% 정도 향상된 것을 확인할 수 있었다. 이러한 탐색시간의 감소는 전체적인 검색시간을 기존의 490~540ms에서 438~480ms로 약 10% 정도 향상된 것을 확인하였다.
최근에 들어 많은 관심과 인기 속에 사용되고 있는 스마트폰은 클라우드 컴퓨팅의 편재적 기능성을 접목하여 즉각적인 지식의 획득에 효과적으로 활용될 수 있다. 또한 지식의 주제어 또는 명칭을 자동으로 파악하여 해당 지식을 저장할 수 있다면 전반적인 지식 획득 과정이 자동화될 수 있다. 본 논문은 텍스트마이닝 기반 주제어 추출 기술과 클라우드 스토리지 기반 스마트폰을 접목하여 지식이 발생되는 지점 및 시점에 즉각적으로 해당 지식을 획득할 수 있는 학제적 방안을 제시한다. 이를 위해 스마트폰은 지식이 포함된, 지식소유자의 대화를 녹음하는 역할을 함과 동시에 지식소유자의 대화의 내용을 부가적으로 특성화 할 수 있는 상황정보를 채취할 수 있는 센서의 역할을 수행한다. 또한 기계학습 알고리듬 중 텍스트마이닝분야에서 우수한 성능을 나타내는 것으로 알려진 Support Vector Machine 알고리듬을 사용하여 해당 대화의 주제어를 추출한다. 파악된 주제어와 상황정보를 연관시켜 일종의 비즈니스 규칙을 생성할 수 있으며, 최종적으로 규칙, 주제어, 상황정보, 그리고 문서화된 대화를 종합하여 하나의 지식을 자동으로 획득할 수 있다.
누구나 뉴스와 주가 사이에는 밀접한 관계를 있을 것이라 생각한다. 그래서 뉴스를 통해 투자기회를 찾고, 투자이익을 얻을 수 있을 것으로 기대한다. 그렇지만 너무나 많은 뉴스들이 실시간으로 생성 전파되며, 정작 어떤 뉴스가 중요한지, 뉴스가 주가에 미치는 영향은 얼마나 되는지를 알아내기는 쉽지 않다. 본 연구는 이러한 뉴스들을 수집 분석하여 주가와 어떠한 관련이 있는지 분석하였다. 뉴스는 그 속성상 특정한 양식을 갖지 않는 비정형 텍스트로 구성되어있다. 이러한 뉴스 컨텐츠를 분석하기 위해 오피니언 마이닝이라는 빅데이터 감성분석 기법을 적용하였고, 이를 통해 주가지수의 등락을 예측하는 지능형 투자의사결정 모형을 제시하였다. 그리고, 모형의 유효성을 검증하기 위하여 마이닝 결과와 주가지수 등락 간의 관계를 통계 분석하였다. 그 결과 뉴스 컨텐츠의 감성분석 결과값과 주가지수 등락과는 유의한 관계를 가지고 있었으며, 좀 더 세부적으로는 주식시장 개장 전 뉴스들과 주가지수의 등락과의 관계 또한 통계적으로 유의하여, 뉴스의 감성분석 결과를 이용해 주가지수의 변동성 예측이 가능할 것으로 판단되었다. 이렇게 도출된 투자의사결정 모형은 여러 유형의 뉴스 중에서 시황 전망 해외 뉴스가 주가지수 변동을 가장 잘 예측하는 것으로 나타났고 로지스틱 회귀분석결과 분류정확도는 주가하락 시 70.0%, 주가상승 시 78.8%이며 전체평균은 74.6%로 나타났다.
본 연구는 경향신문, 한겨레, 동아일보 세 개의 신문기사가 가지고 있는 내용 및 논조에 어떠한 차이가 있는지를 객관적인 데이터를 통해 제시하고자 시행되었다. 본 연구는 텍스트 마이닝 기법을 활용하여 신문기사의 키워드 단순빈도 분석과 Clustering, Classification 결과를 분석하여 제시하였으며, 경제, 문화 국제, 사회, 정치 및 사설 분야에서의 신문사 간 차이점을 분석하고자 하였다. 신문기사의 문단을 분석단위로 하여 각 신문사의 특성을 파악하였고, 키워드 네트워크로 키워드들 간의 관계를 시각화하여 신문사별 특성을 객관적으로 볼 수 있도록 제시하였다. 신문기사의 수집은 신문기사 데이터베이스 시스템인 KINDS에서 2008년부터 2012년까지 해당 주제로 주제어 검색을 하여 총 3,026개의 수집을 하였다. 수집된 신문기사들은 불용어 제거와 형태소 분석을 위해 Java로 구현된 Lucene Korean 모듈을 이용하여 자연어 처리를 하였다. 신문기사의 내용 및 논조를 파악하기 위해 경향신문, 한겨레, 동아일보가 정해진 기간 내에 일어난 특정 사건에 대해 언급하는 단어의 빈도 상위 10위를 제시하여 분석하였고, 키워드들 간 코사인 유사도를 분석하여 네트워크 지도를 만들었으며 단어들의 네트워크를 통해 Clustering 결과를 분석하였다. 신문사들마다의 논조를 확인하기 위해 Supervised Learning 기법을 활용하여 각각의 논조에 대해 분류하였으며, 마지막으로는 분류 성능 평가를 위해 정확률과 재현률, F-value를 측정하여 제시하였다. 본 연구를 통해 문화 전반, 경제 전반, 정치분야의 통합진보당 이슈에 대한 신문기사들에 전반적인 내용과 논조에 차이를 보이고 있음을 알 수 있었고, 사회분야의 4대강 사업에 대한 긍정-부정 논조에 차이가 있음을 발견할 수 있었다. 본 연구는 지금까지 연구되어왔던 한글 신문기사의 코딩 및 담화분석 방법에서 벗어나, 텍스트 마이닝 기법을 활용하여 다량의 데이터를 분석하였음에 의미가 있다. 향후 지속적인 연구를 통해 분류 성능을 보다 높인다면, 사람들이 뉴스를 접할 때 그 뉴스의 특정 논조 성향에 대해 우선적으로 파악하여 객관성을 유지한 채 정보에 접근할 수 있도록 도와주는 신뢰성 있는 툴을 만들 수 있을 것이라 기대한다.
최근 다양한 소셜미디어를 통해 생성되는 비정형 데이터의 양은 빠른 속도로 증가하고 있으며, 이를 저장, 가공, 분석하기 위한 도구의 개발도 이에 맞추어 활발하게 이루어지고 있다. 이러한 환경에서 다양한 분석 도구를 통해 텍스트 데이터를 분석함으로써, 기존의 정형 데이터 분석을 통해 해결하지 못했던 이슈들을 해결하기 위한 많은 시도가 이루어지고 있다. 특히 트위터나 페이스북을 통해 실시간에 근접하게 생산되는 글들과 수많은 인터넷 사이트에 게시되는 다양한 주제의 글들은, 방대한 양의 텍스트 분석을 통해 많은 사람들의 의견을 추출하고 이를 통해 향후 수익 창출에 기여할 수 있는 새로운 통찰을 발굴하기 위한 움직임에 동기를 부여하고 있다. 뉴스 데이터에 대한 오피니언 마이닝을 통해 주가지수 등락 예측 모델을 제안한 최근의 연구는 이러한 시도의 대표적 예라고 할 수 있다. 우리가 여러 매체를 통해 매일 접하는 뉴스 역시 대표적인 비정형 데이터 중의 하나이다. 이러한 비정형 텍스트 데이터를 분석하는 오피니언 마이닝 또는 감성 분석은 제품, 서비스, 조직, 이슈, 그리고 이들의 여러 속성에 대한 사람들의 의견, 감성, 평가, 태도, 감정 등을 분석하는 일련의 과정을 의미한다.  이러한 오피니언 마이닝을 다루는 많은 연구는, 각 어휘별로 긍정/부정의 극성을 규정해 놓은 감성사전을 사용하며, 한 문장 또는 문서에 나타난 어휘들의 극성 분포에 따라 해당 문장 또는 문서의 극성을 산출하는 방식을 채택한다. 하지만 특정 어휘의 극성은 한 가지로 고유하게 정해져 있지 않으며, 분석의 목적에 따라 그 극성이 상이하게 나타날 수도 있다. 본 연구는 특정 어휘의 극성은 한 가지로 고유하게 정해져 있지 않으며, 분석의 목적에 따라 그 극성이 상이하게 나타날 수도 있다는 인식에서 출발한다. 동일한 어휘의 극성이 해석하는 사람의 입장에 따라 또는 분석 목적에 따라 서로 상이하게 해석되는 현상은 지금까지 다루어지지 않은 어려운 이슈로 알려져 있다. 구체적으로는 주가지수의 상승이라는 한정된 주제에 대해 각 관련 어휘가 갖는 극성을 판별하여 주가지수 상승 예측을 위한 감성사전을 구축하고, 이를 기반으로 한 뉴스 분석을 통해 주가지수의 상승을 예측한 결과를 보이고자 한다.
소셜 네트워크는 사용자들의 공통된 관심사, 경험, 그리고 일상 생활들을 함께 공유하기 위해 소셜 네트워크 상 사람들을 서로 연결시켜주는 거대한 커뮤니케이션 플랫폼이다. 소셜 네트워크상의 사용자들은 포스팅, 댓글, 인스턴스 메시지, 게임, 소셜 이벤트 외에도 다양한 애플리케이션을 통해 다른 사용자들과 소통하고 개인 정보 관리하는데 많은 시간을 소비한다. 소셜 네트워크 상의 풍부한 사용자 정보는 추천시스템이 추천 성능을 향상시키기 위해 필요한 큰 잠재력이 되었다. 대부분의 사용자들은 어떤 상품을 구매하기 전 가까운 관계이거나 같은 성향을 가진 사람들의 의견을 반영하여 의사 결정을 하게 된다. 그러므로 소셜 네트워크에서의 사용자 관계는 추천시스템을 위한 사용자 선호도 예측을 효율적으로 높이는데 중요한 요소라 할 수 있다. 일부 연구자들은 소셜 네트워크에서의 사용자와 다른 사용자들 사이의 상호작용 즉, 소셜 관계(social relationship)와 같은 소셜 데이터가 추천시스템에서 추천의 질에 어떠한 영향을 미치는가를 연구하고 있다. 추천시스템은 아마존, 이베이, Last.fm과 같은 큰 규모의 전자상거래 사이트 또한 채택하여 사용되는 시스템으로, 추천시스템을 위한 방법으로는 협업적 여과 방법과 내용 기반 여과 방법이 있다. 협업적 여과 방법은 사용자들의 선호도 학습에 의해 사용자가 아직 평가하지 않은 아이템 중 선호할 수 있는 아이템을 정확하게 제안하기 위한 추천시스템 방법 중 하나이다. 협업적 여과는 사용자들의 데이터에 초점을 맞춘 방법으로 유사한 배경과 선호도를 가지는 사용자들로부터 정보를 수집하여 사용자들의 선호도 예측을 자동으로 발생시킨다. 특히 협업적 여과는 근접한 이웃 사용자들에 의해서 목적 사용자가 선호할 수 있는 아이템을 제시하는 것으로 유사한 이웃 사용자를 찾는 것이 중요하다. 좋은 이웃 사용자 발견은 사용자와 아이템을 고려하는 방법이 일반적이다. 각 사용자는 아이템 즉, 영화, 상품, 책 등에 자신의 선호도를 나타내기 위하여 평가 값을 입력하고, 시스템은 이를 바탕으로 사용자-평가 행렬을 구축한다. 이 사용자-평가 행렬은 목적 사용자와 유사하게 아이템을 평가한 사용자 그룹을 찾기 위한 것으로, 목적 사용자가 아직 평가하지 않은 아이템에 대하여 사용자-평가 매트릭스를 통해 그 평가 값을 예측한다. 현재 이 협업적 여과 방법은 전자상거래와 정보 검색에서 적용되어 개인화 시스템에 효율적으로 사용되고 있다. 하지만 초기 사용자 문제, 데이터 희박성 문제와 확장성 그리고 예측 정확도 향상 등 해결해야 할 과제가 여전히 남아 있다. 이러한 문제들을 해소하기 위해 많은 연구자들은 하이브리드, 신뢰기반, 소셜 네트워크 기반 협업적 여과와 같은 다양한 방법을 제안하였다. 본 논문에서는 전통적인 협업적 여과 방식의 예측 정확도와 추천 성능을 향상시키기 위해 소셜 네트워크에 존재하는 소셜 관계를 이용한 협업적 여과 시스템을 제안한다. 소셜 관계는 소셜 네트워크 서비스 중 하나인 페이스북 사용자들이 남긴 포스팅과 사용자의 소셜 네트워크 친구와 의견 교류 중 남긴 코멘트와 같은 사용자 행동을 기반으로 정의된다. 소셜 관계를 구축하기 위해 소셜 네트워크 사용자의 포스팅과 댓글을 추출하고, 추출된 텍스트에 불용어 및 특수 기호 제거와 스테밍 등 전처리를 수행하였다. 특징 벡터는 TF-IDF를 이용하여 전처리된 텍스트에 나타난 각 단어에 대한 특징 점수를 계산함으로써 구축된다. 본 논문에서 이웃 사용자를 결정하기 위해 사용되는 사용자 간 유사도는 특징 벡터를 이용한 사용자 행동 유사도와 사용자의 영화 평가를 기반으로 한 전통적 방법의 유사도를 결합하여 계산된다. 제안하는 시스템은 목표 사용자와 제안한 방법을 통해 결정된 이웃 사용자 집단을 기반으로 목표 사용자가 평가하지 않은 아이템에 대한 선호도를 예측하고 Top-N 아이템을 선별하여 사용자에게 아이템을 추천하게 된다. 본 논문에서 제안하는 방법을 확인하고 평가하기 위하여 IMDB에서 제공하는 영화 정보 기반으로 영화 평가 시스템을 구축하였다. 예측 정확도를 평가하기 위해 MAE 값을 이용하여 제안하는 알고리즘이 얼마나 정확한 추천을 수행하는지에 대한 예측 정확도를 측정하였다. 그리고 정확도, 재현율 및 F1값 등을 활용하여 시스템의 성능을 평가하였으며, 시스템의 추천 품질은 커버리지를 이용하여 평가되었다. 실험 결과로부터 본 논문에서 제안한 시스템이 보다 더 정확하고 좋은 성능으로 사용자에게 아이템을 추천하는 것을 볼 수 있었다. 특히 소셜 네트워크에서 사용자 행동을 기반으로 한 소셜 관계를 이용함으로써 추천 정확도를 6% 향상시킴을 보였다. 또한 벤치마크 알고리즘과의 성능비교 실험을 통해 7% 향상된 추천 성능의 결과를 보여준다. 그러므로 사용자의 행동으로부터 관찰된 소셜 관계를 CF방법과 결합한 제안한 방법이 정확한 추천시스템을 위해 유용하며, 추천시스템의 성능과 품질을 향상시킬 수 있음을 알 수 있다.
기업 경영에 있어서 고객의 소리(VOC)는 고객 만족도 향상 및 기업의사결정에 매우 중요한 정보이다. 이는 비단 기업뿐만 아니라 대고객, 대민원 업무를 처리하는 모든 조직에 있어서도 동일하다. 때문에 최근에는 기업뿐만 아니라 공공, 의료, 금융, 교육기관 등 거의 모든 조직이 VOC를 수집하여 활용하고 있다. 이러한 VOC는 방문, 전화, 우편, 인터넷게시판, SNS 등 다양한 채널을 통해 전달되지만, 막상 이를 제대로 활용하기는 쉽지 않다. 왜냐하면, 고객이 매우 감정적인 상태에서 고객의 주관적 의사를 음성 또는 문자로 표출하기 때문에 그 형식이나 내용이 정형화되어 있지 않고 저장하기도 어려우며 또한 저장하더라도 매우 방대한 분량의 비정형 데이터로 남기 때문이다. 본 연구는 이러한 비정형 VOC 데이터를 자동으로 분류하고 VOC의 유형과 극성을 판별할 수 있는 오피니언 마이닝 기반의 지능형 VOC 분석 시스템을 제안하였다. 또한 VOC 오피니언 분석의 기준이 되는 주제지향 감성사전 개발 프로세스와 각 단계를 구체적으로 제시하였다. 그리고 본 연구에서 제시한 시스템의 효용성을 검증하기 위하여 의료기관 홈페이지에서 수집한 4,300여건의 VOC 데이터를 이용하여 병원에 특화된 감성어휘와 감성극성값을 도출하여 감성사전을 구축하고 이를 통해 구현된 VOC분류 모형의 정확도를 비교하는 실험을 수행하였다. 그 결과 “칭찬, 친절함, 감사, 무사히, 잘해, 감동, 미소” 등의 어휘는 매우 높은 긍정 오피니언 값을 가지며, “퉁명, 뭡니까, 말하더군요, 무시하는” 등의 어휘들은 강한 부정의 극성값을 가지고 있음을 확인하였다. 또한 VOC의 오피니언 분류 임계값이 -0.50일 때 가장 높은 분류 예측정확도 77.8%를 검증함 으로써 오피니언 마이닝 기반의 지능형 VOC 분석시스템의 유효성을 확인하였다. 그러므로 지능형 VOC 분석시스템을 통해 VOC의 실시간 자동 분류 및 대응 우선순위를 도출하여 고객 민원에 대해 신속히 대응한다면, VOC 전담 인력을 효율적으로 운용하면서도 고객 불만을 초기에 해소할 수 있는 긍정적 효과를 기대해 볼 수 있을 것이다. 또한 VOC 텍스트를 분석하고 활용할 수 있는 오피니언 마이닝 모형이라는 새로운 시도를 통해 향후 다양한 분석과 실용 프레임워크의 기틀을 제공할 수 있을 것으로 기대된다.
인터넷의 발달과 SNS의 등장으로 정보흐름의 방식이 크게 바뀌었다. 이러한 변화에 따라 소셜 미디어가 급부상하고 있으며 소셜 미디어와 비디오 콘텐츠가 융합된 소셜 TV, 소셜 뉴스의 중요성이 강조되고 있다. 이러한 환경 속에서 사용자들은 단순히 콘텐츠를 탐색만 하는 것이 아니라 같은 콘텐츠를 이용하고 있는 친구들이나 지인들과 콘텐츠에 대한 정보나 경험들을 공유하고 더 나아가 새로운 콘텐츠를 만들어내기도 한다. 하지만 기존의 소셜 뉴스에서는 이러한 사용자들의 특성을 반영해 주지 못하고 있다. 특히 이용자들의 참여성만을 고려하고 있어서 서비스간의 차별화가 어렵고 뉴스 콘텐츠에 대한 정보나 경험 공유 시 컨텍스트 공유가 어렵다는 문제가 있다. 이를 해결하기 위해 본 논문에서는 뉴스를 내용별로 분할하고 분할된 뉴스에서 추출된 시간 종속적인 메타데이터를 제공하는 프레임워크를 제안한다. 제안하는 프레임워크에서는 스토리 분할 방법을 이용하여 뉴스 대본을 내용별로 분할한다. 또한 뉴스 전체내용을 대표하는 태그, 분할된 뉴스를 나타내는 서브 태그, 분할된 뉴스가 비디오에서 시작하는 위치 즉, 시간 종속적인 메타데이터를 제공한다. 소셜 뉴스 이용자들에게 시간 종속적인 메타데이터를 제공한다면 이용자들은 전체의 뉴스 내용 중에 자신이 원하는 부분만을 탐색 할 수 있으며 이 부분에 대한 견해를 남길 수 있다. 그리고 뉴스의 전달이나 의견 공유 시 메타데이터를 함께 전달함으로써 전달하고자 하는 내용에 바로 접근이 가능하며 프레임워크의 성능은 추출된 서브 태그가 뉴스의 실제 내용을 얼마나 잘 나타내 주느냐에 따라 결정된다. 그리고 서브 태그는 스토리 분할의 정확성과 서브 태그를 추출하는 방법에 따라 다르게 추출된다. 이 점을 고려하여 의미적 유사도 기반의 스토리 분할 방법을 프레임워크에 적용하였고 벤치마크 알고리즘과 성능 비교 실험을 수행하였으며 분할된 뉴스에서 추출된 서브 태그들과 실제 뉴스의 내용을 비교하여 서브 태그들의 정확도를 분석하였다. 결과적으로 의미적 유사도를 고려한 스토리 분할 방법이 더 우수한 성능을 보였으며 추출된 서브 태그들도 컨텍스트와 관련된 단어들이 추출 되었다.
최근 다양한 정보채널들의 등장으로 인해 빅데이터에 대한 관심이 높아지고 있다. 이와 같은 현상의 가장 큰 원인은, 스마트기기의 사용이 활성화 됨에 따라 사용자가 생성하는 텍스트, 사진, 동영상과 같은 비정형 데이터의 양이 크게 증가하고 있는 것에서 찾을 수 있다. 특히 비정형 데이터 중에서도 텍스트 데이터의 경우, 사용자들의 의견 및 다양한 정보를 명확하게 표현하고 있다는 특징이 있다. 따라서 이러한 텍스트에 대한 분석을 통해 새로운 가치를 창출하고자 하는 시도가 활발히 이루어지고 있다. 텍스트 분석을 위해 필요한 기술은 대표적으로 텍스트 마이닝과 오피니언 마이닝이 있다. 텍스트 마이닝과 오피니언 마이닝은 모두 텍스트 데이터를 입력 데이터로 사용할 뿐 아니라 파싱, 필터링 등 자연어 처리 기술을 사용한다는 측면에서 많은 공통점을 갖고 있다. 특히 문서의 분류 및 예측에 있어서 목적 변수가 긍정 또는 부정의 감성을 나타내는 경우에는, 전통적 텍스트 마이닝, 또는 감성사전 기반의 오피니언 마이닝의 두 가지 방법론에 의해 오피니언 분류를 수행할 수 있다. 따라서 텍스트 마이닝과 오피니언 마이닝의 특징을 구분하는 가장 명확한 기준은 입력 데이터의 형태, 분석의 목적, 분석의 결과물이 아닌 감성사전의 사용 여부라고 할 수 있다. 따라서 본 연구에서는 오피니언 분류라는 동일한 목적에 대해 텍스트 마이닝과 오피니언 마이닝을 각각 사용하여 예측 모델을 수립하는 과정을 비교하고, 결과로 도출된 모델의 예측 정확도를 비교하였다. 오피니언 분류 실험을 위해 영화 리뷰 2,000건에 대한 실험을 수행하였으며, 실험 결과 오피니언 마이닝을 통해 수립된 모델이 텍스트 마이닝 모델에 비해 전체 구간의 예측 정확도 평균이 높게 나타나고, 예측의 확실성이 강한 문서일수록 예측 정확성이 높게 나타나는 일관적인 성향을 나타내는 등 더욱 바람직한 특성을 보였다.
공공 서비스의 수출의 경우 수출 절차와 대상 선정에 따른 다양한 문제가 발생하며, 공공 서비스 수출 플랫폼은 이러한 문제점들을 해결하기 위하여 사용자 중심의 유연하고, 개방형 구조의 디지털 생태계를 조성할 수 있도록 구현되어야 한다. 또한 공공서비스의 수출은 다수의 이해당사자가 참여하고 여러 단계의 과정을 거쳐야 하므로 사용자의 이해 종류와 탐색?컨설팅?협상?계약 등 수출 프로세스 단계별로 맞춤형 플랫폼 서비스 제공이 필수적이다. 이를 위해서 플랫폼 구조는 도메인과 정보의 정의 및 공유는 물론 지식화를 지원할 수 있어야 한다. 본 논문에서는 공공서비스 수출을 지원하는 플랫폼을 위한 온톨로지 모형을 제안한다. 서비스 플랫폼의 핵심 엔진은 시뮬레이터 모듈이며 시뮬레이터 모듈에서는 온톨로지를 사용하여 수출 비즈니스의 여러 컨텍스트들을 파악하고 정의하여 다른 모듈들과 공유하게 된다. 온톨로지는 공유 어휘를 통하여 개념들과 그들 간의 관계를 표현할 수 있으므로 특정 영역에서 구조적인 틀을 개발하기 위한 메타 정보를 구성하는 효과적인 도구로 잘 알려져 있다. 공공서비스 수출 플랫폼을 위한 온톨로지는 서비스, 요구사항, 환경, 기업, 국가 등 5가지 카테고리로 구성되며 각각의 온톨로지는 요구분석과 사례 분석을 통하여 용어를 추출하고 온톨로지의 식별과 개념적 특성을 반영하는 구조로 설계한다. 서비스 온톨로지는 목적효과, 요구조건, 활동, 서비스 분류 등으로 구성되며, 요구사항 온톨로지는 비즈니스, 기술, 제약으로 구성 된다. 환경 온톨로지는 사용자, 요구조건, 활동으로, 기업 온톨로지는 활동, 조직, 전략, 마케팅, 시간으로 구성되며, 국가 온톨로지는 경제, 사회기반시설, 법, 제도, 관습, 인프라, 인구, 위치, 국가전략 등으로 구성된다. 수출 대상 서비스와 국가의 우선순위 리스트가 생성되면 갭(gap) 분석과 매칭 알고리즘 등의 시뮬레이터를 통하여 수출기업과 수출지원 프로그램과의 시스템적 연계가 이루어진다. 제안하는 온톨로지 모형 기반의 공공서비스 수출지원 플랫폼이 구현되면 이해당사자 모두에게 도움이 되며 특히 정보 인프라와 수출경험이 부족한 중소기업에게 상대적으로 더 큰 도움이 될 것이다. 또한 개방형 디지털 생태계를 통하여 이해당사자들이 정보교환, 협업, 신사업 기획 등의 기회를 만들 수 있을 것으로 기대한다.
빅데이터의 중요성에 대한 인식이 확산되고, 관련한 기술이 발전됨에 따라, 최근에는 빅데이터의 처리와 분석의 결과를 어떻게 시각화할 것인지가 매우 관심 받는 주제로 부각되고 있다. 이는 분석된 결과를 보다 명확하고 효과적으로 전달하는 데에 있어서 데이터의 시각화가 매우 효과적인 방법이기 때문이다. 시각화는 분석 시스템과 사용자가 소통하기 위한 하나의 그래픽 사용자 인터페이스(GUI)를 담당하는 역할을 한다. 통상적으로 이러한 GUI 부분은 데이터의 처리나 분석의 결과와 독립될 수록 시스템의 개발과 유지보수가 용이하며, MVC(Model-View-Controller)와 같은 디자인 패턴의 적용을 통해 GUI와 데이터 처리 및 관리 부분 간의 결합도를 최소화하는 것이 중요하다.  한편 빅데이터는 크게 정형 데이터와 비정형 데이터로 구분할 수 있는데 정형 데이터는 시각화가 상대적으로 용이한 반면, 비정형 데이터는 시각화를 구현하기가 복잡하고 다양하다. 그럼에도 불구하고 비정형 데이터에 대한 분석과 활용이 점점 더 확산됨에 따라, 기존의 전통적인 정형 데이터를 위한 시각화 도구들의 한계를 벗어나기 위해 각각의 시스템들의 목적에 따라 고유의 방식으로 시각화 시스템이 구축되는 현실에 직면해 있다.  더욱이나 현재 비정형 데이터 분석의 대상 중 대부분을 차지하고 있는 텍스트 데이터의 경우 언어 분석, 텍스트 마이닝, 소셜 네트워크 분석 등 적용 기술이 매우 다양하여 하나의 시스템에 적용된 시각화 기술을 다른 시스템에 적용하는 것이 용이하지 않다. 이는 현재의 텍스트 분석 결과에 대한 정보 모델이 서로 다른 시스템에 적용될 수 있도록 설계되지 못하는 경우가 많기 때문이다. 본 연구에서는 이러한 문제를 해결하기 위하여 다양한 텍스트 데이터 분석 사례와 시각화 사례들의 공통적 구성 요소들을 식별하여 표준화된 정보 모델인 텍스트 데이터 시각화 모델을 제시하고, 이를 통해 시각화의 GUI 부분과 연결할 수 있는 시스템 모델로서의 시각화 프레임워크인 TexVizu를 제안하고자 한다.
대부분의 인터넷 쇼핑몰은 자사 고객의 관심 분야를 파악하고 이를 상품 추천에 효과적으로 활용하기 위해 많은 노력을 기울이고 있다. 하지만 고객이 회원 가입 시 직접 입력한 개인 정보는 신뢰하기가 어렵고, 고객의 구매 패턴을 통해 파악한 관심 분야 정보는 자사 사이트 내에 진입한 이후에만 보인 한정된 패턴이라는 측면에서 해당 고객의 다양한 관심 분야를 제대로 나타낸다고 보기 어렵다. 이러한 한계를 극복하기 위해 본 연구에서는 고객의 평소 인터넷 사용 기록을 통해 최근 방문 사이트들의 주제를 분석함으로써, 고객의 실제 관심 분야를 파악할 수 있는 방안을 제시하였다. 또한 토픽 분석을 통해 각 사이트의 주제를 도출하고 도출된 주제를 다시 동시 방문자 관점에서 군집화 함으로써, 고객 관점에서 의미가 있는 상위 수준의 새로운 테마를 발굴하기 위한 방법론을 제안하였다. 연구의 특징은 유사주제 중심의 군집화라는 기존 연구와는 달리 사용자 관점의 관심주제 중심 군집화라 할 수 있다. 향후 사용자 중심의 카테고리 설계를 비롯한 새로운 관점의 고객군 정의 등 보다 높은 차원의 마케팅 전략 수립에 활용이 가능할 것으로 기대된다. 사용자 관점의 이슈 군집화 과정은 크롤링, 토픽 분석, 액세스 패턴 분석, 네트워크 병합, 네트워크 변환 및 군집화와 같은 여섯 가지 주요 단계로 구성되어있다. 이를 위해 텍스트 마이닝과 소셜 네트워크 분석 기법을 활용한 비정형 텍스트를 기반으로한 빅데이터의 활용 방법을 모색하였다. 제안 방법론의 실무 적용 가능성을 평가하기 위해, 국내 최대 포털 뉴스 사이트의 방문자 2,177명의 1년간 방문 기록과 뉴스기사 대한 분석을 수행하고 그 결과를 요약하여 제시하였다.
스마트 미디어 장치의 발달로 인하여 시공간적인 제약이 없이 비디오를 시청 가능한 환경이 제공됨에 따라 사용자의 시청행태가 수동적인 시청에서 능동적인 시청으로 계속해서 변화하고 있다. 사용자는 비디오를 시청하면서 비디오를 볼 뿐 아니라 관심 있는 내용에 대한 세부적인 정보를 검색한다. 그 결과 사용자와 미디어 장치간의 인터랙션이 주요 관심사로 등장하였다. 이러한 환경에서 사용자들은 일방적으로 정보를 제공해주는 것보다는 자신이 원하는 정보를 웹 검색을 통해 사용자 스스로 정보를 찾지 않고, 쉽고 빠르게 정보를 얻을 수 있는 방법의 필요성을 인식하게 되었으며 그에 따라 인터랙션을 직접 수행하는 것에 대한 요구가 증가하였다. 또한 많은 정보의 홍수 속에서 정확한 정보를 얻는 것이 중요한 이슈가 되었다. 이러한 사용자들의 요구사항을 만족시키기 위해 사용자 인터랙션 기능을 제공하고, 링크드 데이터를 적용한 시스템이 필요한 상황이다. 본 논문에서는 여러 분야 중에서 사람들이 가장 관심 있는 분야중 하나인 요리를 선택하여 문제점을 발견하고 개선하기 위한 방안을 살펴보았다. 요리는 사람들이 지속적인 관심을 갖는 분야이다. 레시피, 비디오, 텍스트와 같은 요리에 관련된 정보들이 끊임없이 증가하여 빅 데이터의 한 부분으로 발전하였지만 사용자와 요리 콘텐츠간의 인터랙션을 제공하는 방법과 기능이 부족하고, 정보가 부정확하다는 문제점을 가지고 있다. 사용자들은 쉽게 요리 비디오를 시청할 수 있지만 비디오는 단 방향으로만 정보를 제공하기 때문에 사용자들의 요구사항을 충족시키기 어렵고, 검색을 통해 정확한 정보를 얻는 것이 어렵다. 이러한 문제를 해결하기 위하여 본 논문에서는 요리 비디오 시청과 동시에 정보제공을 위한 UI(User Interface), UX(User Experience)를 통해 사용자의 편의성을 고려한 환경을 제시하고, 컨텍스트에 맞는 정확한 정보를 제공하기 위해 링크드 데이터를 이용하여 사용자와 비디오 간에 인터랙션을 위한 요리보조 서비스 시스템을 제안한다.
텍스트에 대한 사용자의 접근성을 향상시키기 위해, 이들 문서는 정해진 기준에 따라 카테고리로 분류되어 제공되고 있다. 과거에는 카테고리 분류 작업이 수작업으로 수행되었지만, 문서 작성자에게 분류를 맡기는 경우 분류 정확성을 보장할 수 없고 관리자가 모든 분류를 담당하는 경우 많은 시간과 비용이 소요된다는 어려움이 있었다. 이러한 한계를 극복하기 위해 카테고리를 자동으로 식별할 수 있는 문서 분류 기법에 대한 연구가 활발하게 수행되었다. 하지만 대부분의 문서 분류 기법은 각 문서가 하나의 카테고리에만 속하는 경우를 가정하고 있기 때문에, 하나의 문서가 다양한 주제를 갖는 실제 상황과 부합하지 않는다는 한계를 갖는다. 이를 보완하기 위해 최근 문서의 다중 카테고리 식별을 위한 연구가 일부 수행되었으나, 이들 연구는 대부분 이미 다중 카테고리가 부여되어 있는 문서에 대한 학습을 통해 분류 규칙을 생성하므로 단일 카테고리만 부여되어 있는 기존 문서의 다중 카테고리 식별에는 적용할 수 없다는 제약을 갖는다. 따라서 본 연구에서는 이러한 제약을 극복하기 위해, 카테고리, 토픽, 문서간 관계 분석을 통해 단일 카테고리를 갖는 문서로부터 추가 주제를 발굴하여 이를 다중 카테고리로 자동 확장시킬 수 있는 방법론을 제안하였다. 실험 결과 원 카테고리가 식별된 총 24,000건의 문서 중 23,089건에 대해 카테고리를 확장시킬 수 있었다. 또한 정확도 분석에서 카테고리의 특성에 따라 카테고리 분류 정확도가 상이하게 나타나는 현상을 발견하였다. 본 연구는 단일 카테고리로 분류된 문서에 대해 다중 카테고리를 추가로 식별하여 부여함으로써, 규칙 학습 과정에서 다중 카테고리가 부여된 문서를 필요로 하는 기존 다중 카테고리 문서 분류 알고리즘의 활용성을 매우 향상시킬 수 있을 것으로 기대한다.
최근 전 세계적인 원전 설비의 수요 증가로 원자력 전략물자 취급의 중요성이 높아지는 가운데, 국외 수출을 위한 원전 관련 물품 및 기술의 신청 또한 급증하는 추세이다. 전략물자 사전판정 업무는 통상 원자력 물자 관리에 해박한 전문가의 경험 및 지식에 근거하여 수행되어 왔지만, 급증하는 수요에 상응하는 전문 인력의 공급이 부족한 실정이다. 이러한 문제를 극복하기 위하여, 본 연구진은 전략물자 수출 통제를 위한 사례 기반 지능형 수출 통제 시스템을 설계 및 개발하였다. 이 시스템은 현장 전문가의 전담 업무이던 신규 사례에 대한 전략물자 사전판정 과정 업무의 주요 맥락을 자동화 하여 전문가 및 관계 기관이 감당해야 할 업무 부담을 줄이며, 빠르고 정확한 판정을 돕는 의사결정 지원 시스템의 역할을 맡는다. 개발된 시스템은 사례 기반 추론  (Case Based Reasoning) 방식에 기반을 두어 설계되었는데, 이는 과거 사례의 특성을 활용하여 신규 사례의 해법을 유추하는 추론 방법이다. 본 연구에서는 자연어로 작성된 전자문서 처리에 널리 사용되는 텍스트 마이닝 분석 기법을 원자력 분야에 특화된 형태로 응용하여 전략물자 수출통제 시스템을 설계하였다. 시스템 설계의 근거로 선행 연구에서 제안된 반자동식 핵심어 추출 방안의 성능을 보다 엄밀히 검증하였고, 추출된 핵심어로 신규 사례와 유사한 과거 사례를 추출하는 알고리즘을 제안하였다. 제안된 방안은 텍스트 마이닝 분야의 TF-IDF 방법 및 코사인 유사도 점수를 활용한 결과(α)와 원자력 분야에서 통용되는 개념적 지식을 계통으로 분류하여 도출한 결과(β)를 조합하여 최종 결과 (γ) 를 생성하게 된다. 세부 요소 기술의 성능 검증은 임상 데이터를 활용한 실험 및 실무 전문가의 의견수렴을 통해 이루어졌다. 개발된 시스템은 사전판정 전문 인력을 다수 양성하는 데 드는 비용을 절감하는 데 일조할 것이며, 지식서비스 산업의 의미 있는 응용 사례로서 관련 산업의 성장에 기여할 수 있을 것으로 보인다.
최근 스마트 기기를 통해 소셜미디어에 참여하는 사용자가 급격히 증가하고 있다. 이에 따라 빅데이터 분석에 대한 관심이 높아지고 있으며 최근 포털 사이트에서 검색어로 자주 입력되거나 다양한 소셜미디어에서 자주 언급되는 단어에 대한 분석을 통해 사회적 이슈를 파악하기 위한 시도가 이루어 지고 있다. 이처럼 다량의 텍스트를 통해 도출된 사회적 이슈의 기간별 추이를 비교하는 분석을 이슈 트래킹이라 한다. 하지만 기존의 이슈 트래킹은 두 가지 한계를 가지고 있다. 첫째, 전통적 방식의 이슈 트래킹은 전체 기간의 문서에 대해 일괄 토픽 분석을 실시하고 각 토픽의 기간별 분포를 파악하는 방식으로 이루어지므로, 새로운 기간의 문서가 추가되었을 때 추가된 문서에 대해서만 분석을 추가 실시하는 것이 아니라 전체 기간의 문서에 대한 분석을 다시 실시해야 한다는 실용성 측면의 한계를 갖고 있다. 둘째, 이슈는 끊임 없이 생성되고 소멸될 뿐 아니라, 때로는 하나의 이슈가 둘 이상의 이슈로 분화하고 둘 이상의 이슈가 하나로 통합되기도 한다. 즉, 이슈는 생성, 변화(병합, 분화), 그리고 소멸의 생명주기를 갖게 되는데, 전통적 이슈 트래킹은 이러한 이슈의 가변성을 다루지 않았다는 한계를 갖는다. 본 연구에서는 이러한 한계를 극복하기 위해 대상 기간 전체의 문서를 한꺼번에 분석하는 방식이 아닌 세부 기간별 문서에 대해 독립적인 분석을 수행하고 이를 통합할 수 있는 방안을 제시하였으며, 이를 통해 새로운 이슈가 생성되고 변화하며 소멸되는 전체 과정을 규명하였다. 또한 실제 인터넷 뉴스에 대해 제안 방법론을 적용함으로써, 제안 방법론의 실무 적용 가능성을 분석하였다.
Web2.0의 등장과 함께 급속히 발전해온 온라인 포럼, 블로그, 트위터, 페이스북과 같은 소셜 미디어 서비스는 소비자와 소비자간의 의사소통을 넘어 이제 기업과 소비자 사이의 새로운 커뮤니케이션 매체로도 인식되고 있다. 때문에 기업뿐만 아니라 수많은 기관, 조직 등에서도 소셜미디어를 활용하여 소비자와 적극적인 의사소통을 전개하고 있으며, 나아가 소셜 미디어 콘텐츠에 담겨있는 소비자 고객들의 의견, 관심, 불만, 평판 등을 분석하고 이해하며 비즈니스에 적용하기 위해 이를 적극 분석하는 단계로 진화하고 있다. 이러한 연구의 한 분야로서 비정형 텍스트 콘텐츠와 같은 빅 데이터에서 저자의 감성이나 의견 등을 추출하는 오피니언 마이닝과 감성분석 기법이 소셜미디어 콘텐츠 분석에도 활발히 이용되고 있으며, 이미 여러 연구에서 이를 위한 방법론, 테크닉, 툴 등을 제시하고 있다. 그러나 아직 대량의 소셜미디어 데이터를 수집하여 언어처리를 거치고 의미를 해석하여 비즈니스 인사이트를 도출하는 전반의 과정을 제시한 연구가 많지 않으며, 그 결과를 의사결정자들이 쉽게 이해할 수 있는 시각화 기법으로 풀어내는 것 또한 드문 실정이다. 그러므로 본 연구에서는 소셜미디어 콘텐츠의 오피니언 마이닝을 위한 실무적인 분석방법을 제시하고 이를 통해 기업의사결정을 지원할 수 있는 시각화된 결과물을 제시하고자 하였다. 이를 위해 한국 인스턴트 식품 1위 기업의 대표 상품인 N-라면을 사례 연구의 대상으로 실제 블로그 데이터와 뉴스를 수집/분석하고 결과를 도출하였다. 또한 이런 과정에서 프리웨어 오픈 소스 R을 이용함으로써 비용부담 없이 어떤 조직에서도 적용할 수 있는 레퍼런스를 구현하였다. 그러므로 저자들은 본 연구의 분석방법과 결과물들이 식품산업뿐만 아니라 타 산업에서도 바로 적용 가능한 실용적 가이드와 참조자료가 될 것으로 기대한다.
빅데이터 및 오피니언 마이닝 분야가 대두됨에 따라 정보 검색/추출, 특히 비정형 데이터에서의 정보 검색/추출 기술의 중요성이 나날이 부각되어지고 있다. 또한 정보 검색 분야에서는 이용자의 의도에 맞는 결과를 제공할 수 있는 검색엔진의 성능향상을 위한 다양한 연구들이 진행되고 있다. 이러한 정보 검색/추출 분야에서 자연어처리 기술은 비정형 데이터 분석/처리 분야에서 중요한 기술이고, 자연어처리에 있어서 하나의 단어가 여러개의 모호한 의미를 가질 수 있는 단어 중의성 문제는 자연어처리의 성능을 향상시키기 위해 우선적으로 해결해야하는 문제점들의 하나이다. 본 연구는 단어 중의성 해소 방법에 사용될 수 있는 말뭉치를 많은 시간과 노력이 요구되는 수동적인 방법이 아닌, 사전들의 예제를 활용하여 자동적으로 생성할 수 있는 방법을 소개한다. 즉, 기존의 수동적인 방법으로 의미 태깅된 세종말뭉치에 표준국어대사전의 예제를 자동적으로 태깅하여 결합한 말뭉치를 사용한 단어 중의성 해소 방법을 소개한다. 표준국어대사전에서 단어 중의성 해소의 주요 대상인 전체 명사 (265,655개) 중에 중의성 해소의 대상이 되는 중의어 (29,868개)의 각 센스 (93,522개)와 연관된 속담, 용례 문장 (56,914개)들을 결합 말뭉치에 추가하였다. 품사 및 센스가 같이 태깅된 세종말뭉치의 약 79만개의 문장과 표준국어대사전의 약 5.7만개의 문장을 각각 또는 병합하여 교차검증을 사용하여 실험을 진행하였다. 실험 결과는 결합 말뭉치를 사용하였을 때 정확도와 재현율에 있어서 향상된 결과가 발견되었다. 본 연구의 결과는 인터넷 검색엔진 등의 검색결과의 성능향상과 오피니언 마이닝, 텍스트 마이닝과 관련한 자연어 분석/처리에 있어서 문장의 내용을 보다 명확히 파악하는데 도움을 줄 수 있을 것으로 기대되어진다.
최근 경제적·사회적 부가가치를 창출할 수 있는 유망분야를 선정하여 국가 전략 및 정책 수립 시 반영하기 위해 미래 핵심 이슈를 발견하고 트렌드를 분석하는 것에 대한 관심이 급증하고 있다. 기존에는 미래의 핵심 기술이나 이슈를 발견하고 트렌드 분석을 통해 미래유망분야를 선정하는 연구를 위해 문헌 조사 또는 전문가 평가와 같은 정성적 연구방법이 사용되어 왔다. 그러나 이 연구방법은 대량의 정보로부터 결과를 도출하는데 많은 시간과 비용이 소요될 뿐만 아니라 전문가의 주관적인 가치가 반영될 가능성이 존재한다. 이와 같은 한계점을 보완하고자 최근 국토교통, 안전, 정보통신기술 등 다양한 분야에서 미래유망분야를 선정하기 위하여 정성적 연구방법에 텍스트 마이닝과 같은 정량적 연구방법을 상호보완적으로 활용하는 방식으로 트렌드 분석을 수행하는 연구 방법론의 패러다임 변화가 시도되고 있다.  본 연구는 항공산업 전반적인 분야에 빅데이터 분석 방법인 텍스트 마이닝 기법을 적용하여 항공 분야의 연구동향을 파악하고 미래유망분야를 전망하였다. 텍스트 마이닝 기법 중하나인 토픽 분석을 이용하여 항공산업 전반적인 분야의 문서 집합 내 잠재된 토픽을 추출하고, 연도별로 핵심 토픽의 추이를 분석하였다. 분석 결과 항공산업의 미래유망분야로 항공안전정책, 항공운임(저가항공), 그리고 친환경 고연비 연료가 도출되었다. 본 연구결과는 분석 대상을 논문에 한정하여 수행하였다는 한계점이 존재하나, 항공산업 분야의 핵심 이슈를 도출하기 위하여 텍스트 마이닝 기반의 트렌드 분석에 대한 활용가능성을 제시하고, 미래유망분야를 선정하기 위한 정량적인 분석 방법론의 전형을 마련하였다는 점에서 의의가 있다.
협업 필터링은 학계나 산업계에서 우수한 성능으로 인해 많이 사용되는 추천기법이지만, 정량적 정보인 사용자들의 평가점수에만 국한하여 추천결과를 생성하므로 간혹 정확도가 떨어지는 문제가 발생한다. 이에 새로운 정보를 추가로 고려하여, 협업 필터링의 성능을 개선하려는 연구들이 지금까지 다양하게 시도되어 왔다. 본 연구는 최근 Web 2.0 시대의 도래로 인해 사용자들이 구입한 상품에 대한 솔직한 의견을 인터넷 상에 자유롭게 표현한다는 점에 착안하여, 사용자가 직접 작성한 리뷰를 참고하여 협업 필터링의 성능을 개선하는 새로운 추천 알고리즘을 제안하고, 이를 스마트폰 앱 추천 시스템에 적용하였다. 정성 정보인 사용자 리뷰를 정량화하기 위해 본 연구에서는 텍스트 마이닝을 활용하였다. 구체적으로 본 연구의 추천시스템은 사용자간 유사도를 산출할 때, 사용자 리뷰의 유사도를 추가로 반영하여 보다 정밀하게 사용자간 유사도를 산출할 수 있도록 하였다. 이 때, 사용자 리뷰의 유사도를 산출하는 접근법으로 중복 사용된 색인어의 빈도로 산출하는 방안과 TF-IDF(Term Frequency - Inverse Document Frequency) 가중치 합으로 산출하는 2가지 방안을 제시한 뒤 그 성능을 비교해 보았다. 실험결과, 제안 알고리즘을 통한 추천, 즉 사용자 리뷰의 유사도를 추가로 반영하는 알고리즘이 평점만을 고려하는 전통적인 협업 필터링과 비교해 더 우수한 예측정확도를 나타냄을 확인할 수 있었다. 아울러, 중복 사용 단어의 TF-IDF 가중치의 합을 고려했을 때, 단순히 중복 사용 단어의 빈도만을 고려했을 때 보다 조금 더 나은 예측정확도를 얻을 수 있음도 함께 확인할 수 있었다.
최근 소셜 미디어의 사용이 폭발적으로 증가함에 따라 이용자가 직접 생성하는 방대한 데이터를 분석하기 위한 다양한 텍스트 마이닝(text mining) 기법들에 대한 연구가 활발히 이루어지고 있다. 이에 따라 텍스트 분석을 위한 알고리듬(algorithm)의 정확도와 수준 역시 높아지고 있으나, 특히 감성 분석(sentimental analysis)의 영역에서 언어의 문법적 요소만을 적용하는데 그쳐 화용론적·의미론적 요소를 고려하지 못한다는 한계를 지닌다. 본 연구는 이러한 한계를 보완하기 위해 기존의 알고리듬 보다 의미 자질을 폭 넓게 고려할 수 있는 Word2Vec 기법을 적용하였다. 또한 한국어 품사 중 형용사를 감정을 표현하는 ‘감정어휘’로 분류하고, Word2Vec 모델을 통해 추출된 감정어휘의 연관어 중 명사를 해당 감정을 유발하는 요인이라고 정의하여 이 전체 과정을 ‘Emotion Trigger'라 명명하였다. 본 연구는 사례 연구(case study)로 사회적 이슈가 된 세 직업군(교수, 검사, 의사)의 특정 사건들을 연구 대상으로 선정하고, 이 사건들에 대한 대중들의 인식에 대해 분석하고자 한다. 특정 사건들에 대한 일반 여론과 직접적으로 표출된 개인 의견 모두를 고려하기 위하여 뉴스(news), 블로그(blog), 트위터(twitter)를 데이터 수집 대상으로 선정하였고, 수집된 데이터는 유의미한 연구 결과를 보여줄 수 있을 정도로 그 규모가 크며, 추후 다양한 연구가 가능한 시계열(time series) 데이터이다. 본 연구의 의의는 키워드(keyword)간의 관계를 밝힘에 있어, 기존 감성 분석의 한계를 극복하기 위해 Word2Vec 기법을 적용하여 의미론적 요소를 결합했다는 점이다. 그 과정에서 감정을 유발하는 Emotion Trigger를 찾아낼 수 있었으며, 이는 사회적 이슈에 대한 일반 대중의 반응을 파악하고, 그 원인을 찾아 사회적 문제를 해결하는데 도움이 될 수 있을 것이다.
장소 브랜딩은 특정 장소에 대한 의미 부여를 통해 장소성의 정체성 및 공동가치를 생성하며 가치 창출을 하는데 중요한 활동이며, 장소 브랜드에 대한 이미지 파악을 통해 이루어진다. 이에 마케팅, 건축학, 도시건설학 등 여러 분야에서는 인상적인 장소 브랜드의 이미지를 구축하기 위하여 많은 노력을 기울이고 있다. 하지만 설문조사를 포함한 대면조사 방법은 대부분 주관적인 작업이며 측정에 많은 인력 또는 고도의 전문 인력이 소요되어 고비용을 발생시키므로 보다 객관적이면서도 비용효과적인 브랜드 이미지 조사 방법이 필요하다. 이에 본 논문은 텍스트마이닝을 통하여 장소 브랜드의 이미지 강도를 객관적이고 저비용으로 얻는 방법을 찾는 것을 목적으로 한다. 제안하는 방법은 장소 브랜드 이미지를 구성하고 있는 요인과 그 키워드들을 관련 웹문서에서 추출하며, 추출된 정보를 통해 특정 장소의 브랜드 이미지 강도를 측정하는 방법이다. 성능은 안홀트 방법에서 평가에 사용하는 전세계 50개 도시 이미지 인덱스 순위와의 일치도로 검증하였다. 성능 비교를 위해 임의로 순위를 매기는 방법, 안홀트의 설문방식대로 일반인이 평가하는 방법, 본 논문의 방법을 사용하되 안홀트의 방법으로 학습한 것으로 유의한 것으로 추정되는 평가 항목만을 반영하는 방법과 비교하였다. 그 결과 제안된 방법론은 정확성, 비용효율성, 적시성, 확장성, 그리고 신뢰성 측면에서 우수함을 보일 수 있었다. 따라서 본 연구에서 제안한 방법론은 안홀트 방식에 상호 보완적으로 사용될 수 있을 것이다. 향후에는 장소 브랜드 이미지를 형성하는 속성 별로 등장횟수를 계산 한 후에 장소 브랜드에 대한 태도, 연상, 그리고 브랜드 자산과의 인과관계를 자동으로 파악할 수 있는 부분까지 구현하고 실증적 실험을 할 예정이다.
인터넷 기술의 발전과 인터넷 상 데이터의 급속한 증가로 인해 데이터의 활용 목적에 적합한 분석방안 연구들이 활발히 진행되고 있다. 최근에는 텍스트 마이닝 기법의 활용에 대한 연구들이 이루어지고 있으며, 특히 문서 내 텍스트를 기반으로 문장이나 어휘의 긍정, 부정과 같은 극성 분포에 따라 의견을 스코어링(scoring)하는 감성분석과 관련된 연구들도 다수 이루어지고 있다. 이러한 연구의 연장선상에서, 본 연구는 인터넷 상의 특정 기업에 대한 뉴스 데이터를 수집하여 이들의 감성분석을 실시함으로써 주가의 등락에 대한 예측을 시도하였다. 개별 기업의 뉴스 정보는 해당 기업의 주가에 영향을 미치는 요인으로, 적절한 데이터 분석을 통해 주가 변동 예측에 유용하게 활용될 수 있을 것으로 기대된다. 따라서 본 연구에서는 개별 기업의 온라인 뉴스 데이터에 대한 감성분석을 바탕으로 개별 기업의 주가 변화 예측을 꾀하였다. 이를 위해, KOSPI200의 상위 종목들을 분석 대상으로 선정하여 국내 대표적 검색 포털 서비스인 네이버에서 약 2년간 발생된 개별 기업의 뉴스 데이터를 수집·분석하였다. 기업별 경영 활동 영역에 따라 기업 온라인 뉴스에 나타나는 어휘의 상이함을 고려하여 각 개별 기업의 어휘사전을 구축하여 분석에 활용함으로써 감성분석의 성능 향상을 도모하였다. 분석결과, 기업별 일간 주가 등락여부에 대한 예측 정확도는 상이했으며 평균적으로 약 56%의 예측률을 보였다. 산업 구분에 따른 주가 예측 정확도를 통하여 ‘에너지/화학’, ‘생활소비재’, ‘경기소비재’의 산업군이 상대적으로 높은 주가 예측 정확도를 보임을 확인하였으며, ‘정보기술’과 ‘조선/운송’ 산업군은 주가 예측 정확도가 낮은 것으로 확인되었다. 본 논문은 온라인 뉴스 정보를 활용한 기업의 어휘사전 구축을 통해 개별 기업의 주가 등락 예측에 대한 분석을 수행하였으며, 향후 감성사전 구축 시 불필요한 어휘가 추가되는 문제점을 보완한 연구 수행을 통하여 주가 예측 정확도를 높이는 방안을 모색할 수 있을 것이다.
최근 가용한 텍스트 데이터 자원이 증가함에 따라 방대한 텍스트 분석을 통해 새로운 가치를 창출하고자 하는 수요가 증가하고 있다. 특히 뉴스, 민원, 블로그, SNS 등을 통해 유통되는 글로부터 다양한 이슈를 발굴해내고 이들 이슈의 추이를 분석하는 이슈 트래킹에 대한 연구가 활발하게 이루어지고 있다. 전통적인 이슈 트래킹은 토픽 모델링을 통해 오랜 기간에 걸쳐 지속된 주요 이슈를 발굴한 후, 각 이슈를 구성하는 문서 수의 세부 기간별 분포를 분석하는 방식으로 이루어진다. 하지만 전통적 이슈 트래킹은 각 이슈를 구성하는 내용이 전체 기간에 걸쳐 변화 없이 유지된다는 가정 하에 수행되기 때문에, 다양한 세부 이슈가 서로 영향을 주며 생성, 병합, 분화, 소멸하는 이슈의 동적 변이과정을 나타내지 못한다. 또한 전체 기간에 걸쳐 지속적으로 출현한 키워드만이 이슈 키워드로 도출되기 때문에, 핵실험, 이산가족 등 세부 기간의 분석에서는 매우 상이한 맥락으로 파악되는 구체적인 이슈가 오랜 기간의 분석에서는 북한이라는 큰 이슈에 함몰되어 가려지는 현상이 발생할 수 있다. 본 연구에서는 이러한 한계를 극복하기 위해 각 세부 기간의 문서에 대한 독립적인 분석을 통해 세부 기간별 주요 이슈를 도출한 후, 각 이슈의 유사도에 기반하여 이슈 흐름도를 도출하고자 한다. 또한 각 문서의 카테고리 정보를 활용하여 카테고리간의 이슈 전이 패턴을 분석하고자 한다. 본 논문에서는 총 53,739건의 신문 기사에 제안 방법론을 적용한 실험을 수행하였으며, 이를 통해 전통적인 이슈 트래킹을 통해 발굴한 주요 이슈의 세부 기간별구성 내용을 살펴볼 수 있을 뿐 아니라, 특정 이슈의 선행 이슈와 후행 이슈를 파악할 수 있음을 확인하였다. 또한 카테고리간 분석을 통해 단방향 전이와 양방향 전이의 흥미로운 패턴을 발견하였다.
의료IT 서비스의 유망 분야인 정신건강 증진을 위한 주관적 웰빙 서비스(subjective well-being service) 구현의 핵심은 개인의 주관적 웰빙 상태를 정확하고 무구속적이며 비용 효율적으로 측정하는 것인데 이를 위해 보편적으로 사용되는 설문지에 의한 자기보고나 신체부착형 센서 기반의 측정 방법론은 정확성은 뛰어나나 비용효율성과 무구속성에 취약하다. 비용효율성과 무구속성을 보강하기 위한 온라인 텍스트 기반의 측정 방법은 사전에 준비된 감정어 어휘만을 사용함으로써 상황에 따라 감정어로 볼 수 있는 이른바 상황적 긍부정성(contextual polarity)을 고려하지 못하여 측정 정확도가 낮다. 한편 기존의 상황적 긍부정성을 활용한 감성분석으로는 주관적 웰빙 상태인 맥락에서의 감성분석을 할 수 있는 감정어휘 사전이나 온톨로지가 구축되어 있지 않다. 더구나 온톨로지 구축도 매우 노력이 소요되는 작업이다. 따라서 본 연구의 목적은 온라인상에 사용자의 의견이 표출된 비정형 텍스트로부터 주관적 웰빙과 관련한 상황감정어를 추출하고, 이를 근거로 상황적 긍부정성 파악의 정확도를 개선하는 방법을 제안하는 것이다. 기본 절차는 다음과 같다. 먼저 일반 감정어휘 사전을 준비한다. 본 연구에서는 가장 대표적인 디지털 감정어휘사전인 SentiWordNet을 사용하였다. 둘째, 정신건강지수를 동적으로 추정하는데 필요한 비정형 자료인 Corpora를 온라인 서베이로 확보하였다. 셋째, Corpora로부터 세 가지 종류의 자원을 확보하였다. 넷째, 자원을 입력변수로 하고 특정 정신건강 상태의 지수값을 종속변수로 하는 추론 모형을 구축하고 추론 규칙을 추출하였다. 마지막으로, 추론 규칙으로 정신건강 상태를 추론하였다. 본 연구는 감정을 분석함에 있어, 기존의 연구들과 달리 상황적 감정어를 적용하여 특정 도메인에 따라 다양한 감정 어휘를 파악할 수 있다는 점에서 독창성이 있다.
그동안 기업의 사회적 책임(CSR)관련 활동의 결과가 기업 성과에 미치는 단기적 및 장기적 영향에 대한 다양한 연구가 진행되었지만 그 결과는 일관되지 못한데 그 주된 원인은 기업의 사회적책임이라고 하는 개념의 불일치였다. 따라서 본 연구는 온라인 뉴스와 같은 비정형 공개 데이터로부터 기업의 사회적책임에 관련한 키워드를 텍스트 마이닝 기법을 사용하여 추출하고 그 개념에 대한 통계치와 기업 성과와의 관계성을 이해하려고 했다. 이를 위해 개념과 관련한 키워드는 뉴욕타임즈와 구글 스칼러에서 CSR이라고 하는 단어로 검색한 비정형 데이터로부터 인식하였다. 그런 다음 점검 대상이 되는 기업에 대한 글이 실려 있는 온라인 문서를 수집하여 기업의 사회적 책임과 기업 단기적 및 장기적성과 사이의 인과관계를 분석하였다. 그 결과, 기업의 사회적 책임에 대한 전문적인 평가 보고서의 도움 없이도 본 연구에서 개발한 기업의 사회적 책임 인덱스만으로 기업의 단기적 성과에는 영향이 없지만 장기적 성과와는 통계적으로 유의하게 정비례관계가 있는 것이 밝혀졌다. 본 연구는 빅데이터 분석을 통해 효율적이고 의미 있는 기업의 사회적 책임 평가 방법을 개발한 첫 번째 시도라는 의미가 있다.
대부분의 부도 예측에 관한 연구는 재무 변수를 중심으로 통계적 방법 또는 인공지능 기법을 적용하여 부도 예측 모형을 구축하였다. 그러나 재무비율과 같은 회계 정보를 이용한 부도 예측 모형은 재무 제표 결산 시점과 신용평가 시점 간 시차를 고려하지 않을 뿐만 아니라 해당 산업의 경제적 상황과 같은 외부 환경적인 요소를 반영하기 어렵다는 한계점이 존재하였다. 기업의 부도 여부를 예측하기 위해 정량 정보인 재무 변수만을 이용하는 것에 한계가 있음에도 불구하고 정성 정보를 부도 예측 모형에 반영한 연구는 아직 미흡한 실정이다. 본 연구에서는 재무 변수를 이용하는 기존 부도 예측 모형의 성과를 개선하기 위해 빅데이터 기반의 정성 정보를 추가적인 입력 변수로 활용하는 부도 예측 모형을 제안하였다. 제안 모형의 성과 향상은 정성 정보를 예측 모형에 통합시키기에 적합한 형태로 정보의 유형을 변환시킬 수 있는가에 따라 달려있다. 이에 본 연구에서는 정성 정보 처리를 위한 방법으로 빅데이터 분석 기법 중 하나인 텍스트 마이닝 (Text Mining)을 활용하였다. 해당 산업과 관련된 경제 뉴스 데이터로부터 경제 상황에 대한 감성 정보를 추출하기 위해 도메인 중심의 감성 어휘 사전을 구축하고, 구축된 어휘 사전을 기반으로 감성 분석 (Sentiment Analysis)을 수행하였다. 형태소 분석 등을 포함한 텍스트 전처리 과정을 거쳐 감성 어휘를 추출하고, 각 어휘에 대한 극성 및 감성 점수를 부여하였다. 분석 결과, 전통적 부도 예측 모형에 경제 뉴스 데이터에서 도출한 정성 정보를 반영하는 것은 모형의 성과를 개선하는 것으로 나타났다. 특히,경제 상황에 대한 부정적 감정이 기업의 부도 여부를 예측하는 데 더욱 효과적임을 알 수 있었다.
인터넷상의 데이터가 급속하게 증가함에 따라 막대한 양의 데이터를 목적에 맞게 적절히 활용하는 빅데이터 분석이 활발하게 진행되고 있다. 최근에는 기존의 정형 데이터분석이 가진 한계점을 보완하는 방법으로 비정형 데이터 분석 분야 중 하나인 텍스트마이닝 기법에 대한 연구들이 다수 이루어지고 있으며, 특히 텍스트를 기반으로 문장의 긍정, 부정을 판별하고 분류하는 감성분석과 관련된 연구들이 활발하게 이루어지고 있다. 이러한 연구의 연장선 상에서, 본 연구는 감성분석에 사용되는 감성사전을 데이터의 특성에 맞게 적절하게 변형하여 구축하는 방법을 시도하였다. 데이터가 속한 영역의 특성을 고려하지 않은 기존의 범용 감성사전을 감성분석에 사용할 경우, 해당 영역에서 쓰이는 단어 또는 감정 표현을 반영하지 못하므로 감성분석의 정확성이 떨어질 수 있다. 따라서 감성분석에 있어서 영역 맞춤형 감성사전의 사용 시 데이터 영역의 특성을 정확하게 반영해 분석의 정확성을 높여줄 것으로 기대할 수 있다. 본 연구에서는 영화 리뷰 데이터를 분석 대상으로 선정하였으며, 대표적 영화정보 사이트 IMDb에서 발생된 약 2년간의 영화리뷰 데이터를 수집·분석하였다. 분석에 앞서 영화 장르별 사용되는 단어의 의미가 각각 다를 것을 고려하여 영화를 ‘액션’, ‘애니메이션’, ‘코메디’,‘드라마’, ‘공포’, ‘과학공상’ 6개 장르로 분류했다. 맞춤형 감성사전 구축을 위한 핵심 기법으로 SO-PMI(Semantic Orientation from Point-wise Mutual Information)를 활용하였으며, 어휘 간 극성이 뚜렷하게 구분되는 형용사에 한정하여 연구를 진행했다. 분석결과 맞춤형사전을 활용한 감성분석 예측정확도는 영화 장르별로 상이했다. ‘애니메이션’을 제외한 5개 장르에서 기존의 범용 감성사전대비 맞춤형 감성사전의 예측정확도가 통계적으로 유의한 수준의 성능 향상을 보였다. 본 연구에서는 데이터 영역의 특성에 맞는 맞춤형 사전 구축을 통한 감성분석의 예측의 성능 향상을 확인하였다. 향후 감성사전 구축 시 동사, 부사 등 다양한 품사의 어휘를 추가하여 감성분석 예측정확도를 높이는 방안을 모색할 수 있을 것이다.
최근 IT기술의 발전에 따라 많은 사람들이 자신들의 여가활동에 대한 경험을 공유하고 있으며, 역으로 다른사람들의 여가활동에 대한 경험을 참고하여 더 나은 여가활동을 누릴 수 있는 기회를 얻게 되었다. 이러한 현상은 영화, 숙박, 음식, 여행 등 여가활동 전반에 걸쳐 나타나고 있으며, 그 중심에는 여가활동에 대한 정보를 요약하여 제공하는 수많은 사이트가 있다. 대부분의 여가활동 정보 사이트는 각 상품에 대한 평균 평점뿐만 아니라상세 리뷰를 제공함으로써, 해당 상품을 구매하고자 하는 잠재고객의 의사결정을 지원하고 있다. 하지만 기존대부분의 사이트는 한 단계의 평가기준에 따라 평점과 리뷰를 제공하기 때문에, 각 평가기준을 구성하는 세부요소에 대한 특징과 평가기준 별 주요 이슈를 파악하기 위해서는 상당히 많은 수의 리뷰를 직접 읽어야 한다는불편이 따른다. 즉 사용자는 자신이 중요한 것으로 생각하는 평가기준에 대한 조건을 파악하기 위해, 많은 수의리뷰를 하나하나 읽어보는 과정에서 많은 시간과 노력을 소비하게 된다. 예를 들어 호텔의 접근성, 객실, 서비스, 음식 등 한 단계의 평가기준만을 사용하여 평점과 리뷰를 제공하는 사이트의 경우, 접근성 중 특히 지하철역과의거리, 객실 중 특히 욕실의 상태를 살펴보고자 하는 사용자에게 필요한 정보를 충분히 제공하지 못하게 된다. 따라서 본 연구에서는 기존 여가활동 정보 사이트의 한계, 즉 평가기준별로 입력된 리뷰를 신뢰하기 어렵다는점과 평가기준을 구성하고 있는 세부 내용을 파악하기 어렵다는 점을 극복하기 위한 방안을 제시하고자 한다. 본 연구에서 제안하는 방법론은 사용자가 별도의 구분 없이 입력한 리뷰를 그 내용에 따라 평가기준별로 자동 분류하고, 각 평가 기준 별 주요 이슈를 요약하여 제공한다. 제안 방법론은 최근 텍스트 분석에 활발하게 사용되고 있는 토픽 모델링(Topic Modeling)에 기반을 두고 있으며, 각 리뷰를 하나의 문서 단위로 사용하는 것이아니라 리뷰를 문장 단위로 끊어 개별 리뷰 유닛(Review Unit)으로 분해한 뒤, 평가기준별로 리뷰 유닛을 재구성하여 분석한다는 측면에서 기존의 토픽 모델링 기반 연구와 큰 차이가 있다고 할 수 있다. 본 논문에서는 제안 방법론을 실제 호텔 정보 사이트에서 수집한 423건의 리뷰 문서에 적용하여 6가지 평가기준에 대해 총4,860건의 리뷰 유닛을 재구성하고, 이에 대한 분석 결과를 소개함으로써 제안 방법론의 유용성을 간접적으로보인다.
누구나 본인이 사용한 제품이나, 이용한 서비스에 대한 후기를 자유롭게 인터넷에 작성할 수 있고, 이러한데이터의 양은 점점 더 많아지고 있다. 감성분석은 사용자가 생성한 온라인 텍스트 속에 내포된 감성 및 감정을식별하기 위해 사용된다. 본 연구는 다양한 데이터 도메인 중 영화 리뷰를 분석 대상으로 한다. 영화 리뷰를 이용한 기존 연구에서는 종종 리뷰 평점을 관객의 감성으로 동일시하여 감성분석에 이용한다. 그러나 리뷰 내용과 평점의 실제적 극성 정도가 항상 일치하는 것은 아니기 때문에 연구의 정확성에 한계가 발생할 수 있다. 이에 본 연구에서는 기계학습 기반의 감성 분류기를 구축하고, 이를 통해 리뷰의 감성점수를 산출하여 리뷰에서나타나는 감성의 수치화를 목표로 한다. 나아가 산출된 감성점수를 이용하여 리뷰와 영화 흥행 간의 연관성을살펴보았다. 감성분석 모델은 지지벡터 분류기와 신경망을 이용해 구축되었고, 총 1만 건의 영화 리뷰를 학습용데이터로 하였다. 감성분석은 총 175편의 영화에 대한 1,258,538개의 리뷰에 적용하였다. 리뷰의 평점과 흥행, 그리고 감성점수와 흥행과의 연관성은 상관분석을 통해 살펴보았고, t-검정으로 두 지표의 평균차를 비교하여감성점수의 활용성을 검증하였다. 연구 결과, 본 연구에서 제시하는 모델 구축 방법은 나이브 베이즈 분류기로구축한 모델보다 높은 정확성을 보였다. 상관분석 결과로는, 영화의 주간 평균 평점과 관객 수 간의 유의미한양의 상관관계가 나타났고, 감성점수와 관객 수 간의 상관분석에서도 유사한 결과가 도출되었다. 이에 두 지표간의 평균을 이용한 t-검정을 수행하고, 이를 바탕으로 산출한 감성점수를 리뷰 평점의 역할을 할 수 있는 지표로써 활용 가능함을 검증하였다. 나아가 검증된 결론을 근거로, 트위터에서 영화를 언급한 트윗을 수집하여 감성분석을 적용한 결과를 살펴봄으로써 감성분석 모델의 활용 방안을 모색하였다. 전체적 실험 및 검증의 과정을 통해 본 연구는 감성분석 연구에 있어 개선된 감성 분류 방법을 제시할 수 있음을 보였고, 이러한 점에서연구의 의의가 있다.
소비자들이 소셜미디어 상에 기록한 글을 통해 기업은 제품 또는 기업 이미지에 대한 감성분석을 수행하는데 이는 소셜미디어 기반 마케팅에서 중요한 활동 중에 하나다. 특히 글로벌 소셜미디어의 경우 국적을 불문하고 다양한 고객이 늘어남에 따라 여러 언어권의 소비자들이 각자의 언어로 다양한 의견을 표명하고 있다. 이처럼 다양한 언어로 작성된 텍스트를 감성분석하기 위해서는 기존 방법과 달리 동일한 언어로 통일시켜야 하는 번역 작업이 필요하다. 하지만 번역을 하게 될 경우, 언어와 관련된 배경이나 문화, 용어사용의 차이 등으로 본래 문서에 있는 모든 단어나 문법을 정확히 표현할수 없는 문제점이 있다. 따라서 본 연구에서는 다중 언어로 수집되는 텍스트를 번역하지 않고 해당 언어별로 텍스트를분리한 다음 감성분석을 진행하여 각각의 극성치를 종합하는 방법을 제안하고자 한다. 본 연구에서 제안한 다국어 감성분석 알고리즘을 검증하기 위해 다중언어 문장을 한국어, 중국어로 번역한 감성분석의 극성치 편차인 RMSE 값을 비교하였다. 그 결과, 번역을 통한 다중언어의 감성분석보다 언어별로 분리한 감성값이 실제 감성값에 가장 근접하는 것으로나타나 본 연구에서 제안한 방법론의 우수성을 입증하였다. 본 연구는 다수의 유사한 연구에서 사용했던 알고리즘을 사용하지 않고 원문 그대로 다중언어 감성분석을 시도했다는 점에서 의의가 있다.
전자상거래에서 소비자들의 구매 의사결정에 판매 제품을 이미 구매하여 사용한 고객의 리뷰가 중요한 영향을 미치고 있다. 전자상거래 업체들은 고객들이 제품 리뷰를 남기도록 유도하고 있으며, 구매고객들도 적극적으로 자신의 경험을 공유하고 있다. 한 제품에 대한 고객 리뷰가 너무 많아져서 구매하려는 제품의 모든 리뷰를읽고 제품의 장단점을 파악하는 것은 무척 힘든 일이 되었다. 전자상거래 업체들과 연구자들은 텍스트 마이닝을 활용하여 리뷰들 중에서 유용한 리뷰들의 속성을 파악하거나 유용한 리뷰와 유용하지 않은 리뷰를 미리 분류하는 노력을 수행하고 있다. 고객들에게 유용한 리뷰를 필터링하여 전달하는 방안이다. 본 연구에서는 문서-단어 매트릭스에서 단어의 제거 기준으로 온라인 고객 리뷰가 유용한 지, 그렇지 않은지를 구분하는 문제에서 단어들이 유용 리뷰 집합과 유용하지 않은 리뷰집합에 중복하여 등장하는 정도를 측정한중립도를 제시한다. 제시한 중립도를 희소성과 함께 분석에 활용하여 제거할 단어를 선정한 후에 각 분류 알고리즘의 성과를 비교하였다. 최적의 성과를 보이는 중립도를 찾았으며, 희소성과 중립도에 따라 단어를 선택적으로 제거하였다. 실험은 Amazon.com의 ‘Cellphones & Accessories’, ‘Movies & TV program’, ‘Automotive’, ‘CDs & Vinyl’, ‘Clothing, Shoes & Jewelry’ 제품 분야 고객 리뷰와 사용자들의 리뷰에 대한 평가를 활용하였다. 전체 득표의 수가 4개 이상인 리뷰 중에서 제품 카테고리 별로 유용하다고 판단되는 1,500개의 리뷰와 유용하지 않다고 판단되는 1,500개의 리뷰를 무작위로 추출하여 연구에 사용하였다. 데이터 집합에 따라 정확도 개선 정도가 상이하며, F-measure 기준으로는 두 알고리즘에서 모두 희소성과 중립도에 기반하여 단어를 제거하는 방안이 더 성과가 높았다. 하지만 Information Gain 알고리즘에서는 Recall 기준으로는 5개 제품 카테고리 데이터에서 언제나 희소성만을 기준으로 단어를 제거하는 방안의 성과가 높았으며, SVM에서는 전체 단어를 활용하는 방안이 Precision 기준으로 성과가 더 높았다. 따라서, 활용하는 알고리즘과 분석 목적에 따라서 단어 제거 방안을 고려하는 것이 필요하다.
융합을 통한 기술과 제품의 혁신을 이해하는 것은 중소기업의 생존을 위한 필수가 되었다. 특히, 이종 산업간 융합을 통한 제품 혁신과 성공을 위해서는 융합 가능한 아이템 즉, 제품과 기술, 아이디어를 탐색하고 대안을 찾는 것이 중요하다. 기존의 융합연구는 크게 두 가지의 한계를 갖는다. 첫째, 특허와 논문 등 기술정보를기반으로 하는 기술융합 발굴은 시장의 수요를 인식하는데 한계가 있다. 본 논문은 중소·창업기업에 적용할 수있는 시장융합(Market convergence)의 관점에서 새로운 융합 기회를 식별하려고 시도하였다. 이를 위해 세계 중소 수출입 기업이 이용하는 글로벌 B2B e-마켓플레이스의 제품 데이터베이스를 활용하였다. 둘째, 기존의 융합기회 발굴 연구는 이미 융합되어 존재하는 제품 또는 기술 기반의 연관성 및 관계를 파악하는데 집중하였다. 본 연구에서는 융합 가능한 새로운 사업기회의 발굴을 목적으로 구조적공백(Structural Hole) 이론을 적용하여, 상이한 산업군에서 서로 직접적인 연결 관계가 없는 키워드 간의 네트워크를 분석하여 융합의 가능성이 있는새로운 융합 사업 테마를 도출하고자 한다. 이를 위해 제품명과 제품 기술서를 기반으로 제품 및 기술 용어 사전과 텍스트마이닝 을 활용하여 제품과 서비스의 특성을 추출하고, 이들 특성간 연관관계분석을 수행한 후, 네트워크 분석을 진행 하였다. 실험 데이터는 시장의 최신 동향을 파악하기 위해 2013년 1월 부터 2016년 7월까지 등록된 24만건의 e-카탈로그를 대상으로 하였으며, 분석의 효율성을 높이기 위해 기술 범위를 IT로 제한하고, IT 기술을 매개로 한 “Health & Medical”과 “Security & Protection” 카테고리 간의 융합 기회를 도출 하였다. 실험을 통하여 융합연관규칙 1,729을 추출하였으며, 지지도를 기반으로 100개의 규칙을 샘플링 하여, 구조적 공백을 분석하였다.
본 연구는 한국지능정보시스템학회의 고유한 연구영역을 파악하고자 지능정보연구 학술지에 최근 3년 동안게재된 논문들을 대상으로 키워드를 수집하여 프로파일링 기법과 동시출현빈도를 분석하였다. 이를 통하여 지능정보시스템 연구의 정통성과 정체성을 밝히는 동시에 향후 추구해야할 연구영역을 제시하고자 한다. 연구 정체성에 대한 상대적 위치를 파악하기 위하여 한국지능정보시스템학회 뿐만 아니라 유사학회에 해당하는 한국경영정보학회 그리고 한국정보시스템학회의 키워드 및 연구방법론을 수집하여 비교하였다. 또한, 한국지능정보시스템학회에서 인공지능/데이터마이닝, 지능형인터넷, 지식경영에 대한 주요 분야를 중점적으로 다루고 있음을 고려할 때 각 분야의 대표적인 학회로 한국빅데이터서비스학회 및 한국빅데이터학회, 한국인터넷전자상거래학회, 한국지식경영학회의 연구 경향을 각각 비교 분석하였다. 키워드 분석 결과만을 요약하면, 한국지능정보시스템학회는 키워드 부문에서는 텍스트마이닝 , 데이터 마이닝 및 추천시스템에 집중하고 있다는 것을 알 수있었다. 인공지능/데이터마이닝 분야에서는 빅데이터 개념 자체와 감성분석에 초점을 두고 있고, 지능형인터넷분야에서는 SNS와 구매의도, 신뢰, 기술수용모델에 집중하고 있었다. 지식경영 분야에서는 지식관리, 지식 공유 키워드에 집중함을 발견할 수 있었다. 더 나아가 한국지능정보시스템학회 뿐만 아니라 유사 연구 분야에서생태계 전반적 융합 가능성을 진단해 보았다.
최근 여론조사 분야에서 데이터에 기반을 둔 분석 기법이 널리 활용되고 있다. 기업에서는 최근 출시된 제품에 대한 선호도를 조사하기 위해 기존의 설문조사나 전문가의 의견을 단순 취합하는 것이 아니라, 온라인상에존재하는 다양한 종류의 데이터를 수집하고 분석하여 제품에 대한 대중의 기호를 정확히 파악할 수 있는 방안을 필요로 한다. 기존의 주요 방안에서는 먼저 해당 분야에 대한 감성사전을 구축한다. 전문가들은 수집된 텍스트 문서들로부터 빈도가 높은 단어들을 정리하여 긍정, 부정, 중립을 판단한다. 특정 제품의 선호를 판별하기위해, 제품에 대한 사용 후기 글을 수집하여 문장을 추출하고, 감성사전을 이용하여 문장들의 긍정, 부정, 중립을 판단하여 최종적으로 긍정과 부정인 문장의 개수를 통해 제품에 대한 선호도를 측정한다. 그리고 제품에 대한 긍·부정 내용을 자동으로 요약하여 제공한다. 이것은 문장들의 감성점수를 산출하여, 긍정과 부정점수가 높은 문장들을 추출한다. 본 연구에서는 일반 대중이 생산한 문서 속에 숨겨져 있는 토픽을 추출하여 주어진 제품의 선호도를 조사하고, 토픽의 긍·부정 내용을 요약하여 보여주는 제품 평판 마이닝 알고리즘을 제안한다. 기존방식과 다르게, 토픽을 활용하여 쉽고 빠르게 감성사전을 구축할 수 있으며 추출된 토픽을 정제하여 제품의 선호도와 요약 결과의 정확도를 높인다. 실험을 통해, K5, SM5, 아반떼 등의 국내에서 생산된 자동차의 수많은후기 글들을 수집하였고, 실험 자동차의 긍·부정 비율, 긍·부정 내용 요약, 통계 검정을 실시하여 제안방안의 효용성을 입증하였다.
언어모델은 순차적으로 입력된 자료를 바탕으로 다음에 나올 단어나 문자를 예측하는 모델로 언어처리나 음성인식 분야에 활용된다. 최근 딥러닝 알고리즘이 발전되면서 입력 개체 간의 의존성을 효과적으로 반영할 수있는 순환신경망 모델과 이를 발전시킨 Long short-term memory(LSTM) 모델이 언어모델에 사용되고 있다. 이러한 모형에 자료를 입력하기 위해서는 문장을 단어 혹은 형태소로 분해하는 과정을 거친 후 단어 레벨 혹은형태소 레벨의 모형을 사용하는 것이 일반적이다. 하지만 이러한 모형은 텍스트가 포함하는 단어나 형태소의수가 일반적으로 매우 많기 때문에 사전 크기가 커지게 되고 이에 따라 모형의 복잡도가 증가하는 문제가 있고사전에 포함된 어휘 외에는 생성이 불가능하다는 등의 단점이 있다. 특히 한국어와 같이 형태소 활용이 다양한언어의 경우 형태소 분석기를 통한 분해과정에서 오류가 더해질 수 있다. 이를 보완하기 위해 본 논문에서는문장을 자음과 모음으로 이루어진 음소 단위로 분해한 뒤 입력 데이터로 사용하는 음소 레벨의 LSTM 언어모델을 제안한다. 본 논문에서는 LSTM layer를 3개 또는 4개 포함하는 모형을 사용한다. 모형의 최적화를 위해Stochastic Gradient 알고리즘과 이를 개선시킨 다양한 알고리즘을 사용하고 그 성능을 비교한다. 구약성경 텍스트를 사용하여 실험을 진행하였고 모든 실험은 Theano를 기반으로 하는 Keras 패키지를 사용하여 수행되었다. 모형의 정량적 비교를 위해 validation loss와 test set에 대한perplexity를 계산하였다. 그 결과 Stochastic Gradient 알고리즘이 상대적으로 큰 validation loss와 perplexity를 나타냈고 나머지 최적화 알고리즘들은 유사한 값들을보이며 비슷한 수준의 모형 복잡도를 나타냈다. Layer 4개인 모형이 3개인 모형에 비해 학습시간이 평균적으로69% 정도 길게 소요되었으나 정량지표는 크게 개선되지 않거나 특정 조건에서는 오히려 악화되는 것으로 나타났다. 하지만 layer 4개를 사용한 모형이 3개를 사용한 모형에 비해 완성도가 높은 문장을 생성했다. 본 논문에서 고려한 어떤 시뮬레이션 조건에서도 한글에서 사용되지 않는 문자조합이 생성되지 않았고 명사와 조사의 조합이나 동사의 활용, 주어 동사의 결합 면에서 상당히 완성도 높은 문장이 발생되었다. 본 연구결과는 현재 대두되고 있는 인공지능 시스템의 기초가 되는 언어처리나 음성인식 분야에서 한국어 처리를 위해 다양하게 활용될 수 있을 것으로 기대된다.
주식 시장은 거래자들의 기업과 시황에 대한 기대가 반영되어 움직이기에, 다양한 원천의 텍스트 데이터 분석을 통해 주가 움직임을 예측하려는 연구들이 진행되어 왔다. 주가의 움직임을 예측하는 것이기에 단순히 주가의 등락 뿐만이 아니라, 뉴스 기사나 소셜 미디어의 반응에 따라 거래를 하고 이에 따른 수익률을 분석하는연구들이 진행되어 왔다. 주가의 움직임을 예측하는 연구들도 다른 분야의 텍스트 마이닝 접근 방안과 동일하게 단어-문서 매트릭스를 구성하여 분류 알고리즘에 적용하여 왔다. 문서에 많은 단어들이 포함되어 있기 때문에 모든 단어를 가지고 단어-문서 매트릭스를 만드는 것보다는 단어가 문서를 범주로 분류할 때 기여도가 높은 단어들을 선정하여야 한다. 단어의 빈도를 고려하여 너무 적은등장 빈도나 중요도를 보이는 단어는 제거하게 된다. 단어가 문서를 정확하게 분류하는 데 기여하는 정도를 측정하여 기여도에 따라 사용할 단어를 선정하기도 한다. 단어-문서 매트릭스를 구성하는 기본적인 방안인 분석의 대상이 되는 모든 문서를 수집하여 분류에 영향력을 미치는 단어를 선정하여 사용하는 것이었다. 본 연구에서는 개별 종목에 대한 문서를 분석하여 종목별 등락에 모두 포함되는 단어를 중립 단어로 선정한다. 선정된 중립 단어 주변에 등장하는 단어들을 추출하여 단어-문서 매트릭스 생성에 활용한다. 중립 단어 자체는 주가 움직임과 연관관계가 적고, 중립 단어의 주변 단어가 주가 상승에 더 영향을 미칠 것이라는 생각에서 출발한다. 생성된 단어-문서 매트릭스를 가지고 주가의 등락 여부를 분류하는 알고리즘에 적용하게 된다. 본 연구에서는 종목 별로 중립 단어를 1차 선정하고, 선정된 단어 중에서 다른 종목에도 많이 포함되는 단어는 추가적으로 제외하는 방안을 활용하였다. 온라인 뉴스 포털을 통해 시가 총액 상위 10개 종목에 대한 4개월간의 뉴스 기사를 수집하였다. 3개월간의 뉴스 기사를 학습 데이터로 분류 모형을 수립하였으며, 남은 1개월간의 뉴스 기사를 모형에 적용하여 다음 날의 주가 움직임을 예측하였다. 본 연구에서 제안하는 중립 단어 활용알고리즘이 희소성에 기반한 단어 선정 방안에 비해 우수한 분류 성과를 보였다.
경제주체들의 경기상황에 대한 판단 및 전망은 경기변동에 영향을 미치므로 경기심리지수와 거시경제지표들간에는 밀접한 관련성을 나타내는 것으로 알려져 있다. 경기선행지표로 국내에서 많이 사용되는 경기심리지수에는 소비자동향조사, 기업경기조사, 경제심리지수가 있다. 그러나 설문조사를 통해 생성된 지수는 자료의 성격상 속보성이 떨어지는 문제가 있다. 본 연구에서는 이러한 정형데이터의 한계를 보완할 수 있도록 비정형데이터에서 정보를 추출해 경기심리지수를 생성하고, 경제분석에서의 활용 가능성을 검토하였다. 민간소비와 관련된 실물지표에는 소매판매업지수와 서비스업생산지수를 사용하였고, 고용지표에는 고용률과 실업률을, 가격지표에는 소비자물가상승률과 가계의 대출금리를 사용하여 지표들 간의 추이 분석 및 시차구조 파악을 위한 교차상관분석을 수행하였다. 마지막으로 이들 지표들에 대한 예측 가능성을 점검하였다. 분석결과, 다른 지표들의선행지수로 많이 사용되는 소비자심리지수와 비교해 선택 지표들과 높은 상관관계를 보이며, 1~2개월 선행한것으로 나타났다. 예측력 또한 향상되어 텍스트데이터에서 생성한 소비자 경기심리지수의 유용성이 확인되었다. 온라인에서 생성되는 뉴스기사나 소셜 SNS 등의 텍스트 데이터는 속보성이 뛰어나고, 커버리지가 넓어 특정 경제적 이슈가 발생할 경우 이것이 경제에 미치는 영향을 빠르게 파악할 수 있다는 점에서 경기판단지표로써의 잠재적 가능성이 클 것으로 보인다. 경제분석에서 비정형데이터를 활용한 국내연구는 초기 단계지만 데이터의 유용성이 확인되면 그 활용도가 크게 높아질 것으로 기대한다.
인터넷 상거래에서, 소비자들은 기존에 제품을 구매한 다른 사용자들이 작성한 상품평에 많은 영향을 받는다. 그러나, 상품평이 점차 축적되어감에 따라, 소비자들이 방대한 상품평을 일일이 확인하는데 많은 시간과 노력이 소요되고, 또한 무성의하게 작성된 상품평들은 오히려 소비자들의 불편을 초래하기도 한다. 이에, 본 연구는 온라인 상품평의 유용성에 영향을 미치는 요인들을 분석하여, 소비자들에게 실제로 도움이 될 수 있는 상품평을 선별적으로 제공하는 예측모형을 도출하는 것을 목적으로 한다. 이를 위해, 텍스트마이닝 기법을 사용하여, 상품평에 포함되어있는 다양한 언어적, 심리적, 지각적 요소들을 추출하였으며, 이러한 요소들 중에서 상품평의 유용성에 영향을 미치는 결정요인이 무엇인지 파악하였다. 특히, 경험재인 의류군과 탐색재인 전자제품군에 대한 상품평의 특성 및 유용성 결정요인이 상이할 수 있음을 고려하여, 제품군별로 상품평의 특성을 비교하고, 각각의 결정요인을 도출하였다. 본 연구에는 아마존닷컴(Amazon.com)의 의류군 상품평 7,498건과 전자제품군 상품평 106,962건이 사용되었다. 또한, 언어분석 소프트웨어인 LIWC(Linguistic Inquiry and Word Count)를활용하여 상품평에 포함된 특징들을 추출하였고, 이후, 데이터마이닝 소프트웨어인 RapidMiner를 사용하여, 회귀분석을 통한, 결정요인 분석을 수행하였다. 본 연구결과, 제품에 대한 리뷰어의 평가가 높고, 상품평에 포함된전체 단어 수가 많으며, 상품평의 내용에 지각적 과정이 많이 포함되어 있는 반면, 부정적 감정은 적게 포함된상품평들이 두 제품 모두에서 유용하다고 인식되는 것을 알 수 있었다. 그 외, 의류군의 경우, 비교급 표현이많고, 전문성 지수는 낮으며, 한 문장에 포함된 단어 수가 적은 간결한 상품평이 유용하다고 인식되고 있었으며, 전자제품의 경우, 전문성 지수가 높고, 분석적이며, 진솔한 표현이 많고, 인지적 과정과 긍정적 감정(PosEmo)이 많이 포함된 상품평이 유용하게 인식되고 있었다. 이러한 연구결과는 향후, 소비자들이 효과적으로유용한 상품평들을 확인하는데 도움이 될 것으로 기대된다.
최근 빅데이터 분석 수요의 지속적 증가와 함께 관련 기법 및 도구의 비약적 발전이 이루어지고 있으며, 이에 따라 빅데이터 분석은 소수 전문가에 의한 독점이 아닌 개별 사용자의 자가 수행 형태로 변모하고 있다. 또한 전통적 방법으로는 분석이 어려웠던 비정형 데이터의 활용 방안에 대한 관심이 증가하고 있으며, 대표적으로 방대한 양의 텍스트에서 주제를 도출해내는 토픽 모델링(Topic Modeling)에 대한 연구가 활발히 진행되고있다. 전통적인 토픽 모델링은 전체 문서에 걸친 주요 용어의 분포에 기반을 두고 수행되기 때문에, 각 문서의 토픽 식별에는 전체 문서에 대한 일괄 분석이 필요하다. 이로 인해 대용량 문서의 토픽 모델링에는 오랜 시간이소요되며, 이 문제는 특히 분석 대상 문서가 복수의 시스템 또는 지역에 분산 저장되어 있는 경우 더욱 크게작용한다. 따라서 이를 극복하기 위해 대량의 문서를 하위 군집으로 분할하고, 각 군집별 분석을 통해 토픽을도출하는 방법을 생각할 수 있다. 하지만 이 경우 각 군집에서 도출한 지역 토픽은 전체 문서로부터 도출한 전역 토픽과 상이하게 나타나므로, 각 문서와 전역 토픽의 대응 관계를 식별할 수 없다. 따라서 본 연구에서는 전체 문서를 하위 군집으로 분할하고, 각 하위 군집에서 대표 문서를 추출하여 축소된전역 문서 집합을 구성하고, 대표 문서를 매개로 하위 군집에서 도출한 지역 토픽으로부터 전역 토픽의 성분을도출하는 방안을 제시한다. 또한 뉴스 기사 24,000건에 대한 실험을 통해 제안 방법론의 실무 적용 가능성을 평가하였으며, 이와 함께 제안 방법론에 따른 분할 정복(Divide and Conquer) 방식과 전체 문서에 대한 일괄 수행방식의 토픽 분석 결과를 비교하였다.
E-commerce 환경의 발전으로 소비자들은 다양한 상품들을 한 자리에서 폭 넓게 비교할 수 있게 되었다. 하지만 온라인 쇼핑몰에 올라와있는 상당량의 주요 상품 정보들이 이미지 형태이기 때문에 컴퓨터가 인지할 수있는 텍스트 기반 검색 시스템에 반영될 수 없다는 한계가 존재한다. 이러한 한계점은 일반적으로 기존 기계학습 기술 및 OCR(Optical Character Recognition) 기술을 활용해, 이미지 형태로 된 키워드를 인식함으로써 개선할수 있다. 그러나 기존 OCR 기술은 이미지 안에 글자가 아닌 그림이 많고 글자 크기가 작으면 낮은 인식률을보인다는 문제가 있다. 이에 본 연구에서는 기존 기술들의 한계점을 해결하기 위하여, 딥러닝 기반 사물인식 모형 중 하나인 SSD(Single Shot MultiBox Detector)를 개조하여 이미지 형태의 상품 카탈로그 내의 텍스트 인식모형을 설계하였다. 하지만 이를 학습시키기 위한 데이터를 구축하는 데 상당한 시간과 비용이 필요했는데, 이는지도학습의 방법론을 따르는 SSD 모형은 훈련 데이터마다 직접 정답 라벨링을 해줘야 하기 때문이다. 본 연구는 이러한 문제점을 해결하기 위해 ‘훈련 데이터 자동 생성 프로그램’을 함께 개발하였다. 훈련 데이터 자동 생성 프로그램을 통해 수작업으로 데이터를 만드는 것에 비하여 시간과 비용을 대폭 절감할 수 있었으며, 생성된훈련용 데이터를 통해 모형의 인식 성능을 높일 수 있었다. 더 나아가 실험연구를 통해 자동으로 생성된 훈련데이터의 특징별로 인식기 모형의 성능에 얼마나 큰 영향을 끼치는지 알아보고, 성능 향상에 효과적인 데이터의 특징을 분석하였다. 본 연구를 통해서 개발된 상품 카탈로그 내 텍스트 인식모형과 훈련 데이터 자동 생성프로그램은 온라인 쇼핑몰 판매자들의 상품 정보 등록 수고를 줄여줄 수 있으며, 구매자들의 상품 검색 시 결과의 정확성을 향상시키는 데 기여할 수 있을 것으로 기대한다.
전통적으로 신문 매체는 국내외에서 발생하는 사건들을 살피는 데에 가장 적합한 매체이다. 최근에는 정보통신 기술의 발달로 온라인 뉴스 매체가 다양하게 등장하면서 주변에서 일어나는 사건들에 대한 보도가 크게증가하였고, 이것은 독자들에게 많은 양의 정보를 보다 빠르고 편리하게 접할 기회를 제공함과 동시에 감당할수 없는 많은 양의 정보소비라는 문제점도 제공하고 있다. 본 연구에서는 방대한 양의 뉴스기사로부터 데이터를 추출하여 주요 사건을 감지하고, 사건들 간의 관련성을 판단하여 사건 네트워크를 구축함으로써 독자들에게현시적이고 요약적인 사건정보를 제공하는 기법을 제안하는 것을 목적으로 한다. 이를 위해 2016년 3월에서2017년 3월까지의 한국 정치 및 사회 기사를 수집하였고, 전처리과정에서 NPMI와 Word2Vec 기법을 활용하여고유명사 및 합성명사와 이형동의어 추출의 정확성을 높였다. 그리고 LDA 토픽 모델링을 실시하여 날짜별로주제 분포를 계산하고 주제 분포의 최고점을 찾아 사건을 탐지하는 데 사용하였다. 또한 사건 네트워크를 구축하기 위해 탐지된 사건들 간의 관련성을 측정을 위하여 두 사건이 같은 뉴스 기사에 동시에 등장할수록 서로더 연관이 있을 것이라는 가정을 바탕으로 코사인 유사도를 확장하여 관련성 점수를 계산하는데 사용하였다. 최종적으로 각 사건은 각각의 정점으로, 그리고 사건 간의 관련성 점수는 정점들을 잇는 간선으로 설정하여 사건 네트워크를 구축하였다. 본 연구에서 제시한 사건 네트워크는 1년간 한국에서 발생했던 정치 및 사회 분야의 주요 사건들이 시간 순으로 정렬되었고, 이와 동시에 특정 사건이 어떤 사건과 관련이 있는지 파악하는데도움을 주었다. 또한 일련의 사건들의 시발점이 되는 사건이 무엇이었는가도 확인이 가능하였다. 본 연구는 텍스트 전처리 과정에서 다양한 텍스트 마이닝 기법과 새로이 주목받고 있는 Word2vec 기법을 적용하여 봄으로써 기존의 한글 텍스트 분석에서 어려움을 겪고 있었던 고유명사 및 합성명사 추출과 이형동의어의 정확도를높였다는 것에서 학문적 의의를 찾을 수 있다. 그리고, LDA 토픽 모델링을 활용하기에 방대한 양의 데이터를쉽게 분석 가능하다는 것과 기존의 사건 탐지에서는 파악하기 어려웠던 사건 간 관련성을 주제 동시출현을 통해 파악할 수 있다는 점에서 기존의 사건 탐지 방법과 차별화된다.
고객과 대중의 니즈를 파악하기 위한 감성분석의 중요성이 커지면서 최근 영어 텍스트를 대상으로 다양한 딥러닝 모델들이 소개되고 있다. 본 연구는 영어와 한국어의 언어적인 차이에 주목하여 딥러닝 모델을 한국어 상품평 텍스트의 감성분석에 적용할 때 부딪히게 되는 기본적인 이슈들에 대하여 실증적으로 살펴본다. 즉, 딥러닝모델의 입력으로 사용되는 단어 벡터(word vector)를 형태소 수준에서 도출하고, 여러 형태소 벡터(morpheme vector) 도출 대안에 따라 감성분석의 정확도가 어떻게 달라지는지를 비정태적(non-static) CNN(Convolutional Neural Network) 모델을 사용하여 검증한다. 형태소 벡터 도출 대안은 CBOW(Continuous Bag-Of-Words)를 기본적으로 적용하고, 입력 데이터의 종류, 문장 분리와 맞춤법 및 띄어쓰기 교정, 품사 선택, 품사 태그 부착, 고려형태소의 최소 빈도수 등과 같은 기준에 따라 달라진다. 형태소 벡터 도출 시, 문법 준수도가 낮더라도 감성분석 대상과 같은 도메인의 텍스트를 사용하고, 문장 분리 외에 맞춤법 및 띄어쓰기 전처리를 하며, 분석불능 범주를 포함한 모든 품사를 고려할 때 감성분석의 분류정확도가 향상되는 결과를 얻었다. 동음이의어 비율이 높은 한국어 특성 때문에 고려한 품사 태그 부착 방안과포함할 형태소에 대한 최소 빈도수 기준은 뚜렷한 영향이 없는 것으로 나타났다.
다양한 스마트 기기 및 관련 서비스의 증가에 따라 텍스트 데이터가 폭발적으로 증가하고 있으며, 이로 인해방대한 문서로부터 필요한 정보만을 추려내는 작업은 더욱 어려워졌다. 따라서 텍스트 데이터로부터 핵심 내용을 자동으로 요약하여 제공할 수 있는 텍스트 자동 요약 기술이 최근 더욱 주목을 받고 있다. 텍스트 요약 기술은 뉴스 요약 서비스, 개인정보 약관 요약 서비스 등을 통해 현업에서도 이미 활발하게 적용되고 있으며, 학계에서도 문서의 주요 요소를 선별하여 제공하는 추출(Extraction) 접근법과 문서의 요소를 발췌한 뒤 이를 조합하여 새로운 문장을 구성하는 생성(Abstraction) 접근법에 따라 많은 연구가 이루어지고 있다. 하지만 문서의 자동요약 기술에 비해, 자동으로 요약된 문서의 품질을 평가하는 기술은 상대적으로 많은 진전을 이루지 못하였다. 요약문의 품질 평가를 다룬 기존의 대부분의 연구들은 사람이 수작업으로 요약문을 작성하여 이를 기준 문서(Reference Document)로 삼고, 자동 요약문과 기준 문서와의 유사도를 측정하는 방식으로 수행되었다. 하지만이러한 방식은 기준 문서의 작성 과정에 막대한 시간과 비용이 소요될 뿐 아니라 요약자의 주관에 의해 평가결과가 다르게 나타날 수 있다는 한계를 갖는다. 한편 이러한 한계를 극복하기 위한 연구도 일부 수행되었는데, 대표적으로 전문에 대해 차원 축소를 수행하고 이렇게 축소된 전문과 자동 요약문의 유사도를 측정하는 기법이 최근 고안된 바 있다. 이 방식은 원문에서출현 빈도가 높은 어휘가 요약문에 많이 나타날수록 해당 요약문의 품질이 우수한 것으로 평가하게 된다. 하지만 요약이란 본질적으로 많은 내용을 줄여서 표현하면서도 내용의 누락을 최소화하는 것을 의미하므로, 단순히빈도수에 기반한 “좋은 요약”이 항상 본질적 의미에서의 “좋은 요약”을 의미한다고 보는 것은 무리가 있다. 요약문 품질 평가의 이러한 기존 연구의 한계를 극복하기 위해, 본 연구에서는 요약의 본질에 기반한 자동 품질평가 방안을 제안한다. 구체적으로 요약문의 문장 중 서로 중복되는 내용이 얼마나 적은지를 나타내는 요소로간결성(Succinctness) 개념을 정의하고, 원문의 내용 중 요약문에 포함되지 않은 내용이 얼마나 적은지를 나타내는 요소로 완전성(Completeness)을 정의한다. 본 연구에서는 간결성과 완전성의 개념을 적용한 요약문 품질 자동평가 방법론을 제안하고, 이를 TripAdvisor 사이트 호텔 리뷰의 요약 및 평가에 적용한 실험 결과를 소개한다.
최근 딥러닝은 오디오, 텍스트 및 이미지 데이터와 같은 비 체계적인 데이터를 대상으로 다양한 추정, 분류 및 예측 문제에 사용 및 적용되고 있다. 특히, 의류산업에 적용될 경우 딥러닝 기법을 활용한의류 인식, 의류 검색, 자동 제품 추천 등의 심층 학습을 기반으로 한 응용이 가능하다. 이 때의 핵심모형은 합성곱 신경망을 사용한 이미지 분류이다. 합성곱 신경망은 입력이 전달되고 출력에 도달하는과정에서 가중치와 같은 매개 변수를 학습하는 뉴런으로 구성되고, 영상 분류에 가장 적합한 방법론으로 사용된다. 기존의 의류 이미지 분류 작업에서 대부분의 분류 모형은 의류 이미지 자체 또는 전문모델 착용 의류와 같이 통제된 상황에서 촬영되는 온라인 제품 이미지를 사용하여 학습을 수행한다. 하지만 본 연구에서는 통제되지 않은 상황에서 촬영되고 사람들의 움직임과 다양한 포즈가 포함된 스트릿 패션 이미지 또는 런웨이 이미지를 분류하려는 상황을 고려하여 분류 모형을 훈련시키는 효과적인 방법을 제안한다. 이동성을 포착하는 런웨이 의류 이미지로 모형을 학습시킴으로써 분류 모형의다양한 쿼리 이미지에 대한 적응력을 높일 수 있다. 모형 학습 시 먼저 ImageNet 데이터셋을 사용하여pre-training 과정을 거치고 본 연구를 위해 수집된 32 개 주요 패션 브랜드의 2426개 런웨이 이미지로구성된 데이터셋을 사용하여 fine-tuning을 수행한다. 학습 과정의 일반화를 고려해 10번의 실험을 수행하고 제안된 모형은 최종 테스트에서 67.2 %의 정확도를 기록했다. 본 연구 모형은 쿼리 이미지가런웨이 이미지, 제품 이미지 또는 스트릿 패션 이미지가 될 수 있는 다양한 분류 환경에 적용될 수있다. 구체적으로는 패션 위크에서 모바일 어플리케이션 서비스를 통해 브랜드 검색을 용이하게 하는서비스를 제공하거나, 패션 잡지사의 편집 작업에 사용되어 브랜드나 스타일을 분류하고 라벨을 붙일수 있으며, 온라인 쇼핑몰에서 아이템 정보를 제공하거나 유사한 아이템을 추천하는 등의 다양한 목적에 적용될 수 있다.
최근 인터넷 기술의 발전과 함께 스마트 기기가 대중화됨에 따라 방대한 양의 텍스트 데이터가 쏟아져 나오고 있으며, 이러한 텍스트 데이터는 뉴스, 블로그, 소셜미디어 등 다양한 미디어 매체를 통해 생산 및 유통되고있다. 이처럼 손쉽게 방대한 양의 정보를 획득할 수 있게 됨에 따라 보다 효율적으로 문서를 관리하기 위한 문서 분류의 필요성이 급증하였다. 문서 분류는 텍스트 문서를 둘 이상의 카테고리 혹은 클래스로 정의하여 분류하는 것을 의미하며, K-근접 이웃(K-Nearest Neighbor), 나이브 베이지안 알고리즘(Naive Bayes Algorithm), SVM(Support Vector Machine), 의사결정나무(Decision Tree), 인공신경망(Artificial Neural Network) 등 다양한 기술들이 문서 분류에 활용되고 있다. 특히, 문서 분류는 문맥에 사용된 단어 및 문서 분류를 위해 추출된 형질에따라 분류 모델의 성능이 달라질 뿐만 아니라, 문서 분류기 구축에 사용된 학습데이터의 질에 따라 문서 분류의성능이 크게 좌우된다. 하지만 현실세계에서 사용되는 대부분의 데이터는 많은 노이즈(Noise)를 포함하고 있으며, 이러한 데이터의 학습을 통해 생성된 분류 모형은 노이즈의 정도에 따라 정확도 측면의 성능이 영향을 받게된다. 이에 본 연구에서는 노이즈를 인위적으로 삽입하여 문서 분류기의 견고성을 강화하고 이를 통해 분류의정확도를 향상시킬 수 있는 방안을 제안하고자 한다. 즉, 분류의 대상이 되는 원 문서와 전혀 다른 특징을 갖는이질적인 데이터소스로부터 추출한 형질을 원 문서에 일종의 노이즈의 형태로 삽입하여 이질성 학습을 수행하고, 도출된 분류 규칙 중 문서 분류기의 정확도 향상에 기여하는 분류 규칙만을 추출하여 적용하는 방식의 규칙선별 기반의 앙상블 준지도학습을 제안함으로써 문서 분류의 성능을 향상시키고자 한다.
크라우드펀딩(Crowdfunding)은 최근 벤처 기업의 기금 모금을 위한 엔젤 기금보다 인기가 있다. 이에 따라 크라우드펀딩의 성공 요인을 파악하는 것은 기금 조성자 및 투자자로 하여금 크라우드펀딩 프로젝트와 관련된 효과적 의사결정을 내리기 위해 크라우드펀딩 성공 여부를 선험적으로 예측하는데 유용할 것이다. 이에 최근까지 프로젝트의 목표 및 관련 SNS의 수와 같은 몇 가지 수치적 요인을 독립변인으로 제안하여 이들이 크라우드펀딩 캠페인의 성공에 어떤 영향을 미치는지 등이 연구되어오고 있었다. 그러나 수치가 아닌 비정형 데이터를 통한 크라우드펀딩 캠페인의 성공에 대한 예측은 거의 이루어진 바 없으며, 특히 프로젝트를 소개하는 문서에 대한 특성 분석을 통해 해당 프로젝트의 성공 여부를 예측하려는 연구는 아직 이루어지지 않았다. 사실 프로젝트를 소개하는 문서는 공개되어 있어 확보에 드는 비용이 적게 들기 때문에 매우 유용하다. 따라서 본 연구의 목적은 Wadiz 등 온라인상으로 공개되어 있는 프로젝트에 대한 소개 문서를 기반으로 크라우드펀딩 프로젝트의 성공을 예측하는 새로운 방법을 제안하는 것이다. 제안된 방법의 성능을 테스트하기 위해, 본 연구에서는 1,980개의 실 제 크라우드펀딩 프로젝트와 관련된 텍스트를 수집하고 경험적으로 분석했다. 텍스트 데이터 세트에서 카테고리, 응답 수, 자금 조달 목표, 기금 모금 방법, 보상, SNS 추종자 수, 이미지 및 비디오 수 및 기타 숫자 데이터와 같은 프로젝트에 대한 세부 정보를 수집하였다. 분석 결과 이러한 요인들은 분류 알고리즘에서 분류 성능을 제고하는데 의미 있는 변인으로 확인되었다. 즉, 제안된 방법이 최근에 제안된 비정형 텍스트 기반 방법보다 정확도나 F-점수 및 수행 경과 시간에서 성능이 우수하였다.
인터넷의 일상화와 각종 스마트 기기의 보급으로 이용자들로 하여금 실시간 의사소통이 가능하게 하여 기존의 커뮤니케이션 양식이 새롭게 변화되었다. 인터넷을 통한 정보주체의 변화로 인해 데이터는 더욱 방대해져서빅데이터라 불리는 정보의 초대형화를 야기하였다. 이러한 빅데이터는 사회적 실제를 이해하기 위한 새로운 기회로 여겨지고 있다. 특히 텍스트 마이닝은 비정형 텍스트 데이터를 이용해 패턴을 탐구하여 의미있는 정보를찾아낸다. 텍스트 데이터는 신문, 도서, 웹, SNS 등 다양한 곳에 존재하기 때문에 데이터의 양이 매우 다양하고방대하여 사회적 실제를 이해하기 위한 데이터로 적합하다. 본 연구는 한국 최대 인터넷 포털사이트 뉴스의 댓글을 수집하여 2017년 19대 한국 대선을 대상으로 연구를 수행하였다. 대선 선거일 직전 여론조사 공표 금지기간이 포함된 2017년 4월 29일부터 2017년 5월 7일까지 226,447건의 댓글을 수집하여 빈도분석, 연관감성어 분석, 토픽 감성 분석, 후보자 득표율 예측을 수행하였다. 이를 통해 각 후보자들에 대한 이슈를 분석 및 해석하고득표율을 예측하였다. 분석 결과 뉴스 댓글이 대선 후보들에 대한 이슈를 추적하고 득표율을 예측하기에 효과적인 도구임을 보여주었다. 대선 후보자들은 사회적 여론을 객관적으로 판단하여 선거유세 전략에 반영할 수있고 유권자들은 각 후보자들에 대한 이슈를 파악하여 투표시 참조할 수 있다. 또한 후보자들이 빅데이터 분석을 참조하여 선거캠페인을 벌인다면 국민들은 자신들이 원하는 바가 후보자들에게 피력, 반영된다는 것을 인지하고 웹상에서 더욱 적극적인 활동을 할 것이다. 이는 국민의 정치 참여 행위로써 사회적 의의가 있다.
챗봇은 음성, 이미지, 비디오 또는 텍스트와 같은 다양한 매채를 이용하여 대화가 가능한 대화형 어시스턴트이자 인공지능을 기반으로 사용자의 질문에 답하거나 문제를 해결할 수 있는 사용자 친화적프로그램이다. 하지만 현재 챗봇은 사용자가 요청한 작업을 정확하게 수행하는 기술적측면에 초점이맞추어져 있으며, 개인화된 대화로 사용자와 챗봇간의 관계성 구축에는 제한적이어서 일부 사례에도불구하고 소셜챗봇이 되기에는 미흡한 상태이다. 만약 인간의 사회성을 나타내는 특징 중 하나인 관계성을 챗봇이 인식하여 알맞게 대화를 하여 문제를 해결할 수 있다면, 개인화된 대화를 할 수 있을 뿐만아니라 인간과 유사한 대화를 할 수 있을 것이다. 본 연구의 목적은 사용자가 입력한 내용을 기반으로챗봇과 사용자 간의 관계성을 추론하고 대화 상황에 맞게 대화 상대가 적절한 대화를 수행 할 수 있는텍스트 분석 방법을 제안하는 것이다. 본 연구의 실험 및 평가를 하기 위하여 실제 SNS대화 내용을사용하였다. 분석결과 개인정보 보호를 위해 사용자의 개인 프로필 정보가 제외된 방법에서도 우수한결과를 나타내어 소셜 챗봇에 적합한 방법으로 검증되었다.
감성사전은 감성 어휘에 대한 사전으로 감성 분석(Sentiment Analysis)을 위한 기초 자료로 활용된다. 이와 같은 감성사전을 구성하는 감성 어휘는 특정 도메인에 따라 감성의 종류나 정도가 달라질 수 있다. 예를 들면, ‘슬프다’라는 감성 어휘는 일반적으로 부정의 의미를 나타내지만 영화 도메인에 적용되었을 경우 부정의 의미를나타내지 않는다. 그렇기 때문에 정확한 감성 분석을 수행하기 위해서는 특정 도메인에 알맞은 감성사전을 구축하는 것이 중요하다. 최근 특정 도메인에 알맞은 감성사전을 구축하기 위해 범용 감성 사전인 오픈한글, SentiWordNet 등을 활용한 연구가 진행되어 왔으나 오픈한글은 현재 서비스가 종료되어 활용이 불가능하며, SentiWordNet은 번역 간에 한국 감성 어휘들의 특징이 잘 반영되지 않는다는 문제점으로 인해 특정 도메인의감성사전 구축을 위한 기초 자료로써 제약이 존재한다. 이 논문에서는 기존의 범용 감성사전의 문제점을 해결하기 위해 한국어 기반의 새로운 범용 감성사전을 구축하고 이를 KNU 한국어 감성사전이라 명명한다. KNU 한국어 감성사전은 표준국어대사전의 뜻풀이의 감성을 Bi-LSTM을 활용하여 89.45%의 정확도로 분류하였으며긍정으로 분류된 뜻풀이에서는 긍정에 대한 감성 어휘를, 부정으로 분류된 뜻풀이에서는 부정에 대한 감성 어휘를 1-gram, 2-gram, 어구 그리고 문형 등 다양한 형태로 추출한다. 또한 다양한 외부 소스(SentiWordNet, SenticNet, 감정동사, 감성사전0603)를 활용하여 감성 어휘를 확장하였으며 온라인 텍스트 데이터에서 사용되는신조어, 이모티콘에 대한 감성 어휘도 포함하고 있다. 이 논문에서 구축한 KNU 한국어 감성사전은 특정 도메인에 영향을 받지 않는 14,843개의 감성 어휘로 구성되어 있으며 특정 도메인에 대한 감성사전을 효율적이고빠르게 구축하기 위한 기초 자료로 활용될 수 있다. 또한 딥러닝의 성능을 높이기 위한 입력 자질로써 활용될수 있으며, 기본적인 감성 분석의 수행이나 기계 학습을 위한 대량의 학습 데이터 세트를 빠르게 구축에 활용될수 있다.
제4차 산업혁명을 이끄는 주요 원동력 중 하나인 인공지능 기술은 이미지와 음성 인식 등 여러 분야에서 사람과 유사하거나 더 뛰어난 능력을 보이며, 사회 전반에 미치게 될 다양한 영향력으로 인하여 높은 주목을 받고있다. 특히, 인공지능 기술은 의료, 금융, 제조, 서비스, 교육 등 광범위한 분야에서 활용이 가능하기 때문에, 현재의 기술 동향을 파악하고 발전 방향을 분석하기 위한 노력들 또한 활발히 이루어지고 있다. 한편, 이러한 인공지능 기술의 급속한 발전 배경에는 학습, 추론, 인식 등의 복잡한 인공지능 알고리즘을 개발할 수 있는 주요플랫폼들이 오픈 소스로 공개되면서, 이를 활용한 기술과 서비스들의 개발이 비약적으로 증가하고 있는 것이주요 요인 중 하나로 확인된다. 또한, 주요 글로벌 기업들이 개발한 자연어 인식, 음성 인식, 이미지 인식 기능등의 인공지능 소프트웨어들이 오픈 소스 소프트웨어(OSS: Open Sources Software)로 무료로 공개되면서 기술확산에 크게 기여하고 있다. 이에 따라, 본 연구에서는 온라인상에서 다수의 협업을 통하여 개발이 이루어지고있는 인공지능과 관련된 주요 오픈 소스 소프트웨어 프로젝트들을 분석하여, 인공지능 기술 개발 현황에 대한보다 실질적인 동향을 파악하고자 한다. 이를 위하여 깃허브(Github) 상에서 2000년부터 2018년 7월까지 생성된인공지능과 관련된 주요 프로젝트들의 목록을 검색 및 수집하였으며, 수집 된 프로젝트들의 특징과 기술 분야를 의미하는 토픽 정보들을 대상으로 텍스트 마이닝 기법을 적용하여 주요 기술들의 개발 동향을 연도별로 상세하게 확인하였다. 분석 결과, 인공지능과 관련된 오픈 소스 소프트웨어들은 2016년을 기준으로 급격하게 증가하는 추세이며, 토픽들의 관계 분석을 통하여 주요 기술 동향이 ‘알고리즘’, ‘프로그래밍 언어’, ‘응용분야’, ‘개발 도구’의 범주로 구분하는 것이 가능함을 확인하였다. 이러한 분석 결과를 바탕으로, 향후 다양한 분야에서의 활용을 위해 개발되고 있는 인공지능 관련 기술들을 보다 상세하게 구분하여 확인하는 것이 가능할 것이며, 효과적인 발전 방향 모색과 변화 추이 분석에 활용이 가능할 것이다.
정보 기술의 발전으로 온라인에서 활용 가능한 데이터의 양이 급속히 증대되고 있다. 이러한 빅데이터 시대에 많은 연구들이 통찰력을 발견하고 데이터의 효과를 입증하기 위해 노력하고 있다. 특히 관광 산업의 경우 정보에 민감한 사업으로 소셜 미디어의 영향력이 높고 소셜 미디어의 상품 후기에 소비자들이 영향을 많이 받아 많은 기업과 연구자들이 소셜 미디어를 분석하여 새로운 서비스 및 통찰력을 얻고자 시도하였다. 하지만 소셜 미디어의 후기는 텍스트로 이루어진 대표적인 비정형 데이터로적절한 처리를 하지 않으면 분석에 활용할 수 없다. 또한 후기 데이터의 양이 방대함에 따라 사람이직접 분석하기도 어려운 실정이다. 따라서, 본 연구에서는 이러한 소셜미디어 상의 온라인 후기로부터직접 호텔의 서비스 품질 향상을 위한 통찰력을 추출할 수 있는 분석 방법을 제시하고자 한다. 이를위해 본 연구에서는 먼저 후기 데이터에 포함되어 있는 주제어를 추출하는 토픽 마이닝 기법을 적용하였다. 토픽 마이닝은 대용량의 문서 집합으로부터 문서를 대표하는 단어 집합을 추출하는 기법을 의미하며 본 연구에서는 다양한 연구에서 활용되고 있는 LDA모형을 사용하여 토픽 마이닝을 수행하였다. 하지만, 토픽 마이닝 자체만으로는 주제어와 평점 사이의 관계를 도출할 수 없어 서비스 품질 향상을위한 통찰력을 발견하기 어렵다. 그에 따라 본 연구에서는 토픽 마이닝의 결과값을 기반으로 의사결정나무 모형을 사용하여 주제어와 평점 사이의 관계를 도출하였다. 이러한 방법론의 유용성을 평가하기위해 홍콩에 있는 4개 호텔의 온라인 후기를 수집하고 제안한 방법론의 분석 결과를 해석하는 실험을진행하였다. 실험 결과 긍정 후기를 통해 각 호텔이 유지해야할 서비스 영역을 발견할 수 있었으며부정 후기를 통해 개선해야할 서비스 영역을 도출할 수 있었다. 따라서, 본 연구에서 제안한 방법론을사용하여 방대한 양의 후기 데이터로부터 서비스 개선 및 유지 영역을 발견할 수 있으리라 기대된다.
최근 4차 산업혁명과 함께 인공지능 기술에 대한 연구가 활발히 진행되고 있으며, 이전의 그 어느 때보다도기술의 발전이 빠르게 진행되고 있는 추세이다. 이러한 인공지능 환경에서 양질의 지식베이스는 인공지능 기술의 향상 및 사용자 경험을 높이기 위한 기반 기술로써 중요한 역할을 하고 있다. 특히 최근에는 인공지능 스피커를 통한 질의응답과 같은 서비스의 기반 지식으로 활용되고 있다. 하지만 지식베이스를 구축하는 것은 사람의 많은 노력을 요하며, 이로 인해 지식을 구축하는데 많은 시간과 비용이 소모된다. 이러한 문제를 해결하기위해 본 연구에서는 기계학습을 이용하여 지식베이스의 구조에 따라 학습을 수행하고, 이를 통해 자연어 문서로부터 지식을 추출하여 지식화하는 방법에 대해 제안하고자 한다. 이러한 방법의 적절성을 보이기 위해DBpedia 온톨로지의 구조를 기반으로 학습을 수행하여 지식을 구축할 것이다. 즉, DBpedia의 온톨로지 구조에따라 위키피디아 문서에 기술되어 있는 인포박스를 이용하여 학습을 수행하고 이를 바탕으로 자연어 텍스트로부터 지식을 추출하여 온톨로지화하기 위한 방법론을 제안하고자 한다. 학습을 바탕으로 지식을 추출하기 위한과정은 문서 분류, 적합 문장 분류, 그리고 지식 추출 및 지식베이스 변환의 과정으로 이루어진다. 이와 같은방법론에 따라 실제 지식 추출을 위한 플랫폼을 구축하였으며, 실험을 통해 본 연구에서 제안하고자 하는 방법론이 지식을 확장하는데 있어 유용하게 활용될 수 있음을 증명하였다. 이러한 방법을 통해 구축된 지식은 향후지식베이스를 기반으로 한 인공지능을 위해 활용될 수 있을 것으로 판단된다.
중국 화장품 전체 교역중 약 67% 정도가 전자상거래로 이루어지고 있는데 특히 한국 화장품인 K-Beauty 제품의 인기가 높다. 기존 연구에 의하면 화장품 같은 소비재의 경우 소비자의 80%는 제품 구매 전 제품정보를인터넷으로 검색하며 구전정보에 영향을 받는다. 대부분의 중국 소비자들은 화장품과 관련된 정보를 주요 SNS 에 다른 소비자들이 올린 댓글을 통해 획득하며 최근에는 뷰티 관련 동영상 채널 정보를 이용하기도 한다. 기존의 온라인 구전 관련 연구는 대부분 Facebook, Twitter, 블로그 등의 매체 자체가 중심이었다. 본 연구에서는 온라인 구전정보의 전달 형태와 정보의 형태를 고려하여 정보유형을 동영상과 사진 및 텍스트로 나누어 연구하고자 한다. 중국의 SNS대표 플랫폼인 SINA Weibo와 동영상 플랫폼 Meipai의 비정형 데이터를 분석하고 온라인구전정보를 양과 방향성으로 나누어 K-Beauty브랜드 매출액에 미치는 영향을 분석하고자 한다. Meipai에서는총 약 33만개의 데이터를 수집하였고 SINA Weibo에서는 총 약 11만개의 데이터를 수집하여 화장품의 기본 속성도 고려하여 분석하였다. 본 연구의 의의는 온라인 매출은 K-Beauty화장품에 대해서도 구전에 영향을 받는다는 것을 기본적으로 입증함과 동시에 특히 정보 유형에 대한 구분을 시도 했다는 것이다. 두가지 매체 모두 기존 연구와 같이 양이 매출에 영향을 미치고 있으나 매체풍부성으로 인해 텍스트보다 동영상이 정보를 더 주고영향이 크다는 것을 입증하였다. 또한, 정보 방향성 측면에서는 색조화장품의 경우 부정 댓글의 영향이 크게 나타났다. 실무적으로는 화장품 판매 전략 및 광고 전략에 기초 및 색조 화장품을 구분하여 중국 K-Beauty화장품매출증대를 위한 마케팅전략을 구사하는데 도움이 될 것으로 기대된다.
개인에게 맞춤형 서비스를 제공하는 것이 중요해지면서 개인화 추천 시스템 관련 연구들이 끊임없이 이루어지고 있다. 추천 시스템 중 협업 필터링은 학계 및 산업계에서 가장 많이 사용되고 있다. 다만 사용자들의 평점 혹은사용 여부와 같은 정량적인 정보에 국한하여 추천이 이루어져 정확도가 떨어진다는 문제가 제기되고 있다. 이와같은 문제를 해결하기 위해 현재까지 많은 연구에서 정량적 정보 외에 다른 정보들을 활용하여 추천 시스템의성능을 개선하려는 시도가 활발하게 이루어지고 있다. 리뷰를 이용한 감성 분석이 대표적이지만, 기존의 연구에서는 감성 분석의 결과를 추천 시스템에 직접적으로 반영하지 못한다는 한계가 있다. 이에 본 연구는 리뷰에 나타난감성을 수치화하여 평점에 반영하는 것을 목표로 한다. 즉, 사용자가 직접 작성한 리뷰를 감성 수치화하여 정량적인 정보로 변환해 추천 시스템에 직접 반영할 수 있는 새로운 알고리즘을 제안한다. 이를 위해서는 정성적인 정보인 사용자들의 리뷰를 정량화 시켜야 하므로, 본 연구에서는 텍스트 마이닝의 감성 분석 기법을 통해 감성 수치를산출하였다. 데이터는 영화 리뷰를 대상으로 하여 도메인 맞춤형 감성 사전을 구축하고, 이를 기반으로 리뷰의감성점수를 산출한다. 본 논문에서 사용자 리뷰의 감성 수치를 반영한 협업 필터링이 평점만을 고려하는 전통적인 방식의 협업 필터링과 비교하여 우수한 정확도를 나타내는 것을 확인하였다. 이후 제안된 모델이 더 개선된방식이라고 할 근거를 확보하기 위해 paired t-test 검증을 시도했고, 제안된 모델이 더 우수하다는 결론을 도출하였다. 본 연구에서는 평점만으로 사용자의 감성을 판단한 기존의 선행연구들이 가지는 한계를 극복하고자 리뷰를수치화하여 기존의 평점 시스템보다 사용자의 의견을 더 정교하게 추천 시스템에 반영시켜 정확도를 향상시켰다. 이를 기반으로 추가적으로 다양한 분석을 시행한다면 추천의 정확도가 더 높아질 것으로 기대된다.
정보화 시대의 넘쳐나는 콘텐츠들 속에서 사용자의 관심과 요구에 맞는 양질의 정보를 선별해내는 과정은세대를 거듭할수록 더욱 중요해지고 있다. 정보의 홍수 속에서 사용자의 정보 요구를 단순한 문자열로 인식하지 않고, 의미적으로 파악하여 검색결과에 사용자 의도를 더 정확하게 반영하고자 하는 노력이 이루어지고 있다. 구글이나 마이크로소프트와 같은 대형 IT 기업들도 시멘틱 기술을 기반으로 사용자에게 만족도와 편의성을제공하는 검색엔진 및 지식기반기술의 개발에 집중하고 있다. 특히 금융 분야는 끊임없이 방대한 새로운 정보가 발생하며 초기의 정보일수록 큰 가치를 지녀 텍스트 데이터 분석과 관련된 연구의 효용성과 발전 가능성이기대되는 분야 중 하나이다. 따라서, 본 연구는 주식 관련 정보검색의 시멘틱 성능을 향상시키기 위해 주식 개별종목을 대상으로 뉴럴 텐서 네트워크를 활용한 지식 개체명 추출과 이에 대한 성능평가를 시도하고자 한다. 뉴럴 텐서 네트워크 관련 기존 주요 연구들이 추론을 통해 지식 개체명들 사이의 관계 탐색을 주로 목표로 하였다면, 본 연구는 주식 개별종목과 관련이 있는 지식 개체명 자체의 추출을 주목적으로 한다. 기존 관련 연구의 문제점들을 해결하고 모형의 실효성과 현실성을 높이기 위한 다양한 데이터 처리 방법이 모형설계 과정에서적용되며, 객관적인 성능 평가를 위한 실증 분석 결과와 분석 내용을 제시한다. 2017년 5월 30일부터 2018년 5 월 21일 사이에 발생한 전문가 리포트를 대상으로 실증 분석을 진행한 결과, 제시된 모형을 통해 추출된 개체명들은 개별종목이 이름을 약 69% 정확도로 예측하였다. 이러한 결과는 본 연구에서 제시하는 모형의 활용 가능성을 보여주고 있으며, 후속 연구와 모형 개선을 통한 성과의 제고가 가능하다는 것을 의미한다. 마지막으로종목명 예측 테스트를 통해 본 연구에서 제시한 학습 방법이 새로운 텍스트 정보를 의미적으로 접근하여 관련주식 종목과 매칭시키는 목적으로 사용될 수 있는 가능성을 확인하였다.
최근 다양한 매체를 통해 생성되는 방대한 양의 텍스트 데이터를 효율적으로 관리 및 활용하기 위한 방안으로써 문서 요약에 대한 연구가 활발히 진행되고 있다. 특히 최근에는 기계 학습 및 인공 지능을 활용하여 객관적이고 효율적으로 요약문을 도출하기 위한 다양한 자동 요약 기법이(Automatic Summarization) 고안되고 있다. 하지만 현재까지 제안된 대부분의 텍스트 자동 요약 기법들은 원문에서 나타난 내용의 분포에 따라 요약문의내용이 구성되는 방식을 따르며, 이와 같은 방식은 비중이 낮은 주제(Subject), 즉 원문 내에서 언급 빈도가 낮은 주제에 대한 내용이 요약문에 포함되기 어렵다는 한계를 갖고 있다. 본 논문에서는 이러한 한계를 극복하기위해 저빈도 주제의 누락을 최소화하는 문서 자동 요약 기법을 제안한다. 구체적으로 본 연구에서는 (i) 원문에포함된 다양한 주제를 식별하고 주제별 대표 용어를 선정한 뒤 워드 임베딩을 통해 주제별 용어 사전을 생성하고, (ii) 원문의 각 문장이 다양한 주제에 대응되는 정도를 파악하고, (iii) 문장을 주제별로 분할한 후 각 주제에해당하는 문장들의 유사도를 계산한 뒤, (iv) 요약문 내 내용의 중복을 최소화하면서도 원문의 다양한 내용을최대한 포함할 수 있는 자동적인 문서 요약 기법을 제시한다. 제안 방법론의 평가를 위해 TripAdvisor의 리뷰50,000건으로부터 용어 사전을 구축하고, 리뷰 23,087건에 대한 요약 실험을 수행한 뒤 기존의 단순 빈도 기반의 요약문과 주제별 분포의 비교를 진행하였다. 실험 결과 제안 방법론에 따른 문서 자동 요약을 통해 원문 내각 주제의 균형을 유지하는 요약문을 도출할 수 있음을 확인하였다.
빅데이터 시대에 정보의 양이 급증하고, 그중 많은 부분을 차지하는 문자열 정보를 정량화하여 의미를 찾아낼 수 있는 인공지능 방법론이 함께 발전하면서, 텍스트 마이닝을 통해 주가 예측에 적용해 온라인 뉴스로 주가를 예측하려는 시도가 다양해지고 있다. 이러한 주가 예측의 방법은 대개 예측하고자 하는 기업의 뉴스로 주가를 예측하는 방식이다. 하지만 특정 회사의 뉴스만이 그 회사의 주가에 영향을 주는 것이 아니라, 그 회사와 관련성이 높은 회사들의 뉴스 또한 주가에 영향을 줄 수 있다. 그러나 관련성이 높은 기업을 찾는 것은 시장 전반의 공통적인 영향과 무작위 신호 때문에 쉽지 않다. 따라서 기존 연구들은 주로 미리 정해진 국제 산업 분류표준에 기반을 둬 관련성이 높은 기업을 찾았다. 하지만 최근 연구에 따르면, 국제 산업 분류 표준은 섹터에 따라 동질성이 다르며, 동질성이 낮은 섹터는 그들을 모두 함께 고려하여 주가를 예측하는 것이 성능에 악영향을줄 수 있다는 한계점을 가진다. 이러한 한계점을 극복하기 위해, 본 논문에서는 주가 예측 연구에서 처음으로 경제물리학에서 주로 사용되는 무작위 행렬 이론을 사용하여 시장 전반 효과와 무작위 신호를 제거하고 군집 분석을 시행하여 관련성이 높은 회사를 찾는 방법을 제시하였다. 또한, 이를 기반으로 관련성이 높은 회사의 뉴스를 함께 고려하며 다중 커널 학습을 사용하는 인공지능 모형을 제시한다. 본 논문의 결과는 무작위 행렬 이론을 통해 시장 전반의 효과와무작위 신호를 제거하여 정확한 상관 계수를 찾아 군집 분석을 시행한다면 기존 연구보다 더 좋은 성능을 보여준다는 것을 보여준다.
텍스트 데이터에 대한 다양한 분석을 위해 최근 비정형 텍스트 데이터를 구조화하는 방안에 대한 연구가 활발하게 이루어지고 있다. doc2Vec으로 대표되는 기존 문서 임베딩 방법은 문서가 포함한 모든 단어를 사용하여벡터를 만들기 때문에, 문서 벡터가 핵심 단어뿐 아니라 주변 단어의 영향도 함께 받는다는 한계가 있다. 또한기존 문서 임베딩 방법은 하나의 문서가 하나의 벡터로 표현되기 때문에, 다양한 주제를 복합적으로 갖는 복합문서를 정확하게 사상하기 어렵다는 한계를 갖는다. 본 논문에서는 기존의 문서 임베딩이 갖는 이러한 두 가지한계를 극복하기 위해 다중 벡터 문서 임베딩 방법론을 새롭게 제안한다. 구체적으로 제안 방법론은 전체 단어가 아닌 핵심 단어만 이용하여 문서를 벡터화하고, 문서가 포함하는 다양한 주제를 분해하여 하나의 문서를 여러 벡터의 집합으로 표현한다. KISS에서 수집한 총 3,147개의 논문에 대한 실험을 통해 복합 문서를 단일 벡터로 표현하는 경우의 벡터 왜곡 현상을 확인하였으며, 복합 문서를 의미적으로 분해하여 다중 벡터로 나타내는제안 방법론에 의해 이러한 왜곡 현상을 보정하고 각 문서를 더욱 정확하게 임베딩할 수 있음을 확인하였다
북한의 변화와 동향 파악에 대한 연구는 북한관련 정책에 대한 방향을 결정하고 북한의 행위를 예측하여 사전에 대응 할 수 있다는 측면에서 매우 중요하다. 현재까지 북한 동향에 대한 연구는 전문가를 중심으로 과거사례를 서술적으로 분석하여, 향후에 북한의 동향을 분석하고 대응하여 왔다. 이런 전문가 서술 중심의 북한 변화 및 동향 연구에서 비정형데이터를 이용한 텍스트마이닝 분석이 더해지면 보다 과학적인 북한 동향 분석이가능할 것이다. 특히 북한의 동향 파악과 북한의 대남 관련 행위와 연관된 연구는 통일 및 국방 분야에서 매우유용하며 필요한 분야이다. 본 연구에서는 북한의 신문 기사 내용을 활용한 텍스트마이닝 방법으로 북한과 관련한 핵심 단어를 구축하였다. 그리고 본 연구는 김정은 집권 이후 최근의 남북관계의 극적인 관계와 변화들을 기반으로 세 개의 기간을나누고 이 기간 내에 국내 언론에 나타난 북한과 관련성이 높은 단어들을 시계열적으로 분석한 연구이다. 북한과 관련한 주요 단어들을 세 개의 기간별로 분류하고 당시에 북한의 태도와 동향에 따라 해당 단어와 주제들의관련성이 어떻게 변화하였는지를 파악하였다. 본 연구는 텍스트마이닝을 이용한 연구가 남북관계 및 북한의 동향을 이해하고 분석하는 방법론으로서 얼마나 유용한 것이지를 파악하는 것이었다. 앞으로 북한의 동향 분석에 대한 연구는 물론 대북관계 및 정책에 대한방향을 결정하고, 북한의 행위를 사전에 예측하여 대응 할 수 있는 북한 리스크 측정 모델 구축을 위한 연구로진행 될 것이다.
본 연구는 고전 추리 소설 작가로 유명한 아서 코난 도일과 애거서 크리스티의 문체적 차이점을 데이터 분석을 통해 제시하고, 나아가 텍스트 마이닝에 입각한 문체 연구의 해석적 방법론을 제시하고자 시행되었다. 추리소설의 핵심 요소인 사건과 인물에 더해 작가의 문법적인 집필 방식을 문체로 정의하고 분석을 시도하였다. 작가 별로 각 2권, 총 4권의 책을 선정하였으며 문장 단위로 텍스트를 나누어 데이터를 확보하였다. 각 문장에 따른 감성 점수를 부여한 뒤 페이지 진행에 따른 감성을 시각화하였으며, 페이지에 따라 토픽 모델링을 적용하여소설 속 사건 진행 흐름을 파악할 수 있었다. 동시 발생 매트릭스(co-occurrence matrix)를 구성하고 네트워크 분석(Network Analysis)을 시행함으로써 사건이 진행되는 과정에서 인물들 간 관계의 변화를 확인할 수 있었다. 또한 전체 문장을 총 6가지 문체를 기준으로 문법적인 체계를 나누어 작가 간, 그리고 작품 간 집필 방식의 차이점을 확인하였다. 이러한 일련의 연구 과정은 문체에 대한 이해를 바탕으로 글 전체의 맥락을 파악할 수 있도록 도움을 줄 수 있으며, 나아가 기존에 개별적으로 진행되었던 문체 연구를 통합시킴으로써 문체 구조에 대한이해를 도울 수 있다. 그리고 이러한 선행된 이해를 통해 온라인 텍스트를 비롯한 비정형 데이터 속 문체의 존재를 발견하고 구체화하는 작업에 기여할 수 있다. 뉴미디어를 포함한 온라인 텍스트를 심도 있게 분석하고자하는 시도가 증가하고 있는 상황에서 해당 연구들과 연계를 통해 보다 의미 있는 온라인 텍스트 분석에 기여할것으로 기대된다.
구전(Word-of-Mouth) 활동은 오래 전부터 기업의 마케팅 과정에서 중요성을 인식하고 특히 마케팅 분야에서많은 주목을 받아왔다. 최근에는 인터넷의 발달에 따라 온라인 뉴스, 온라인 커뮤니티 등에서 사람들이 지식과정보를 주고 받는 방식이 다양해지면서 구전은 후기, 평점, 좋아요 등으로 입소문의 양상이 다각화되고 있다. 이러한 현상에 따라 구전에 관한 다양한 연구들이 선행되어왔으나, 이들을 종합적으로 분석한 메타 분석 연구는 부재하다. 본 연구는 학술 빅데이터를 활용해 구전 관련 연구동향을 알아내기 위해서 텍스트 마이닝 기법을적용하여 주요 연구들을 추출하고 시기별로 연구들의 주요 쟁점을 파악하는 기법을 제안하였다. 이를 위해서1941년부터 2018년까지 인용 데이터베이스인 Scopus에서 ‘Word-of-Mouth’라는 키워드로 검색되는 총 4389건의문헌을 수집하였고, 영어 형태소 분석과 불용어 제거 등 전처리 과정을 통해 데이터를 정제하였다. 본 연구는학문 분야의 발전 궤적을 추적하는 데 활용되는 주경로 분석기법을 적용해 구전과 관련된 핵심 연구들을 추출하여 연구동향을 거시적 관점에서 제시하였고, 단어동시출현 정보를 추출하여 키워드 간 네트워크를 구축하여시기별로 구전과 관련된 연관어들이 어떻게 변화되었는지 살펴봄으로써 연구동향을 미시적 관점에서 제시하였다. 수집된 문헌 데이터를 기반으로 인용 네트워크를 구축하고 SPC 가중치를 적용하여 키루트 주경로를 추출한 결과 30개의 문헌으로 구성된 주경로가 추출되었고, 연관어 네트워크 분석을 통해서는 시기별로 온라인 시대, 관광 산업 등 다양한 산업군 등 산업 변화가 반영돼 시대적 변화와 더불어 발전하고 있는 학술적 영역의변화를 확인할 수 있었다.
가짜뉴스가 전세계적 이슈로 부상한 최근 수년간 가짜뉴스 문제 해결을 위한 논의와 연구가 지속되고 있다. 특히 인공지능과 텍스트 분석을 이용한 자동화 가짜 뉴스 탐지에 대한 연구가 주목을 받고 있는데, 대부분 문서 분류 기법을 이용한 연구들이 주를 이루고 있는 가운데 문서 요약 기법은지금까지 거의 활용되지 않았다. 그러나 최근 가짜뉴스 탐지 연구에 생성 요약 기법을 적용하여 성능 개선을 이끌어낸 사례가 해외에서 보고된 바 있으며, 추출 요약 기법 기반의 뉴스 자동 요약 서비스가 대중화된 현재, 요약된 뉴스 정보가 국내 가짜뉴스 탐지 모형의 성능 제고에 긍정적인 영향을 미치는지 확인해 볼 필요가 있다. 이에 본 연구에서는 국내 가짜뉴스에 요약 기법을 적용했을 때정보 손실이 일어나는지, 혹은 정보가 그대로 보전되거나 혹은 잡음 제거를 통한 정보 획득 효과가발생하는지 알아보기 위해 국내 뉴스 데이터에 추출 요약 기법을 적용하여 ‘본문 기반 가짜뉴스 탐지 모형’과 ‘요약문 기반 가짜뉴스 탐지 모형’을 구축하고, 다수의 기계학습 알고리즘을 적용하여 두모형의 성능을 비교하는 실험을 수행하였다. 그 결과 BPN(Back Propagation Neural Network)과SVM(Support Vector Machine)의 경우 큰 성능 차이가 발생하지 않았지만 DT(Decision Tree)의 경우본문 기반 모델이, LR(Logistic Regression)의 경우 요약문 기반 모델이 다소 우세한 성능을 보였음을확인하였다. 결과를 검증하는 과정에서 통계적으로 유의미한 수준으로는 요약문 기반 모델과 본문기반 모델간의 차이가 확인되지는 않았지만, 요약을 적용하였을 경우 가짜뉴스 판별에 도움이 되는핵심 정보는 최소한 보전되며 LR의 경우 성능 향상의 가능성이 있음을 확인하였다. 본 연구는 추출요약 기법을 국내 가짜뉴스 탐지 연구에 처음으로 적용해 본 도전적인 연구라는 점에서 의의가 있다. 하지만 한계점으로는 비교적 적은 데이터로 실험이 수행되었다는 점과 한 가지 문서요약기법만사용되었다는 점을 제시할 수 있다. 향후 대규모의 데이터에서도 같은 맥락의 실험결과가 도출되는 지 검증하고, 보다 다양한 문서요약기법을 적용해 봄으로써 요약 기법 간 차이를 규명하는 확장된연구가 추후 수행되어야 할 것이다.
텍스트 데이터가 특정 범주에 속하는지 판별하는 문장 분류에서, 문장의 특징을 어떻게 표현하고 어떤 특징을 선택할 것인가는 분류기의 성능에 많은 영향을 미친다. 특징 선택의 목적은 차원을 축소하여도 데이터를 잘설명할 수 있는 방안을 찾아내는 것이다. 다양한 방법이 제시되어 왔으며 Fisher Score나 정보 이득(Information Gain) 알고리즘 등을 통해 특징을 선택 하거나 문맥의 의미와 통사론적 정보를 가지는 Word2Vec 모델로 학습된 단어들을 벡터로 표현하여 차원을 축소하는 방안이 활발하게 연구되었다. 사전에 정의된 단어의 긍정 및 부정 점수에 따라 단어의 임베딩을 수정하는 방법 또한 시도하였다. 본 연구는 문장 분류 문제에 대해 선택적 단어 제거를 수행하고 임베딩을 적용하여 문장 분류 정확도를 향상시키는 방안을 제안한다. 텍스트 데이터에서 정보 이득 값이 낮은 단어들을 제거하고 단어 임베딩을 적용하는방식과, 정보이득 값이 낮은 단어와 코사인 유사도가 높은 주변 단어를 추가로 선택하여 텍스트 데이터에서 제거하고 단어 임베딩을 재구성하는 방식이다. 본 연구에서 제안하는 방안을 수행함에 있어 데이터는 Amazon.com의 ‘Kindle’ 제품에 대한 고객리뷰, IMDB 의 영화리뷰, Yelp의 사용자 리뷰를 사용하였다. Amazon.com의 리뷰 데이터는 유용한 득표수가 5개 이상을 만족하고, 전체 득표 중 유용한 득표의 비율이 70% 이상인 리뷰에 대해 유용한 리뷰라고 판단하였다. Yelp의 경우는 유용한 득표수가 5개 이상인 리뷰 약 75만개 중 10만개를 무작위 추출하였다. 학습에 사용한 딥러닝 모델은 CNN, Attention-Based Bidirectional LSTM을 사용하였고, 단어 임베딩은 Word2Vec과 GloVe를 사용하였다. 단어 제거를 수행하지 않고 Word2Vec 및 GloVe 임베딩을 적용한 경우와 본 연구에서 제안하는 선택적으로 단어 제거를 수행하고 Word2Vec 임베딩을 적용한 경우를 비교하여 통계적 유의성을 검정하였다.
인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.
인공지능 기술의 급속한 발전과 함께 빅데이터의 상당 부분을 차지하는 비정형 텍스트 데이터로부터 의미있는 정보를 추출하기 위한 다양한 연구들이 활발히 진행되고 있다. 비즈니스 인텔리전스 분야에서도 새로운 시장기회를 발굴하거나 기술사업화 주체의 합리적 의사결정을 돕기 위한 많은 연구들이 이뤄져 왔다. 본 연구에서는 기업의 성공적인 사업 추진을 위해 핵심적인 정보 중의 하나인 시장규모 정보를 도출함에 있어 기존에 제공되던 범위보다 세부적인 수준의 제품군별 시장규모 추정이 가능하고 자동화된 방법론을 제안하고자 한다. 이를 위해 신경망 기반의 시멘틱 단어 임베딩 모델인 Word2Vec 알고리즘을 적용하여 개별 기업의 생산제품에 대한 텍스트 데이터를 벡터 공간으로 임베딩하고, 제품명 간 코사인 거리(유사도)를 계산함으로써 특정한 제품명과 유사한 제품들을 추출한 뒤, 이들의 매출액 정보를 연산하여 자동으로 해당 제품군의 시장규모를 산출하는알고리즘을 구현하였다. 실험 데이터로서 통계청의 경제총조사 마이크로데이터(약 34만 5천 건)를 이용하여 제품명 텍스트 데이터를 벡터화 하고, 한국표준산업분류 해설서의 산업분류 색인어를 기준으로 활용하여 코사인거리 기반으로 유사한 제품명을 추출하였다. 이후 개별 기업의 제품 데이터에 연결된 매출액 정보를 기초로 추출된 제품들의 매출액을 합산함으로써 11,654개의 상세한 제품군별 시장규모를 추정하였다. 성능 검증을 위해실제 집계된 통계청의 품목별 시장규모 수치와 비교한 결과 피어슨 상관계수가 0.513 수준으로 나타났다. 본 연구에서 제시한 모형은 의미 기반 임베딩 모델의 정확성 향상 및 제품군 추출 방식의 개선이 필요하나, 표본조사또는 다수의 가정을 기반으로 하는 전통적인 시장규모 추정 방법의 한계를 뛰어넘어 텍스트 마이닝 및 기계학습 기법을 최초로 적용하여 시장규모 추정 방식을 지능화하였다는 점, 시장규모 산출범위를 사용 목적에 따라쉽고 빠르게 조절할 수 있다는 점, 이를 통해 다양한 분야에서 수요가 높은 세부적인 제품군별 시장정보 도출이가능하여 실무적인 활용성이 높다는 점에서 의의가 있다.
KTX 차량은 수많은 기계, 전기 장치 및 부품들로 구성되어 있는 하나의 시스템으로 차량의 유지보수에는 상당히 많은 전문성과 유지보수 작업자들의 경험을 필요로 한다. 차량 고장발생 시 유지보수자의 지식과 경험에따라 문제 해결의 시간과 작업의 질적 차이가 발생하며 그에 따른 차량의 가용율이 달라진다. 일반적으로 문제해결은 고장 매뉴얼을 기반으로 하지만 경험이 많고 능숙한 전문가의 경우는 이와 더불어 개인의 노하우를 접목하여 신속하게 진단하고 조치를 취한다. 이러한 지식은 암묵지 형태로 존재하기 때문에 후임자에게 완전히전수되기 어려우며, 이를 위해 사례기반의 철도차량 전문가시스템을 개발하여 데이터화된 지식으로 바꾸려고하는 연구들이 있어왔다. 하지만, 간선에 가장 많이 투입되고 있는 KTX 차량에 대한 연구나 텍스트의 특징을추출하여 유사사례를 검색하는 시스템 개발은 아직 미비하다. 따라서, 본 연구에서는 이러한 차량 유지보수 전문가들의 노하우를 통해 수행된 고장들에 대한 진단과 조치 이력을 문제 해결의 사례로 활용하여 새롭게 발생하는 고장에 대한 조치가이드를 제공하는 지능형 조치지원시스템을 제안하고자 한다. 이를 위하여, 2015년부터 2017년동안 생성된 차량고장 데이터를 수집하여 사례베이스를 구축하였고, 차원축소 기법인 비음수 행렬 인수분해(NMF), 잠재의미분석(LSA), Doc2Vec을 통해 고장의 특징을 추출하여 벡터 간의 코사인 거리를 측정하는 방식으로 유사 사례를 검색하였으며, 위의 알고리즘에 의해 제안된 조치내역들 간성능을 비교하였다. 분석결과, 고장 내역의 키워드가 적은 경우의 유사 사례 검색과 조치 제안은 코사인 유사도를 직접 적용하는 경우에도 좋은 성능을 낸다는 것을 알 수 있었고 차원 축소 기법들의 성능 비교를 통해 문맥적 의미를 보존하는 차원 축소 방식 중 Doc2Vec을 적용하는 것이 가장 좋은 성능을 나타낸다는 것을 알 수 있었다. 텍스트 마이닝 기술은 여러 분야에서 활용을 위한 연구들이 이루어지고 있는 추세이나, 본 연구에서 활용하고자 하는 분야처럼 전문적인 용어들이 다수이고 데이터에 대한 접근이 제한적인 환경에서 이러한 텍스트 데이터를 활용한 연구는 아직 부족한 실정이다. 본 연구는 이러한 관점에서 키워드 기반의 사례 검색을 보완하고자텍스트 마이닝 기법을 접목하여 고장의 특징을 추출하는 방식으로 사례를 검색해 조치를 제안하는 지능형 진단시스템을 제시하였다는 데에 의의가 있다. 이를 통해 현장에서 바로 사용 가능한 진단시스템을 단계적으로 개발하는데 기초자료로써 시사점을 제공할 수 있을 것으로 기대한다.
추천시스템(recommender system)은 고객의 선호도를 예측하여 상품과 서비스를 제공하는 기법으로, 현재 다양한 온라인 서비스에 활용되고 있다. 이와 관련된 많은 선행 연구들은 협업필터링(collaborative filtering)에 기반한 추천시스템을 제안하였는데, 대부분의 경우 고객의 구매 내역 또는 평점 데이터만 사용하여 진행되었다. 오늘날 소비자들은 제품을 구매하는 과정에서 온라인 검색 행동을하여 관심있는 제품을 찾는다. 그렇기 때문에 검색 키워드 데이터는 고객의 선호도를 파악하는데 매우유용한 정보일 수 있다. 그러나 지금까지 추천시스템 연구에서 사용되는 경우는 거의 없었다. 이에 본연구는 고객의 검색 행동에 주목하여 온라인 쇼핑몰 고객의 검색 키워드 데이터와 구매 데이터를 고려한 하이브리드 협업 필터링을 제안하였다. 본 연구는 제안된 모델의 적용 가능성을 검증하기 위해 실제 온라인 쇼핑몰 데이터를 사용하여 성능을 검증하였다. 연구 결과, 추천 상품의 개수가 많아질수록고객의 검색 키워드를 기반으로 구축된 협업필터링의 추천 성능이 향상되는 반면 일반적인 협업필터링의 성능은 추천된 상품의 개수가 많아질수록 점차 감소함을 발견하였다. 따라서 본 연구는 검색 키워드 데이터를 활용한 하이브리드 협업필터링이 고객의 선호도를 반영한 추천할 수 있으며, 구매이력데이터의 정보부족을 해결할 수 있음을 확인하였다. 이는 기존의 정량 데이터만을 활용한 추천 시스템이 아닌, 비정형 데이터인 텍스트를 사용함으로써 새로운 하이브리드 협업필터링 구축 방법을 제안했다는 점에서 의의가 있다.
최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간간섭 문제를 해결하기 위해 ‘특성 독립 전이 학습’ 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한‘이미지-전문 캡션’ 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다.
박지성 선수의 2005년 맨체스터 유나이티드 FC 입단 이후로, 국내에서 프로축구 유니폼 시장이 본격적으로 성장하기시작했다. 이후, 국내 선수들의 해외 리그에서 활약이 계속되면서 국내에서도 잉글랜드 프리미어리그에 대한 대중의 관심이 지속되고 있다. 이러한 시점에서 본 연구는 국내 프로축구 팬들의 유니폼 소비에 전반적인 소비자 인식을 알아보고, 선수의 영입에 따른 소비자 인식 변화를 비교하고자 했다. EPL의 토트넘에서 활동하고 있는 손흥민 선수의 영입 전후를중심으로 소셜 미디어에 나타난 프로축구 팬들의 소비자 인식과 구매 요인을 알아보았다. ‘EPL 유니폼’을 키워드로, 국내포털사이트와 소셜 미디어의 게시글을 수집하고, 텍스트 마이닝, SNA, 회귀분석을 사용하여 분석했다. 연구 결과, 첫째, 선수의 소속 팀, 실적, 포지션과 구단의 실적, 순위, 리그의 우승 여부가 프로축구 유니폼의 구매와 탐색에 있어 주요 요인으로 확인되었다. 가격, 디자인, 사이즈, 로고 등과 같은 항목보다 유니폼의 형태, 마킹, 정품 여부, 스폰서와 더 중요하게작용하고 있었다. 둘째, 구조적 등위성 분석과 군집분석을 통해 국내 프로축구 팬들 사이에서 유니폼과 관련되어 언급되고 있는 주요 주제를 알아본 결과, EPL에 소속된 구단과 유명 선수들이 가장 핵심적인 주제로 나타났다. 셋째, 프로축구유니폼에 대한 시기별 주제는 월드컵과 EPL 리그에 대한 관심에서 EPL에서 활동하는 다양한 국내외 선수들에 대한 관심으로, 2015년 이후에는 유니폼 자체에 대한 것으로 주제가 변화했다. 이를 통해, 선수들의 이적에 따라 선수가 소속된 해당 구단의 유니폼이 관심을 받고 있음을 알 수 있었다. 넷째, 남녀 소비자 모두 손흥민에 대한 관심이 증가함에 따라서토트넘이 소속된 리그인 EPL에 대한 관심도 증가하는 것으로 나타났다. 여성의 경우 손흥민에 대한 관심이 증가함에 따라 축구 유니폼에 대해서도 관심을 가지는 것으로 나타난 반면, 남성의 경우 손흥민 선수에 대한 관심과 축구 유니폼에대한 관심 사이의 관계가 유의하게 나타나지 않았다. 각 구단은 선수와 구단의 성적과 이미지 관리, 스폰서 브랜드 관리에집중하고, 선수의 이적이 결정되면 선수의 자국에 해당 물량의 공급을 늘리며, 인기를 끌고 있는 선수의 등번호가 부착된유니폼의 경우에는 여성을 위한 다양한 사이즈를 제공해야 할 필요가 있다.
현 정부의 주요 국책사업 중 하나인 도시재생 뉴딜사업은 매년 100 곳씩, 5년간 500곳을대상으로 50조를 투자하여 낙후된 지역을 개발하는 것으로 언론과 지자체의 높은 이목이 집중되고 있다. 그러나, 현재 이 사업모델은 면적 규모에 따라“우리동네 살리기, 주거정비지원형, 일반근린형, 중심시가지형, 경제기반형” 등 다섯 가지로 나뉘어 추진되어 그 지역 본래의 특성을 반영하지 못하고 있다. 국내 도시재생 성공 키워드는 “주민 참여”, “지역특화” “부처협업”, “민관협력”이다. 성공 키워드에 따르면 지자체에서 정부에게 도시재생 사업을 제안할 때 지역주민, 민간기업의 도움과 함께 도시의 특성을정확히 이해하고 도시의 특성에 어울리는 방향으로 사업을 추진하는 것이 가장 중요하다는 것을 알 수 있다. 또한 도시재생 사업 후 발생하는 부작용 중 하나인 젠트리피케이션 문제를 고려하면 그 지역 특성에 맞는 도시재생 유형을 선정하여추진하는 것이 중요하다. 이에 본 연구는 ‘도시재생 뉴딜 사업’ 방법론의 한계점을 보완하기 위해, 기존 서울시가 지역 특성에 기반하여 추진하고 있는 “2025 서울시 도시재생 전략계획”의 도시재생 유형을 참고하여 도시재생 사업지에 맞는 도시재생 유형을 추천하는 시스템을 머신러닝 알고리즘을 활용하여 제안하고자 한다. 서울시 도시재생 유형은 “저이용저개발, 쇠퇴낙후, 노후주거, 역사문화자원 특화” 네 가지로 분류된다 (Shon and Park, 2017). 지역 특성을 파악하기 위해 총 4가지 도시재생 유형에 대해 사업이 진행된 22개의 지역에 대한 뉴스 미디어 10만여건의 텍스트 데이터를 수집하였다. 수집된 텍스트를 이용하여 도시재생 유형에 따른 지역별 주요 키워드를 도출하고 토픽모델링을 수행하여 유형별 차이가 있는 지 탐색해 보았다. 다음 단계로 주어진 텍스트를 기반으로 도시재생 유형을 추천하는 추천시스템 구축을 위해 텍스트 데이터를 벡터로변환하여 머신러닝 분류모델을 개발하였고, 이를 검증한 결과 97% 정확도를 보였다. 따라서 본 연구에서 제안하는 추천시스템은 도시재생 사업을 진행하는 과정에서 신규 사업지의 지역 특성에 기반한 도시재생 유형을 추천할 수 있을 것으로기대된다.
대규모 텍스트에서 관심 대상이 가지고 있는 속성들에 대한 감성을 세부적으로 분석하는 속성기반 감성분석(Aspect-Based Sentiment Analysis)은 상당한 비즈니스 가치를 제공한다. 특히, 텍스트에 속성어가 존재하는 명시적 속성뿐만 아니라 속성어가 없는 암시적 속성까지 분석 대상으로 하는 속성카테고리 감성분류(ACSC, Aspect Category Sentiment Classification)는 속성기반 감성분석에서 중요한 의미를 지니고 있다. 본 연구는 속성카테고리 감성분류에BERT 사전훈련 언어 모델을 적용할 때 기존 연구에서 다루지 않은 다음과 같은 주요 이슈들에 대한 답을 찾고, 이를 통해 우수한 ACSC 모델 구조를 도출하고자 한다. 첫째, [CLS] 토큰의 출력 벡터만 분류벡터로 사용하기보다는 속성카테고리에 대한 토큰들의 출력 벡터를 분류벡터에 반영하면 더 나은 성능을 달성할 수 있지 않을까? 둘째, 입력 데이터의 문장- 쌍(sentence-pair) 구성에서 QA(Question Answering)와 NLI(Natural Language Inference) 타입 간 성능 차이가 존재할까? 셋째, 입력 데이터의 QA 또는 NLI 타입 문장-쌍 구성에서 속성카테고리를 포함한 문장의 순서에 따른 성능 차이가 존재할까? 이러한 연구 목적을 달성하기 위해 입력 및 출력 옵션들의 조합에 따라 12가지 ACSC 모델들을 구현하고 4종 영어 벤치마크 데이터셋에 대한 실험을 통해 기존 모델 이상의 성능을 제공하는 ACSC 모델들을 도출하였다. 그리고 [CLS] 토큰에 대한 출력 벡터를 분류벡터로 사용하기 보다는 속성카테고리 토큰의 출력 벡터를 사용하거나 두 가지를 함께 사용하는것이 더욱 효과적이고, NLI 보다는 QA 타입의 입력이 대체적으로 더 나은 성능을 제공하며, QA 타입 안에서 속성이 포함된 문장의 순서는 성능과 무관한 점 등의 유용한 시사점들을 발견하였다. 본 연구에서 사용한 ACSC 모델 디자인을 위한 방법론은 다른 연구에도 비슷하게 응용될 수 있을 것으로 기대된다.
전세계적으로 퍼진 코로나19 상황은우리의 일상생활의 많은 부분에 영향을 끼쳤을 뿐만 아니라, 경제·사회 등 많은 부분에 걸쳐 막대한 영향력을 미치고 있다. 확진자와 사망자 수가 증가함에 따라 의료진과 대중은 불안, 우울, 스트레스 등 심리적인 문제를 겪고 있다고 한다. 장기적인 부정적인 감정은 사람들의 면역력을 감소시키고 신체적인 균형을 파괴할 수도 있으므로 코로나 19로 인한 심리적인 상태를 이해하는 것이 필수적인 상황이다. 본 연구에서는 코로나 19 감정과 관 련된 뉴스 데이터를 수집하여, 텍스트 마이닝을 통해 키워드를 분류하고, 키워드 사이의 의미 네트워크 분석을 통해 단어 들의 관계를 시각화하였다. 코로나 감정과 관련된 기사의 키워드에 나타난 단어들의 빈도수를 확인하고 이를 워드 클라우 드로 분석하였다. 키워드 빈도 분석 결과 코로나 19 감정과 관련하여 ‘중국’, ‘불안’, ‘상황’, ‘마음’, ‘사회’, ‘건강’과 같은 단어의 빈도가 높게 나타난 것을 확인할 수 있었다. 각 데이터 간 연결 중심성을 분석한 결과 키워드 중심성 네트워크에서 가장 중심적인 핵심어는 ‘심리’와 ‘코로나 19’, ‘블루’, ‘불안’이라는 단어가 높은 연결 중심성을 가지는 것을 확인할 수 있었다. 기사의 헤드라인에 나타난 주요 핵심어 사이의 동시 출현 빈도 네트워크를 그래프로 시각화한 결과, ‘코로나-블루’ 쌍이 가장 굵게 표시 되었고, ‘코로나-감정’, ‘코로나-불안’ 쌍이 비교적 굵은 선으로 표시된 것을 알 수 있었다. 코로나 와 관련된 ‘블루’는 우울증을 의미하는 단어로, 코로나와 우울증은 이제 관심을 가져야 할 키워드임을 확인할 수 있었다. 본 연구에서는 장기화한 코로나 19 상황에서 신체적인 방역 뿐만 아니라 심리적인 방역에도 힘써야 할 이 시기에 보건 정책 담당자가 빠르고 복잡한 의사결정 과정에 도움이 되고자 미디어 뉴스를 모니터링 함으로써, 더욱더 쉬운 소셜 미디어 네트워크 분석 방법을 제시하고자 한다.
정보기술 산업이 발전 됨에 따라 다양한 종류의 데이터가 생겨나고 있고 이를 가공하여 산업에 활용하는 것이 필수인 시대가 되었다. 온 오프라인 상에서 수집된 다양한 디지털 데이터를 분석하여 활용하는것은 산업 내의 고객에게 적합한 경험을 제공하기 위해서 꼭 필요한 과정이다. 새로운 비즈니스, 제품, 서비스를 창출하기 위해서는 다방면에서 수집된 고객 데이터를 활용하여 잠재고객의 니즈를 깊게 파악하고 행동패턴을 분석하여 숨겨진 욕망의 신호를 잡아내는 것이 필수이다. 그러나 효과적인 서비스 개발을 위해서 병행해서 진행되어야 할 데이터 분석, UX 방법론을 활용한 연구는 각각 따로 진행되고 있고 산업 내의 활용 예시가 부족한 것이 사실이다. 본 연구에서는 데이터 분석 방법과 UX 방법론을 응용하여 하나의 프로세스를 제작하였다. 행복을 주제로 진행된 설문조사에서 추출된 고객 데이터를 활용하여 고객의 특성을 파악하기 위한 데이터 분석을 진행하였다. 요인, 회귀분석을 실시하여 행복 데이터 설문의 요인 간의 연관 관계를 확인하였다. 그 다음 연관 관계를 군집을 분류하고 가장 최적의 군집 수를 추출하여 분류하였다. 이러한 결과를 바탕으로 교차분석을 진행하여 군집 별로 인구통계학적 특성을 확인하였다. 세그먼트를 분류하기 전 서비스 정의를 하기 위하여 뉴스 기사 및 SNS 문장들을 바탕으로 텍스트 마이닝을 통해 주요 키워드를 바탕으로 아이디어를 도출 하였고 이중에 가장 타당한 서비스를 선택하였다. 이러한 결과를 바탕으로 세그먼트 및 목표 고객을 선정한 후 세그먼트의 특성대로 대상자를 선정하여 인터뷰를 진행하였다. 그 후 특성 및 프로파일 정보를 활용하여 페르소나를 제작하여 고객의 행동과 최종 목표를 서술하였다. 일반적인 페르소나와 데이터를 활용한 페르소나를 비교하여 각각의 특성을 비교 분석하였다. 본 연구를 통해 도출된 프로세스는 다변화되는 서비스의 변화 상황에서 적절한 타겟 고객의 정의 및 정확한 분류 체계로 나뉘어진 고객군을 파악할 수 있는 방법을 제시한 것에 의의가 있다.
추천시스템은 사용자의 기호를 파악하여 물품 구매 결정을 도와주는 역할을 할 뿐만 아니라, 비즈니스 전략의 관점에서도 중요한 역할을 하기에 많은 기업과 기관에서 관심을 갖고 있다. 최근에는 다양한 추천시스템 연구 중에서도 NLP와 딥러닝 등을 결합한 하이브리드 추천시스템 연구가 증가하고 있다. NLP를 이용한 감성분석은 사용자 리뷰 데이터가 증가함에 따라 2000년대 중반부터 활용되기 시작하였지만, 기계학습 기반 텍스트 분류를 통해서는 텍스트의 특성을 완전히 고려하기 어렵기 때문에 리뷰의 정보를 식별하기 어려운 단점을 갖고 있다. 본 연구에서는 기계학습의 단점을 보완하기 위하여 BERT 기반 감성분석을 활용한 추천시스템을 제안하고자 한다. 비교 모형은 Naive-CF(collaborative filtering), SVD(singular value decomposition)-CF, MF(matrix factorization)-CF, BPR-MF(Bayesian personalized ranking matrix factorization)-CF, LSTM, CNN-LSTM, GRU(Gated Recurrent Units)를 기반으로 하는 추천 모형이며, 실제 데이터에 대한 분석 결과, BERT를 기반으로 하는 추천시스템의 성과가 가장 우수한 것으로 나타났다
화자인식은 자동 음성시스템에서 중요한 기능을 담당하며, 최근 휴대용 기기의 발전 및 음성 기술, 오디오 콘텐츠 분야 등이 계속해서 확장됨에 따라 화자인식 기술의 중요성은 더구나 부각 되고 있다. 이전의 화자인식 연구는 음성 파일을 기반으로 화자가 누구인지 자동으로 판정 및 정확도 향상을 위한 목표를 가지고 진행되었다. 한편 말투는 중요한 사회언어학적 소재로 사용자의 사회적 환경과 밀접하게 관련되어 있다. 추가로 화자의 말투에 사용되는 종결어미는 문장의 유형을 결정하거나 화자의 의도, 심리적 태도 또는 청자에 대한 관계 등의 기능과 정보를 가지고 있다. 이처럼 종결어미의 활용 형태는 화자의 특성에 따라 다양한 개연성이 있어 특정 미확인 화자의 종결어미의 종류와 분포는 해당 화자를 인식하는 것에 도움이 될 것으로 보인다. 기존 텍스트 기반의 화자인식에서 말투를 고려한 연구가 적었으며 음성 신호를 기반으로 한 화자인식 기법에 말투 정보를 추가한다면 화자인식의 정확도를 더욱 높일 수 있을 것이다. 따라서 본 연구의 목적은 한국어 화자인식의 정확도를 개선하기 위해 종결어미로 표현되는 말투(speech style) 정보를 활용한 방법을 제안하는 것이다. 이를 위해 특정인의 발화 내용에서 등장하는 종결어미의 종류와 빈도를 활용하여 벡터값을 생성하는 문장 시퀀싱이라는 방법을 제안한다. 본 연구에서 제안한 방법의 우수성을 평가하기 위해 드라마 대본으로 학습 및 성능평가를 수행하였다. 본 연구에서 제안한 방법은 향후 실존하는 한국어 음성인식 서비스의 성능 향상을 위한 수단으로 사용될 수 있으며 지능형 대화 시스템 및 각종 음성 기반 서비스에 활용될 것을 기대한다.
최근 4차 산업혁명, 코로나로 인한 뉴노멀 시대의 도래 등을 계기로 인공지능, 빅데이터 연구와 같은 언택트 관련 기술의 중요성이 더욱 급상하고 있다. 각종 연구 분야에서는 이러한 연구 트렌드를 따라가기 위한 융합적 연구가 본격적으로 시행되고 있으나 원자력 분야의 경우 자연어 처리, 텍스트마이닝 분석 등 인공지능 및 빅데이터 관련 기술을 적용한 연구가 많이 수행되지 않았다. 이에 원자력 연구 분야에 데이터 사이언스 분석기술의 적용 가능성을 확인해보고자 본 연구를 수행하였다. 원자로 연료로 사용된 뒤 배출되는 사용후핵연료 인식 동향 파악에 대한 연구는 원자력 산업 정책에 대한 방향을 결정하고 산업정책 변화를 사전에 대응할 수 있다는 측면에서 매우 중요하다. 사용후핵연료 처리기술은 크게 습식 재처리 방식과 건식 재처리 방식으로 나뉘는데, 이 중 환경 친화적이고 핵비확산성 및 경제성이 높은 건식재처리 기술인 ‘파이로프로세싱’과 그 연계 원자로 ‘소듐냉각고속로’의 연구개발에 대한 재평가가 현재 지속적으로 검토되고 있다. 따라서 위와 같은 이유로, 본 연구에서는 사용후핵연료 처리기술인 파이로프로세싱에 대한 언론 동향 분석을 진행하였다. 사용후핵연료 처리기술인‘파이로프로세싱’키워드를 포함하는 네이버 웹 뉴스 기사 전문의 텍스트데이터를 수집하여 기간에 따라 인식변화를 분석하였다. 2016년 발생한 경주 지진, 2017년 새 정부의 에너지 전환정책 시행된 2010년대 중반 시기를 기준으로 전, 후의 동향 분석이 시행되었고, 빈도분석을 바탕으로 한 워드 클라우드 도출, TF-IDF(Term Frequency ? Inverse Document Frequency) 도출, 연결정도 중심성 산출 등의 분석방법을 통해 텍스트데이터에 대한 세부적이고 다층적인 분석을 수행하였다. 연구 결과, 2010년대 이전에는 사용후핵연료 처리기술에 대한 사회 언론의 인식이 외교적이고 긍정적이었음을 알 수 있었다. 그러나 시간이 흐름에 따라 ‘안전(safety)’, ‘재검토(reexamination)’, ‘대책(countermeasure)’, ‘처분(disposal)’, ‘해체(disassemble)’ 등의 키워드 출현빈도가 급증하며 사용후핵연료 처리기술 연구에 대한 지속 여부가 사회적으로 진지하게 고려되고 있음을 알 수 있었다. 정치 외교적 기술로 인식되던 사용후핵연료 처리기술이 국내 정책의 변화로 연구 지속 가능성이 모호해짐에 따라 언론 인식도 점차 변화했다는 것을 확인하였다. 이러한 연구 결과를 통해 원자력 분야에서의 사회과학 연구의 지속은 필수불가결함을 알 수 있었고 이에 대한 중요성이 부각되었다. 또한, 현 정부의 원전 감축과 같은 에너지 정책의 영향으로, 사용후핵연료 처리기술 연구개발에 대한 재평가가 시행되는 이 시점에서 해당 분야의 주요 키워드 분석은 향후 연구 방향 설정에 기여할 수 있을 것이라는 측면에서 실무적 의의를 갖는다. 더 나아가 원자력 공학 분야에 사회과학 분야를 폭넓게 적용할 필요가 있으며, 국가 정책적 변화를 고려해야 원자력 산업이 지속 가능할 것으로 사료된다.
전 세계적인 COVID-19의 유행으로 인해 관광산업 전반이 큰 타격을 받고 있다. 최근 공유경제의 확산으로 팽창되고 있는 Airbnb와 같은 숙박 공유서비스는 공급자와 수요자 간의 신뢰와 소통을 기반으로 거래가 이루어지기 때문에 팬데믹으로 인한 영향을 특히 크게 받고 있다. 팬데믹 상황이 개인의 여행에 대한 인식과 행동을 변화시킴에 따라 이를 개선하기 위한 전략에 대한 논의가 이루어지고 있지만 대부분의 연구는 전통적인 외식업, 숙박업 공급자와 정부 측면의 거시적 전략을 제시하고 있다. 본 연구는 Peer-to-Peer 거래 중심의 공유경제의 특수성을 고려하여 COVID-19 팬데믹 발생 전후로 Airbnb 개별 호스트의 마케팅 전략의 변화가 공유성과에 미치는 영향을 실증적으로 분석함으로써 개별 호스트 측면의 팬데믹 전략에 대해 논한다. Airbnb의 호스트가 본인의 시설을 홍보하는 통로인 시설소개 텍스트를 수집하여 딥러닝 기반 특성추출방법인 Attention-based aspect extraction 모델로부터 9개의 주요 특성을 추출하였다. 추출된 특성이 해당 텍스트에서 등장하는 빈도가 COVID-19 발생 전후 변화량을 측정하여 이것이 공유성과에 미치는 영향을 분석하였다. 또한 이러한 영향을 숙박시설의 유형 간에 비교함으로써 시설 유형별 효과적으로 작용하는 특성을 관찰하였다. 회귀분석 결과 주방시설, 정원, 호스트와의 교류 순으로 공유성과에 긍정적인 영향을 보이지만 시설 유형에 따라 공유성과에 미치는 영향은 다소 차이가 있었다. 특히 집 전체를 대여하는 경우 개인실 대여에 비해 주방시설에 대한 설명이 상당한 효과를 보여주었다. 이를 통해 본 연구는 공유숙박 서비스의 개별 서비스 제공자가 시설의 종류에 따라 취할 수 있는 팬데믹 위기 대처 전략에 대한 아이디어를 제시한다.
저출산 문제로 인한 병역자원 감소와 병 복무기간 단축에 따른 군 간부 대비 병 복무 선호 현상은 우수한 군 간부확보 정책에 대한 추가적인 고찰을 필요로 한다. 이와 관련된 연구들은 대부분 사회과학에서 주로 사용되는 방법론으로 분석하 였으나, 본 연구는 대량의 문헌조사에 적합한 텍스트 마이닝의 방법론으로 접근한다. 이를 위해, 본 연구는 공군 부사관 지원자 자기소개서에서 차별적인 특성의 단어들을 추출하고 합격 및 불합격의 극성을 분석한다. 본 연구는 총 3단계로 이 루어졌다. 첫번째, 지원분야를 일반분야와 기술분야로 나누고, 자기소개서에서 특성을 가지는 단어들을 분야별 빈도수 비 율의 차이대로 순서화 한다. 각 지원분야별 비율의 차이가 클수록 해당 지원분야의 특성을 나타내는 것으로 정의하였다. 두번째, 이 특성을 나타내는 단어들을 LDA를 통해 단어들의 Topic을 군집화하고 이를 바탕으로 Label을 정의하였다. 세 번째, 이 군집화 된 지원분야별 단어들을 L-LDA를 통해 합격과 불합격의 극성을 분석하였다. L-LDA값의 차이가 합격에 가까울수록 합격자들이 많이 사용하는 단어로 정의하였다. 본 연구를 통해, 공군 부사관 자기소개서의 차별적 특성을 추 출하기에는 LDA보다 L-LDA가 더 적합함을 알 수 있다. 또한, 이러한 방법론은 별도의 서면 또는 대면 설문 방식이 아니 라, 대량 문서에 대한 텍스트 마이닝 기법을 적용하여 분석시간을 단축하고, 전체 모집단에 대한 신뢰성을 높일 수 있다. 따라서 본 연구인 공군 부사관 선발결과 분석을 통해, 선발제도 및 홍보제도에 활용 가능한 정보를 제공하고, 군 인력획득 분야 연구에 있어 활용 가능한 방법론을 제안하고자 한다.
최근 딥 러닝 기술의 발전으로 뉴스, 블로그 등 다양한 문서에 포함된 텍스트 분석에 딥 러닝 기술을 활용하는 연구가 활발하게 수행되고 있다. 다양한 텍스트 분석 응용 가운데, 텍스트 분류는 학계와 업계에서 가장 많이 활용되는 대표적인 기술이다. 텍스트 분류의 활용 예로는 정답 레이블이 하나만 존재하는 이진 클래스 분류와 다중 클래스 분류, 그리고 정답 레이블이 여러 개 존재하는 다중 레이블 분류 등이 있다. 특히, 다중 레이블 분류는 여러 개의 정답 레이블이 존재한다는 특성 때문에 일반적인 분류와는 상이한 학습 방법이 요구된다. 또한, 다중 레이블 분류 문제는 레이블과 클래스의 개수가 증가할수록 예측의 난이도가 상승한다는 측면에서 데이터 과학 분야의 난제로 여겨지고 있다. 따라서 이를 해결하기 위해 다수의 레이블을 압축한 후 압축된 레이블을 예측하고, 예측된 압축 레이블을 원래 레이블로 복원하는 레이블 임베딩이 많이 활용되고 있다. 대표적으로 딥 러닝 모델인 오토인코더 기반 레이블 임베딩이 이러한 목적으로 사용되고 있지만, 이러한 기법은 클래스의 수가 무수히 많은 고차원 레이블 공간을 저차원 잠재 레이블 공간으로 압축할 때 많은 정보 손실을 야기한다는 한계가 있다. 이에 본 연구에서는 오토인코더의 인코더와 디코더 각각에 스킵 연결을 추가하여, 고차원 레이블 공간의 압축 과정에서 정보 손실을 최소화할 수 있는 레이블 임베딩 방법을 제안한다. 또한 학술연구정보서비스인 ‘RISS’에서 수집한 학술논문 4,675건에 대해 각 논문의 초록으로부터 해당 논문의 다중 키워드를 예측하는 실험을 수행한 결과, 제안 방법론이 기존의 일반 오토인코더 기반 레이블 임베딩 기법에 비해 정확도, 정밀도, 재현율, 그리고 F1 점수 등 모든 측면에서 우수한 성능을 나타냄을 확인하였다.